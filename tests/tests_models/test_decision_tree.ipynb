{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Training\n",
    "\n",
    "This notebook trains a Decision Tree classifier on the CICIDS2017 intrusion detection dataset.\n",
    "\n",
    "**Key Features:**\n",
    "- SMOTE balancing\n",
    "- Tree complexity analysis\n",
    "- Feature importance visualization\n",
    "- Decision rules extraction\n",
    "- Tree visualization\n",
    "\n",
    "**Advantages of Decision Trees:**\n",
    "- Fast training and prediction\n",
    "- Interpretable results\n",
    "- Handles non-linear relationships\n",
    "- No feature scaling required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "\n",
    "# Add project root to path\n",
    "root_dir = os.getcwd().split(\"AdversarialNIDS\")[0] + \"AdversarialNIDS\"\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "from CICIDS2017.dataset import CICIDS2017\n",
    "from UNSWNB15.dataset import UNSWNB15\n",
    "\n",
    "# Import shared utilities\n",
    "from scripts.models.model_utils import (\n",
    "    check_data_leakage,\n",
    "    get_tree_feature_importance,\n",
    ")\n",
    "\n",
    "# Import model-specific modules\n",
    "from scripts.models.decision_tree.decision_tree import train_decision_tree\n",
    "from scripts.analysis.model_analysis import perform_model_analysis\n",
    "from scripts.logger import LoggerManager\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = LoggerManager(log_name=\"dt_notebook\").get_logger()\n",
    "logger.info(\"Starting Decision Tree training notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "logger.info(\"Loading CICIDS2017 dataset...\")\n",
    "dataset = CICIDS2017(logger=logger).optimize_memory().encode().scale().subset(size=100000, multi_class=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Leakage Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO\n",
    "# diagnostics = check_data_leakage(X, y, logger=logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = dataset.split(test_size=0.2, apply_smote=True)\n",
    "print(f\"Train set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cross-Validation and training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack model and CV scores from train_decision_tree\n",
    "dt_model, cv_scores = train_decision_tree(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    max_depth=3,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    criterion='gini',\n",
    "    max_features=None,\n",
    "    class_weight='balanced',\n",
    "    cv_test=False,\n",
    "    cv=3,\n",
    "    random_state=0,\n",
    "    logger=logger\n",
    ")\n",
    "if cv_scores!= None:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"CROSS-VALIDATION RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"CV Scores: {cv_scores}\")\n",
    "    print(f\"Mean CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
    "    # Plot CV scores\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(cv_scores)+1), cv_scores, marker='o', markersize=10, linewidth=2, color='green')\n",
    "    plt.axhline(y=cv_scores.mean(), color='r', linestyle='--', \n",
    "                label=f'Mean: {cv_scores.mean():.4f}')\n",
    "    plt.xlabel('Fold', fontsize=12)\n",
    "    plt.ylabel('Accuracy', fontsize=12)\n",
    "    plt.title('Decision Tree Cross-Validation Scores', fontsize=14, fontweight='bold')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analyze Tree Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.models.decision_tree.analyze_tree import analyze_tree_complexity \n",
    "# Analyze tree complexity\n",
    "complexity = analyze_tree_complexity(dt_model, logger=logger)\n",
    "\n",
    "# Visualize complexity\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart of tree metrics\n",
    "metrics = ['Total Nodes', 'Leaf Nodes', 'Max Depth', 'Features Used']\n",
    "values = [complexity['n_nodes'], complexity['n_leaves'], \n",
    "          complexity['max_depth'], complexity['n_features_used']]\n",
    "\n",
    "axes[0].bar(metrics, values, color=['skyblue', 'lightgreen', 'salmon', 'gold'])\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].set_title('Tree Complexity Metrics', fontsize=14, fontweight='bold')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Pie chart of node distribution\n",
    "internal_nodes = complexity['n_nodes'] - complexity['n_leaves']\n",
    "axes[1].pie([internal_nodes, complexity['n_leaves']], \n",
    "            labels=['Internal Nodes', 'Leaf Nodes'],\n",
    "            autopct='%1.1f%%', startangle=90,\n",
    "            colors=['lightcoral', 'lightgreen'])\n",
    "axes[1].set_title('Node Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluate on Test Set and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "cm, cr = perform_model_analysis(\n",
    "    model=dt_model,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    logger=logger,\n",
    "    model_name=\"DecisionTree\",\n",
    "    dir=os.getcwd(),\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "top_features = get_tree_feature_importance(\n",
    "    dt_model,\n",
    "    feature_names=list(dataset.data.columns),\n",
    "    top_n=15,\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "# Plot feature importance\n",
    "features, importances = zip(*top_features)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(features)))\n",
    "plt.barh(range(len(features)), importances, color=colors)\n",
    "plt.yticks(range(len(features)), features)\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.title('Top 15 Feature Importances', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Extract Decision Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.models.decision_tree.tree_rules import *\n",
    "# Use the correct feature names: drop the label column (e.g., 'Attack Type') if present\n",
    "feature_names = list(dataset.data.columns.drop('Attack Type'))\n",
    "rules = get_tree_rules(dt_model, feature_names, max_depth=3)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DECISION RULES (Top 3 Levels)\")\n",
    "print(\"=\"*70)\n",
    "print(rules)\n",
    "print(\"\\n... (tree continues deeper)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips for Improving Decision Tree Performance\n",
    "\n",
    "### To Reduce Overfitting:\n",
    "1. **Limit max_depth** - Prevents very deep, overfit trees\n",
    "2. **Increase min_samples_split** - Requires more samples before splitting\n",
    "3. **Increase min_samples_leaf** - Requires more samples at leaf nodes\n",
    "4. **Use max_features** - Adds randomness (closer to Random Forest)\n",
    "5. **Prune the tree** - Post-pruning using cost complexity pruning\n",
    "\n",
    "### To Improve Performance:\n",
    "1. **Use Random Forest** - Ensemble of trees usually performs better\n",
    "2. **Try criterion='entropy'** - May work better than 'gini' for some datasets\n",
    "3. **Feature engineering** - Create more informative features\n",
    "4. **Handle class imbalance** - Use class_weight='balanced' or SMOTE\n",
    "5. **Grid search** - Find optimal hyperparameters\n",
    "\n",
    "### Interpretability vs Performance:\n",
    "- **Shallow trees** (depth 5-10): More interpretable, may underfit\n",
    "- **Deep trees** (depth 20+): Better performance, less interpretable, may overfit\n",
    "- **Random Forest**: Best performance, harder to interpret"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
