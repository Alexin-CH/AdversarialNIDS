{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f8e7fa1",
   "metadata": {},
   "source": [
    "# Test du HSJ sur différents modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5b56f5",
   "metadata": {},
   "source": [
    "Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85fccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "root_dir = os.getcwd().split(\"AdversarialNIDS\")[0] + \"AdversarialNIDS\"\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from CICIDS2017.dataset import CICIDS2017\n",
    "from UNSWNB15.dataset import UNSWNB15\n",
    "\n",
    "from scripts.logger import SimpleLogger\n",
    "\n",
    "from art.attacks.evasion import HopSkipJump\n",
    "from art.estimators.classification import SklearnClassifier, PyTorchClassifier\n",
    "\n",
    "from NIDS_attacks.bounds_constrains import apply_bounds_constraints\n",
    "from NIDS_attacks.integers_constrains import apply_integer_constraints\n",
    "\n",
    "from scripts.models.decision_tree.decision_tree import train_decision_tree\n",
    "from scripts.models.random_forest.random_forest import train_random_forest\n",
    "from scripts.models.knn.knn import train_knn\n",
    "\n",
    "from scripts.analysis.model_analysis import perform_model_analysis\n",
    "\n",
    "from NIDS_attacks.hsj_attack_generalized import hsj_attack_generalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb75962",
   "metadata": {},
   "source": [
    "Import du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f203637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Downloading dataset: sweety18/cicids2017-full-dataset\n",
      "[INFO] Loading dataset into DataFrame\n",
      "[DEBUG] /home/loup/.cache/kagglehub/datasets/sweety18/cicids2017-full-dataset/versions/1/combine.csv\n",
      "[INFO] Loading dataset into DataFrame\n",
      "[DEBUG] /home/loup/.cache/kagglehub/datasets/sweety18/cicids2017-full-dataset/versions/1/combine.csv\n",
      "[INFO] Initial dimensions: 2,214,469 rows x 79 columns = 174,943,051 cells\n",
      "[DEBUG] Cleaning column names\n",
      "[INFO] Initial dimensions: 2,214,469 rows x 79 columns = 174,943,051 cells\n",
      "[DEBUG] Cleaning column names\n",
      "[DEBUG] Removing duplicate rows\n",
      "[DEBUG] Removing duplicate rows\n",
      "[DEBUG] Removed 271,598 duplicate rows. Remaining: 1,942,871\n",
      "[DEBUG] Removing rows with missing values (initial pass)\n",
      "[DEBUG] Removed 271,598 duplicate rows. Remaining: 1,942,871\n",
      "[DEBUG] Removing rows with missing values (initial pass)\n",
      "[DEBUG] Removed 178 rows with missing values. Remaining: 1,942,693\n",
      "[DEBUG] Checking for infinite values in numeric columns\n",
      "[DEBUG] Removed 178 rows with missing values. Remaining: 1,942,693\n",
      "[DEBUG] Checking for infinite values in numeric columns\n",
      "[DEBUG] Columns with infinite values:\n",
      "[DEBUG]   Flow Bytes/s: 1,041 infinite values\n",
      "[DEBUG]   Flow Packets/s: 1,041 infinite values\n",
      "[DEBUG] Missing values before processing infinite values: 0\n",
      "[DEBUG] Columns with infinite values:\n",
      "[DEBUG]   Flow Bytes/s: 1,041 infinite values\n",
      "[DEBUG]   Flow Packets/s: 1,041 infinite values\n",
      "[DEBUG] Missing values before processing infinite values: 0\n",
      "[DEBUG] Missing values after processing infinite values: 2,082\n",
      "[DEBUG] Infinite values converted to NaN: 2,082\n",
      "[DEBUG] Columns with missing values:\n",
      "[DEBUG]   Flow Bytes/s: 1,041 (0.05%)\n",
      "[DEBUG]   Flow Packets/s: 1,041 (0.05%)\n",
      "[DEBUG] Filling 1,041 missing values in 'Flow Bytes/s' with median: 4032.31\n",
      "[DEBUG] Filling 1,041 missing values in 'Flow Packets/s' with median: 65.62\n",
      "[DEBUG] Remaining missing values in 'Flow Bytes/s': 0\n",
      "[DEBUG] Remaining missing values in 'Flow Packets/s': 0\n",
      "[DEBUG] Missing values after processing infinite values: 2,082\n",
      "[DEBUG] Infinite values converted to NaN: 2,082\n",
      "[DEBUG] Columns with missing values:\n",
      "[DEBUG]   Flow Bytes/s: 1,041 (0.05%)\n",
      "[DEBUG]   Flow Packets/s: 1,041 (0.05%)\n",
      "[DEBUG] Filling 1,041 missing values in 'Flow Bytes/s' with median: 4032.31\n",
      "[DEBUG] Filling 1,041 missing values in 'Flow Packets/s' with median: 65.62\n",
      "[DEBUG] Remaining missing values in 'Flow Bytes/s': 0\n",
      "[DEBUG] Remaining missing values in 'Flow Packets/s': 0\n",
      "[DEBUG] Dropping 8 columns with only one unique value:\n",
      "[DEBUG]   Dropped column: Bwd PSH Flags\n",
      "[DEBUG]   Dropped column: Bwd URG Flags\n",
      "[DEBUG]   Dropped column: Fwd Avg Bytes/Bulk\n",
      "[DEBUG]   Dropped column: Fwd Avg Packets/Bulk\n",
      "[DEBUG]   Dropped column: Fwd Avg Bulk Rate\n",
      "[DEBUG]   Dropped column: Bwd Avg Bytes/Bulk\n",
      "[DEBUG]   Dropped column: Bwd Avg Packets/Bulk\n",
      "[DEBUG]   Dropped column: Bwd Avg Bulk Rate\n",
      "[DEBUG] Dropping 8 columns with only one unique value:\n",
      "[DEBUG]   Dropped column: Bwd PSH Flags\n",
      "[DEBUG]   Dropped column: Bwd URG Flags\n",
      "[DEBUG]   Dropped column: Fwd Avg Bytes/Bulk\n",
      "[DEBUG]   Dropped column: Fwd Avg Packets/Bulk\n",
      "[DEBUG]   Dropped column: Fwd Avg Bulk Rate\n",
      "[DEBUG]   Dropped column: Bwd Avg Bytes/Bulk\n",
      "[DEBUG]   Dropped column: Bwd Avg Packets/Bulk\n",
      "[DEBUG]   Dropped column: Bwd Avg Bulk Rate\n",
      "[INFO] ============================================================\n",
      "[INFO] Preprocessing completed successfully\n",
      "[INFO] Final dimensions: 1,940,693 rows x 71 columns\n",
      "[INFO] Total rows removed: 273,776 (12.36%)\n",
      "[INFO] data retention rate: 87.64%\n",
      "[INFO] ============================================================\n",
      "[INFO] Optimizing memory usage of the dataset...\n",
      "[INFO] Initial memory usage: 1066.05 MB\n",
      "[INFO] ============================================================\n",
      "[INFO] Preprocessing completed successfully\n",
      "[INFO] Final dimensions: 1,940,693 rows x 71 columns\n",
      "[INFO] Total rows removed: 273,776 (12.36%)\n",
      "[INFO] data retention rate: 87.64%\n",
      "[INFO] ============================================================\n",
      "[INFO] Optimizing memory usage of the dataset...\n",
      "[INFO] Initial memory usage: 1066.05 MB\n",
      "[INFO] Optimized memory usage: 555.24 MB\n",
      "[INFO] Memory reduction: 510.82 MB (47.92%)\n",
      "[INFO] Encoding attack labels...\n",
      "[DEBUG] Data Labels after encoding:\n",
      "[INFO] Optimized memory usage: 555.24 MB\n",
      "[INFO] Memory reduction: 510.82 MB (47.92%)\n",
      "[INFO] Encoding attack labels...\n",
      "[DEBUG] Data Labels after encoding:\n",
      "[DEBUG]   BENIGN: 1528113\n",
      "[DEBUG]   DoS: 193745\n",
      "[DEBUG]   DDoS: 128016\n",
      "[DEBUG]   PortScan: 90819\n",
      "[INFO] Attack labels encoded using LabelEncoder() encoder.\n",
      "[DEBUG]   BENIGN: 1528113\n",
      "[DEBUG]   DoS: 193745\n",
      "[DEBUG]   DDoS: 128016\n",
      "[DEBUG]   PortScan: 90819\n",
      "[INFO] Attack labels encoded using LabelEncoder() encoder.\n",
      "[INFO] Subsetting dataset to size: 10000...\n",
      "[INFO] Class distribution before subsetting:\n",
      "[INFO]   Class 0: 1528113 samples\n",
      "[INFO]   Class 1: 128016 samples\n",
      "[INFO]   Class 2: 193745 samples\n",
      "[INFO]   Class 3: 90819 samples\n",
      "[INFO] Subsetted dataset to size: 10000\n",
      "[INFO] Splitting dataset into training and testing sets...\n",
      "[INFO] Class distribution before SMOTE:\n",
      "[INFO]   Class 0.0: 1999 samples\n",
      "[INFO]   Class 1.0: 2004 samples\n",
      "[INFO]   Class 2.0: 2003 samples\n",
      "[INFO]   Class 3.0: 1994 samples\n",
      "[INFO] Class distribution after SMOTE:\n",
      "[INFO]   Class 0.0: 1999 samples\n",
      "[INFO]   Class 1.0: 2004 samples\n",
      "[INFO]   Class 2.0: 2003 samples\n",
      "[INFO]   Class 3.0: 1994 samples\n",
      "[INFO] Subsetting dataset to size: 10000...\n",
      "[INFO] Class distribution before subsetting:\n",
      "[INFO]   Class 0: 1528113 samples\n",
      "[INFO]   Class 1: 128016 samples\n",
      "[INFO]   Class 2: 193745 samples\n",
      "[INFO]   Class 3: 90819 samples\n",
      "[INFO] Subsetted dataset to size: 10000\n",
      "[INFO] Splitting dataset into training and testing sets...\n",
      "[INFO] Class distribution before SMOTE:\n",
      "[INFO]   Class 0.0: 1999 samples\n",
      "[INFO]   Class 1.0: 2004 samples\n",
      "[INFO]   Class 2.0: 2003 samples\n",
      "[INFO]   Class 3.0: 1994 samples\n",
      "[INFO] Class distribution after SMOTE:\n",
      "[INFO]   Class 0.0: 1999 samples\n",
      "[INFO]   Class 1.0: 2004 samples\n",
      "[INFO]   Class 2.0: 2003 samples\n",
      "[INFO]   Class 3.0: 1994 samples\n"
     ]
    }
   ],
   "source": [
    "ds = CICIDS2017().optimize_memory().encode()\n",
    "#ds = UNSWNB15().optimize_memory().encode()\n",
    "ds = ds.subset(size=10000, multi_class=True)\n",
    "X_train, X_test, y_train, y_test = ds.split(test_size=0.2, apply_smote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548d3cfa",
   "metadata": {},
   "source": [
    "Choix des contraintes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5f4000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_indices = [0, 2, 5, 10, 15] # Exemple\n",
    "modifiable_indices = list(range(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba36873",
   "metadata": {},
   "source": [
    "## 1.Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e49b2f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting Generalized HopSkipJump attack on CICIDS2017\n",
      "[INFO] Using targeted class: 0\n",
      "[INFO] Applying constraints with 20 modifiable features\n",
      "[INFO] Integer constraints on 5 features\n",
      "[INFO] Initial accuracy: 0.994\n",
      "[INFO] Attacking 20 attack samples to make them appear benign...\n",
      "[INFO] Target classes being attacked: [1. 2. 3.]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa66f7c388ee4f50b71ef8a3b934e656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HopSkipJump:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] === Attack Results ===\n",
      "[INFO] Original accuracy on attack samples: 1.000\n",
      "[INFO] Adversarial accuracy on attack samples: 0.650\n",
      "[INFO] Attack success rate (attacks -> benign): 0.000\n",
      "[INFO] Average L2 perturbation: 0.533575\n",
      "[INFO] Constraints applied: bounds + 5 integer features\n",
      "[INFO] \n",
      "Summary: Attack succeeded 0.0% of the time\n"
     ]
    }
   ],
   "source": [
    "model_dt, _ = train_decision_tree(X_train, y_train, max_depth=10)\n",
    "\n",
    "results_dt = hsj_attack_generalized(\n",
    "        model=model_dt,\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "        dataset=\"CICIDS2017\",\n",
    "        #dataset=\"UNSWNB15\",\n",
    "        nb_samples=20,  # Réduire pour les tests\n",
    "        integer_indices=integer_indices,\n",
    "        modifiable_indices=modifiable_indices,\n",
    "        apply_constraints=True,\n",
    "        per_sample_visualization=False  # Désactiver pour réduire le bruit\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "010fbbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running analysis for scikit-learn model: Decision Tree - Dataset Original\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAxisError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m logger = SimpleLogger()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m cm_orig, report_orig = \u001b[43mperform_model_analysis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_dt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDecision Tree - Dataset Original\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_fig\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m \u001b[38;5;66;03m# Does not work\u001b[39;00m\n\u001b[32m     12\u001b[39m cm_adv, report_adv = perform_model_analysis(\n\u001b[32m     13\u001b[39m     model=model_dt,\n\u001b[32m     14\u001b[39m     X_test=results[\u001b[33m'\u001b[39m\u001b[33mX_adv\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m \n\u001b[32m     21\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/2A_TELECOM/Programmation/Projet_d_application/AdversarialNIDS/scripts/analysis/model_analysis.py:51\u001b[39m, in \u001b[36mperform_model_analysis\u001b[39m\u001b[34m(model, X_test, y_test, root_dir, logger, title, plot, save_fig, device)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     50\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning analysis for scikit-learn model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     y_true = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m     y_pred = model.predict(X_test).argmax(axis=\u001b[32m1\u001b[39m)\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Calculate metrics\u001b[39;00m\n",
      "\u001b[31mAxisError\u001b[39m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "logger = SimpleLogger()\n",
    "cm_orig, report_orig = perform_model_analysis(\n",
    "    model=model_dt,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    logger=logger,\n",
    "    title=\"Decision Tree - Dataset Original\",\n",
    "    plot=True,\n",
    "    save_fig=False\n",
    ") # Does not work\n",
    "\n",
    "cm_adv, report_adv = perform_model_analysis(\n",
    "    model=model_dt,\n",
    "    X_test=results['X_adv'],\n",
    "    y_test=results['y_attacks'],\n",
    "    logger=logger,\n",
    "    title=\"Decision Tree - Dataset Adverserial\",\n",
    "    plot=True,\n",
    "    save_fig=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a08a05d",
   "metadata": {},
   "source": [
    "## 2.Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2e5a54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting Generalized HopSkipJump attack on CICIDS2017\n",
      "[INFO] Using targeted class: 0\n",
      "[INFO] Applying constraints with 20 modifiable features\n",
      "[INFO] Integer constraints on 5 features\n",
      "[INFO] Initial accuracy: 0.997\n",
      "[INFO] Attacking 10 attack samples to make them appear benign...\n",
      "[INFO] Target classes being attacked: [1. 2. 3.]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b5692624a948149db86e3c1cdfbd81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HopSkipJump:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] === Attack Results ===\n",
      "[INFO] Original accuracy on attack samples: 1.000\n",
      "[INFO] Adversarial accuracy on attack samples: 1.000\n",
      "[INFO] Attack success rate (attacks -> benign): 0.000\n",
      "[INFO] Average L2 perturbation: 22.698642\n",
      "[INFO] Constraints applied: bounds + 5 integer features\n",
      "[INFO] === Per-Sample Analysis ===\n",
      "[INFO] Sample 1: Class 1.0 -> Original pred: 1.0 -> Adversarial pred: 1.0\n",
      "[INFO] Sample 2: Class 1.0 -> Original pred: 1.0 -> Adversarial pred: 1.0\n",
      "[INFO] Sample 3: Class 1.0 -> Original pred: 1.0 -> Adversarial pred: 1.0\n",
      "[INFO] Sample 4: Class 3.0 -> Original pred: 3.0 -> Adversarial pred: 3.0\n",
      "[INFO] Sample 5: Class 2.0 -> Original pred: 2.0 -> Adversarial pred: 2.0\n",
      "[INFO] Sample 6: Class 1.0 -> Original pred: 1.0 -> Adversarial pred: 1.0\n",
      "[INFO] Sample 7: Class 2.0 -> Original pred: 2.0 -> Adversarial pred: 2.0\n",
      "[INFO] Sample 8: Class 1.0 -> Original pred: 1.0 -> Adversarial pred: 1.0\n",
      "[INFO] Sample 9: Class 3.0 -> Original pred: 3.0 -> Adversarial pred: 3.0\n",
      "[INFO] Sample 10: Class 1.0 -> Original pred: 1.0 -> Adversarial pred: 1.0\n",
      "[INFO] \n",
      "Summary: Attack succeeded 0.0% of the time\n"
     ]
    }
   ],
   "source": [
    "model_rf, _ = train_random_forest(X_train, y_train, n_estimators=50, max_depth=10)\n",
    "\n",
    "results_rf = hsj_attack_generalized(\n",
    "        model=model_rf,\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "        dataset=\"CICIDS2017\",\n",
    "        #dataset=\"UNSWNB15\",\n",
    "        nb_samples=10,\n",
    "        integer_indices=integer_indices,\n",
    "        modifiable_indices=modifiable_indices,\n",
    "        apply_constraints=True,\n",
    "        per_sample_visualization=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7be9c4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running analysis for scikit-learn model: Random Forest - Dataset Original\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAxisError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m logger = SimpleLogger()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m cm_orig, report_orig = \u001b[43mperform_model_analysis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_rf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRandom Forest - Dataset Original\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_fig\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m \u001b[38;5;66;03m# Does not work\u001b[39;00m\n\u001b[32m     12\u001b[39m cm_adv, report_adv = perform_model_analysis(\n\u001b[32m     13\u001b[39m     model=model_rf,\n\u001b[32m     14\u001b[39m     X_test=results_rf[\u001b[33m'\u001b[39m\u001b[33mX_adv\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     save_fig=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     20\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/2A_TELECOM/Programmation/Projet_d_application/AdversarialNIDS/scripts/analysis/model_analysis.py:51\u001b[39m, in \u001b[36mperform_model_analysis\u001b[39m\u001b[34m(model, X_test, y_test, root_dir, logger, title, plot, save_fig, device)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     50\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning analysis for scikit-learn model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     y_true = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m     y_pred = model.predict(X_test).argmax(axis=\u001b[32m1\u001b[39m)\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Calculate metrics\u001b[39;00m\n",
      "\u001b[31mAxisError\u001b[39m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "logger = SimpleLogger()\n",
    "cm_orig, report_orig = perform_model_analysis(\n",
    "    model=model_rf,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    logger=logger,\n",
    "    title=\"Random Forest - Dataset Original\",\n",
    "    plot=True,\n",
    "    save_fig=False\n",
    ") # Does not work\n",
    "\n",
    "cm_adv, report_adv = perform_model_analysis(\n",
    "    model=model_rf,\n",
    "    X_test=results_rf['X_adv'],\n",
    "    y_test=results_rf['y_attacks'],\n",
    "    logger=logger,\n",
    "    title=\"Random Forest - Dataset Adverserial\",\n",
    "    plot=True,\n",
    "    save_fig=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc5442f",
   "metadata": {},
   "source": [
    "## 3.KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6615dcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting Generalized HopSkipJump attack on CICIDS2017\n",
      "[INFO] Using targeted class: 0\n",
      "[INFO] Applying constraints with 20 modifiable features\n",
      "[INFO] Integer constraints on 5 features\n",
      "[INFO] Initial accuracy: 0.947\n",
      "[INFO] Attacking 10 attack samples to make them appear benign...\n",
      "[INFO] Target classes being attacked: [1. 2. 3.]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639c47b8354a4dcfb7eebcb57b5bbe57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HopSkipJump:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_knn, _ = train_knn(X_train, y_train, n_neighbors=5)\n",
    "\n",
    "results_knn = hsj_attack_generalized(\n",
    "        model=model_knn,\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "        dataset=\"CICIDS2017\",\n",
    "        #dataset=\"UNSWNB15\",\n",
    "        nb_samples=10,\n",
    "        integer_indices=integer_indices,\n",
    "        modifiable_indices=modifiable_indices,\n",
    "        apply_constraints=True,\n",
    "        per_sample_visualization=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b04d1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = SimpleLogger()\n",
    "cm_orig, report_orig = perform_model_analysis(\n",
    "    model=model_knn,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    logger=logger,\n",
    "    title=\"K-Nearest Neighbors - Dataset Original\",\n",
    "    plot=True,\n",
    "    save_fig=False\n",
    ") # Does not work\n",
    "\n",
    "cm_adv, report_adv = perform_model_analysis(\n",
    "    model=model_rf,\n",
    "    X_test=results_knn['X_adv'],\n",
    "    y_test=results_knn['y_attacks'],\n",
    "    logger=logger,\n",
    "    title=\"K-Nearest Neighbors - Dataset Adverserial\",\n",
    "    plot=True,\n",
    "    save_fig=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
