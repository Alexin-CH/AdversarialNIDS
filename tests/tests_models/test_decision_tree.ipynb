{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Training on CICIDS2017 Dataset\n",
    "\n",
    "This notebook trains a Decision Tree classifier on the CICIDS2017 intrusion detection dataset.\n",
    "\n",
    "**Key Features:**\n",
    "- SMOTE balancing applied within CV pipeline\n",
    "- Tree complexity analysis\n",
    "- Feature importance visualization\n",
    "- Decision rules extraction\n",
    "- Hyperparameter tuning\n",
    "- Tree visualization\n",
    "\n",
    "**Advantages of Decision Trees:**\n",
    "- Fast training and prediction\n",
    "- Interpretable results\n",
    "- Handles non-linear relationships\n",
    "- No feature scaling required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', '..')))\n",
    "\n",
    "from CICIDS2017.preprocessing.dataset import CICIDS2017\n",
    "# Import shared utilities\n",
    "from scripts.models.model_utils import (\n",
    "    prepare_data,\n",
    "    evaluate_model,\n",
    "    check_data_leakage,\n",
    "    get_feature_importance,\n",
    "    balance_classes_info,\n",
    "    remove_rare_classes,\n",
    "    print_performance_summary,\n",
    "    remove_low_variance_features\n",
    ")\n",
    "\n",
    "# Import model-specific modules\n",
    "from scripts.models.decision_tree.decision_tree import train_decision_tree\n",
    "\n",
    "from scripts.logger import LoggerManager\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úì Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = LoggerManager(log_name=\"dt_notebook\").get_logger()\n",
    "logger.info(\"Starting Decision Tree training notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "logger.info(\"Loading CICIDS2017 dataset...\")\n",
    "dataset = CICIDS2017(logger=logger)\n",
    "dataset.encode().optimize_memory()\n",
    "data = dataset.data\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision trees are fast, so we can use a larger sample\n",
    "SAMPLE_SIZE = 200000\n",
    "\n",
    "logger.info(f\"Sampling {SAMPLE_SIZE} rows from dataset...\")\n",
    "data_sample = data.sample(n=min(SAMPLE_SIZE, len(data)), random_state=0)\n",
    "\n",
    "print(f\"Sampled data shape: {data_sample.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and labels\n",
    "X = data_sample.drop('Attack Type', axis=1)\n",
    "y = data_sample['Attack Type']\n",
    "\n",
    "# Remove known leakage features\n",
    "leakage_features = ['Attack Number']\n",
    "existing_leakage = [f for f in leakage_features if f in X.columns]\n",
    "\n",
    "if existing_leakage:\n",
    "    logger.warning(f\"üö® REMOVING LEAKAGE FEATURES: {existing_leakage}\")\n",
    "    X = X.drop(columns=existing_leakage)\n",
    "\n",
    "# Convert to numeric\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Handle missing values\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    n_missing = X.isnull().sum().sum()\n",
    "    logger.info(f\"Filling {n_missing} missing values with 0\")\n",
    "    X = X.fillna(0)\n",
    "\n",
    "# Remove low variance features\n",
    "X, removed_features = remove_low_variance_features(X, threshold=0.01, logger=logger)\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "y.value_counts().plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.title('Class Distribution (Before SMOTE)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Attack Type', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Leakage Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostics = check_data_leakage(X, y, logger=logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove classes with fewer than 2 samples\n",
    "class_counts = y.value_counts()\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "X = X[y.isin(valid_classes)]\n",
    "y = y[y.isin(valid_classes)]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.25,\n",
    "    random_state=0,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create Decision Tree and SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE before training (outside pipeline)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"SMOTE-applied data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack model and CV scores from train_decision_tree\n",
    "dt_model, cv_scores = train_decision_tree(\n",
    "    X_train_res,\n",
    "    y_train_res,\n",
    "    max_depth=3,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    criterion='gini',\n",
    "    max_features=None,\n",
    "    class_weight='balanced',\n",
    "    random_state=0,\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CROSS-VALIDATION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"CV Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
    "\n",
    "# Plot CV scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(cv_scores)+1), cv_scores, marker='o', markersize=10, linewidth=2, color='green')\n",
    "plt.axhline(y=cv_scores.mean(), color='r', linestyle='--', \n",
    "            label=f'Mean: {cv_scores.mean():.4f}')\n",
    "plt.xlabel('Fold', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('Decision Tree Cross-Validation Scores', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Train Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on full training set\n",
    "logger.info(\"Training final model on full training set...\")\n",
    "start_time = time()\n",
    "\n",
    "dt_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "training_time = time() - start_time\n",
    "\n",
    "print(f\"‚úì Model training completed in {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Analyze Tree Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.models.decision_tree.analyze_tree import analyze_tree_complexity \n",
    "# Analyze tree complexity\n",
    "complexity = analyze_tree_complexity(dt_model, logger=logger)\n",
    "\n",
    "# Visualize complexity\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart of tree metrics\n",
    "metrics = ['Total Nodes', 'Leaf Nodes', 'Max Depth', 'Features Used']\n",
    "values = [complexity['n_nodes'], complexity['n_leaves'], \n",
    "          complexity['max_depth'], complexity['n_features_used']]\n",
    "\n",
    "axes[0].bar(metrics, values, color=['skyblue', 'lightgreen', 'salmon', 'gold'])\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].set_title('Tree Complexity Metrics', fontsize=14, fontweight='bold')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Pie chart of node distribution\n",
    "internal_nodes = complexity['n_nodes'] - complexity['n_leaves']\n",
    "axes[1].pie([internal_nodes, complexity['n_leaves']], \n",
    "            labels=['Internal Nodes', 'Leaf Nodes'],\n",
    "            autopct='%1.1f%%', startangle=90,\n",
    "            colors=['lightcoral', 'lightgreen'])\n",
    "axes[1].set_title('Node Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "results = evaluate_model(dt_model, X_test, y_test, logger=logger)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Test Accuracy: {results['accuracy']:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(results['report'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=results['confusion_matrix'],\n",
    "                               display_labels=dt_model.classes_)\n",
    "disp.plot(cmap='Greens', xticks_rotation=45)\n",
    "plt.title('Decision Tree Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "top_features = get_feature_importance(\n",
    "    dt_model,\n",
    "    feature_names=list(X.columns),\n",
    "    top_n=15,\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "# Plot feature importance\n",
    "features, importances = zip(*top_features)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(features)))\n",
    "plt.barh(range(len(features)), importances, color=colors)\n",
    "plt.yticks(range(len(features)), features)\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.title('Top 15 Feature Importances', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Extract Decision Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.models.decision_tree.tree_rules import *\n",
    "rules = get_tree_rules(dt_model, feature_names=list(X.columns), max_depth=3)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DECISION RULES (Top 3 Levels)\")\n",
    "print(\"=\"*70)\n",
    "print(rules)\n",
    "print(\"\\n... (tree continues deeper)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Visualize Tree (Top Levels)\n",
    "\n",
    "We'll visualize only the top levels of the tree for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the tree (top 3 levels only)\n",
    "dt_model = dt_model.named_steps['dt']\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(\n",
    "    dt_model,\n",
    "    feature_names=list(X.columns),\n",
    "    class_names=[str(c) for c in dt_model.classes_],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    max_depth=3,  # Only show top 3 levels\n",
    "    fontsize=10\n",
    ")\n",
    "plt.title('Decision Tree Visualization (Top 3 Levels)', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìù Note: Full tree has {complexity['max_depth']} levels. \")\n",
    "print(f\"   Only showing top 3 levels for clarity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Mean CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
    "print(f\"Test Accuracy: {results['accuracy']:.4f}\")\n",
    "print(f\"\\nModel Configuration:\")\n",
    "print(f\"  - Max depth: {dt_model.named_steps['dt'].max_depth}\")\n",
    "print(f\"  - Criterion: {dt_model.named_steps['dt'].criterion}\")\n",
    "print(f\"  - Min samples split: {dt_model.named_steps['dt'].min_samples_split}\")\n",
    "print(f\"  - Min samples leaf: {dt_model.named_steps['dt'].min_samples_leaf}\")\n",
    "print(f\"  - SMOTE: Enabled\")\n",
    "print(f\"\\nTree Complexity:\")\n",
    "print(f\"  - Total nodes: {complexity['n_nodes']}\")\n",
    "print(f\"  - Leaf nodes: {complexity['n_leaves']}\")\n",
    "print(f\"  - Actual depth: {complexity['max_depth']}\")\n",
    "print(f\"  - Features used: {complexity['n_features_used']}/{X.shape[1]}\")\n",
    "print(f\"\\nTiming:\")\n",
    "print(f\"  - Training time: {training_time:.2f}s\")\n",
    "\n",
    "# Performance indicators\n",
    "if cv_scores.mean() > 0.99:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: CV score > 0.99 may indicate data leakage or overfitting!\")\n",
    "elif cv_scores.mean() >= 0.95:\n",
    "    print(\"\\n‚úì Excellent performance achieved (CV score ‚â• 0.95)\")\n",
    "elif cv_scores.mean() >= 0.90:\n",
    "    print(\"\\n‚úì Good performance achieved (CV score ‚â• 0.90)\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Performance below 0.90\")\n",
    "    print(\"   Consider:\")\n",
    "    print(\"   - Increasing max_depth\")\n",
    "    print(\"   - Decreasing min_samples_split/min_samples_leaf\")\n",
    "    print(\"   - Trying criterion='entropy' instead of 'gini'\")\n",
    "    print(\"   - Using Random Forest instead (ensemble of trees)\")\n",
    "\n",
    "# Check for overfitting\n",
    "if abs(cv_scores.mean() - results['accuracy']) > 0.05:\n",
    "    print(\"\\n‚ö†Ô∏è  Warning: Large gap between CV and test accuracy\")\n",
    "    print(f\"   CV: {cv_scores.mean():.4f}, Test: {results['accuracy']:.4f}\")\n",
    "    print(\"   This may indicate overfitting. Consider:\")\n",
    "    print(\"   - Reducing max_depth\")\n",
    "    print(\"   - Increasing min_samples_split/min_samples_leaf\")\n",
    "    print(\"   - Using max_features to add randomness\")\n",
    "\n",
    "logger.info(\"Notebook execution completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips for Improving Decision Tree Performance\n",
    "\n",
    "### To Reduce Overfitting:\n",
    "1. **Limit max_depth** - Prevents very deep, overfit trees\n",
    "2. **Increase min_samples_split** - Requires more samples before splitting\n",
    "3. **Increase min_samples_leaf** - Requires more samples at leaf nodes\n",
    "4. **Use max_features** - Adds randomness (closer to Random Forest)\n",
    "5. **Prune the tree** - Post-pruning using cost complexity pruning\n",
    "\n",
    "### To Improve Performance:\n",
    "1. **Use Random Forest** - Ensemble of trees usually performs better\n",
    "2. **Try criterion='entropy'** - May work better than 'gini' for some datasets\n",
    "3. **Feature engineering** - Create more informative features\n",
    "4. **Handle class imbalance** - Use class_weight='balanced' or SMOTE\n",
    "5. **Grid search** - Find optimal hyperparameters\n",
    "\n",
    "### Interpretability vs Performance:\n",
    "- **Shallow trees** (depth 5-10): More interpretable, may underfit\n",
    "- **Deep trees** (depth 20+): Better performance, less interpretable, may overfit\n",
    "- **Random Forest**: Best performance, harder to interpret"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
