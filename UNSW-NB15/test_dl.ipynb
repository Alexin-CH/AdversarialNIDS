{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d412408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "sys.path.append(os.path.join(current_dir, \"..\"))\n",
    "\n",
    "from scripts.logger import LoggerManager\n",
    "from scripts.generaldataset import UNSWNB15\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9926f92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:54:14,145 - INFO - Logger initialized\n",
      "2025-11-17 11:54:14,148 - INFO - Downloading dataset: mrwellsdavid/unsw-nb15\n",
      "2025-11-17 11:54:15,186 - INFO - Loading data\n",
      "c:\\msys64\\home\\valen\\TDpython\\AdversarialNIDS\\UNSW-NB15\\..\\scripts\\generaldownload.py:54: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[\"Attack Type\"].fillna(\"Benign\", inplace=True)\n",
      "2025-11-17 11:54:24,313 - INFO - Initial dimensions: 700,000 rows x 46 columns = 32,200,000 cells\n",
      "2025-11-17 11:54:29,074 - INFO - ============================================================\n",
      "2025-11-17 11:54:29,076 - INFO - Preprocessing completed successfully\n",
      "2025-11-17 11:54:29,077 - INFO - Final dimensions: 640,658 rows x 46 columns\n",
      "2025-11-17 11:54:29,079 - INFO - Total rows removed: 59,342 (8.48%)\n",
      "2025-11-17 11:54:29,080 - INFO - data retention rate: 91.52%\n",
      "2025-11-17 11:54:29,081 - INFO - ============================================================\n",
      "2025-11-17 11:54:29,084 - INFO - Encoding attack labels...\n",
      "2025-11-17 11:54:29,709 - INFO - Attack labels encoded using OneHotEncoder(sparse_output=False) encoder.\n",
      "2025-11-17 11:54:29,710 - INFO - Scaling dataset features...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        sport dsport  proto  state       dur  sbytes   dbytes  sttl  dttl  \\\n",
      "0       33661   1024    120      2  0.036133     528      304    31    29   \n",
      "1        1464     53    120      2  0.001119     146      178    31    29   \n",
      "2        3593     53    120      2  0.001209     132      164    31    29   \n",
      "3       49664     53    120      2  0.001169     146      178    31    29   \n",
      "4       32119    111    120      2  0.078339     568      312    31    29   \n",
      "...       ...    ...    ...    ...       ...     ...      ...   ...   ...   \n",
      "699995  12520  31010    114      5  0.020383     320     1874    31    29   \n",
      "699996  18895     80    114      5  1.402957   19410  1087890    31    29   \n",
      "699997  30103   5190    114      5  0.007108    2158     2464    31    29   \n",
      "699998  30388    111    120      2  0.004435     568      304    31    29   \n",
      "699999   6055  54145    114      5  0.072974    4238    60788    31    29   \n",
      "\n",
      "        sloss  ...  ct_flw_http_mthd  is_ftp_login  ct_ftp_cmd  ct_srv_src  \\\n",
      "0           0  ...                 0             0           0           2   \n",
      "1           0  ...                 0             0           0          12   \n",
      "2           0  ...                 0             0           0           6   \n",
      "3           0  ...                 0             0           0           7   \n",
      "4           0  ...                 0             0           0           2   \n",
      "...       ...  ...               ...           ...         ...         ...   \n",
      "699995      1  ...                 0             0           0           8   \n",
      "699996      2  ...                 4             0           0           1   \n",
      "699997      6  ...                 0             0           0          13   \n",
      "699998      0  ...                 0             0           0          10   \n",
      "699999      7  ...                 0             0           0          13   \n",
      "\n",
      "        ct_srv_dst  ct_dst_ltm  ct_src_ltm  ct_src_dport_ltm  \\\n",
      "0                4           2           3                 1   \n",
      "1                8           1           2                 2   \n",
      "2                9           1           1                 1   \n",
      "3                9           1           1                 1   \n",
      "4                4           2           3                 1   \n",
      "...            ...         ...         ...               ...   \n",
      "699995          20           7           5                 1   \n",
      "699996           1           2           7                 2   \n",
      "699997          13           6           7                 2   \n",
      "699998          13           6           5                 1   \n",
      "699999          13           6           7                 1   \n",
      "\n",
      "        ct_dst_sport_ltm  ct_dst_src_ltm  \n",
      "0                      1               2  \n",
      "1                      1               1  \n",
      "2                      1               1  \n",
      "3                      1               1  \n",
      "4                      1               2  \n",
      "...                  ...             ...  \n",
      "699995                 1               4  \n",
      "699996                 2               2  \n",
      "699997                 1               2  \n",
      "699998                 1               3  \n",
      "699999                 1               2  \n",
      "\n",
      "[640658 rows x 45 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '0x000b'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_13360\\2028396328.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m lm = LoggerManager(log_dir=f\"{current_dir}/logs\", log_name=\u001b[33m\"test_dl_models\"\u001b[39m)\n\u001b[32m      2\u001b[39m lm.logger.info(\u001b[33m\"Logger initialized\"\u001b[39m)\n\u001b[32m      3\u001b[39m \n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m dataset = UNSWNB15(logger=lm.logger).encode(attack_encoder=\u001b[33m\"onehot\"\u001b[39m).scale(scaler=\u001b[33m\"minmax\"\u001b[39m).optimize_memory()\n",
      "\u001b[32mc:\\msys64\\home\\valen\\TDpython\\AdversarialNIDS\\UNSW-NB15\\..\\scripts\\generaldataset.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, scaler, logger)\u001b[39m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m scale(self, scaler=\u001b[33m\"standard\"\u001b[39m, logger=SimpleLogger()):\n\u001b[32m     64\u001b[39m         \u001b[33m\"\"\" Scale the dataset features using the provided scaler. \"\"\"\u001b[39m\n\u001b[32m     65\u001b[39m         self.logger.info(\u001b[33m\"Scaling dataset features...\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m         self.scaled_features = scale(self.data, scaler=scaler, logger=self.logger)\n\u001b[32m     67\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self\n",
      "\u001b[32mc:\\msys64\\home\\valen\\TDpython\\AdversarialNIDS\\UNSW-NB15\\..\\scripts\\general_scaling.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(data, scaler, logger)\u001b[39m\n\u001b[32m     19\u001b[39m \n\u001b[32m     20\u001b[39m     scaler = available_scalers[scaler]\n\u001b[32m     21\u001b[39m     features = data.drop(columns=[\u001b[33m'Attack Type'\u001b[39m])\n\u001b[32m     22\u001b[39m     print(features)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     scaled_features = scaler.fit_transform(features)\n\u001b[32m     24\u001b[39m \n\u001b[32m     25\u001b[39m     logger.info(f\"Features scaled using {scaler} scaler.\")\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m scaled_features\n",
      "\u001b[32mc:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m     @wraps(f)\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m wrapped(self, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m         data_to_wrap = f(self, X, *args, **kwargs)\n\u001b[32m    317\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m isinstance(data_to_wrap, tuple):\n\u001b[32m    318\u001b[39m             \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m             return_tuple = (\n",
      "\u001b[32mc:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    888\u001b[39m                 )\n\u001b[32m    889\u001b[39m \n\u001b[32m    890\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    891\u001b[39m             \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m892\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, **fit_params).transform(X)\n\u001b[32m    893\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    894\u001b[39m             \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    895\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[32mc:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    450\u001b[39m             Fitted scaler.\n\u001b[32m    451\u001b[39m         \"\"\"\n\u001b[32m    452\u001b[39m         \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    453\u001b[39m         self._reset()\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self.partial_fit(X, y)\n",
      "\u001b[32mc:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1359\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m                 )\n\u001b[32m   1362\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32mc:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    490\u001b[39m \n\u001b[32m    491\u001b[39m         xp, _ = get_namespace(X)\n\u001b[32m    492\u001b[39m \n\u001b[32m    493\u001b[39m         first_pass = \u001b[38;5;28;01mnot\u001b[39;00m hasattr(self, \u001b[33m\"n_samples_seen_\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m         X = validate_data(\n\u001b[32m    495\u001b[39m             self,\n\u001b[32m    496\u001b[39m             X,\n\u001b[32m    497\u001b[39m             reset=first_pass,\n",
      "\u001b[32mc:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2950\u001b[39m             out = y\n\u001b[32m   2951\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2952\u001b[39m             out = X, y\n\u001b[32m   2953\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2954\u001b[39m         out = check_array(X, input_name=\u001b[33m\"X\"\u001b[39m, **check_params)\n\u001b[32m   2955\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2956\u001b[39m         out = _check_y(y, **check_params)\n\u001b[32m   2957\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32mc:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1050\u001b[39m                         )\n\u001b[32m   1051\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1052\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1053\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1055\u001b[39m                 raise ValueError(\n\u001b[32m   1056\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1057\u001b[39m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m complex_warning\n",
      "\u001b[32mc:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    754\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    755\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    756\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    758\u001b[39m \n\u001b[32m    759\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    760\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32mc:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2164\u001b[39m             )\n\u001b[32m   2165\u001b[39m         values = self._values\n\u001b[32m   2166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2167\u001b[39m             \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2168\u001b[39m             arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2169\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2170\u001b[39m             arr = np.array(values, dtype=dtype, copy=copy)\n\u001b[32m   2171\u001b[39m \n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: '0x000b'"
     ]
    }
   ],
   "source": [
    "lm = LoggerManager(log_dir=f\"{current_dir}/logs\", log_name=\"test_dl_models\")\n",
    "lm.logger.info(\"Logger initialized\")\n",
    "\n",
    "dataset = UNSWNB15(logger=lm.logger).encode(attack_encoder=\"onehot\").scale(scaler=\"minmax\").optimize_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caffb21c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
