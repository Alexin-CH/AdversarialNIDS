{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqiP1ftFazMG"
      },
      "source": [
        "# **Analysis of the Intrusion Detection Evaluation Dataset (CIC-IDS2017)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxU8-WULcl3P"
      },
      "source": [
        "## 1. An overview of the Dataset including the Dataset Characteristics and Exploratory Data Analysis, Data Preprocessing, and performance of different models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJU7_XXQeRCW"
      },
      "source": [
        "- **Dataset Characteristics:** CIC-IDS2017 dataset contains network traffic data for the development and evaluation of intrusion detection systems. The dataset is designed to be representative of modern network traffic and includes more than 2.8 million network packets captured over a period of seven days in a real network environment. The dataset includes normal traffic and seven different attack scenarios: Brute Force, Heartbleed, Botnet, DoS, DDoS, Web Attack and Infiltration. The dataset is highly imbalanced. The majority of records belongs to the 'Benign' class and relatively few records belongs to the other classes. The dataset consists of 2830743 rows and 79 columns. In these columns, 78 of them are features that are numerical and the 'label' column is categorical.\n",
        "\n",
        "- **Exploratory Data Analysis:** This dataset have many duplicate values (308381), which creates bias that is not good for the machine learning model. The number of missing values and infinite values on two columns 'Flow Bytes/s' and 'Flow Packets/s' are very few comparing to the size of the dataset which is only 0.06% (1564). However, the values were handled using appropriate methods.\n",
        "\n",
        "- **Data Preprocessing:** We dropped the duplicates, replaced any infinite values (positive or negative) with NaN (not a number) and filled the missing values with median values. Since we have a very large dataset, the initial memory usage is quite high leading to session crashes. We later worked our way through this by down casting data types based on the min and max values available. We try to reduce the memory usages that is helpful for our model.\n",
        "\n",
        "- **Data Analysis:** We grouped similar attacks together to analyze the dataset and identify patterns in the different types of attacks. We took a sample from the population (20%). Later we did some data analysis which consist of plotting various kinds of charts, correlation matrices etc. to see the relationships between features, types of attacks present in the dataset etc. In our analysis, we noticed there are a good number of features that are strongly, even directly correlated with other features (both positive and negative). This is an issue it introduces multi-collinearity which can highly impact the machine learning models that we will develop later.\n",
        "\n",
        "  Also, as the dataset is quite huge and has more than 70 features, it would be extremely difficult to train models using limited resources. In order to overcome this issue, we used PCA (Principal Component Analysis) to reduece dimensions. We played with the number of components to see how much information we can preserve. We monitored the '*explained_variance_ratio_*' to make sure we retain most informations. However, it was a bit challenging to reduce dimensions while preserving the information to train the models. We performed StandardScaler before performing Incremental PCA.\n",
        "\n",
        "- **ML Models:** It is worth mentioning the fact that the following dataset is highly imbalanced. So, we created a balanced dataset out of this with our domain knowledge to train various ML models. Since our dataset is quite large and has a reasonable amount of samples to train and test different ML models using various classification algorithms (Logistic Regression, Support Vector Machine for Binary Classification and Random Forest Classifier, Decision Tree, K Nearest Neighbours for Multi-class Classification).\n",
        "\n",
        "  For binary classifications, we trained the models to distinguish between normal traffic and anomalous traffic. This means it will only predict whether an intrusion is taking place or not. Alternatively, using the multi-class classification algorithms, we further extended our prediction capabilities to identify which type of attack or intrusion is taking place. We tried both binary classifications and multi-class classifications to see how the data holds up. Later we cross-validated, evaluated and compared those models to see which one works better or worse.\n",
        "\n",
        "- **Performance Evaluation:** After training multiple machine learning models, we proceeded to evaluate their respective performances. Our evaluation process involved comparing the accuracy, recall, f1-score and confusion matrix of each model. Through analysis of the results, we were able to see which model performed the best and which performed worse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download Link\n",
        "\n",
        "[CIC-IDS2017 Dataset](http://cicresearch.ca/CICDataset/CIC-IDS-2017/Dataset/CIC-IDS-2017/CSVs/MachineLearningCSV.zip)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPwNIskNhEHI"
      },
      "source": [
        "## 2.\tDataset Characteristics and Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8DGk4gEhiJp"
      },
      "source": [
        "### 2.1 Load, View Data and Show Analysis on Rows and Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zZZzVucCEfoi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "sns.set(style='darkgrid')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "current_dir = os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g-Ma89nNhldR"
      },
      "outputs": [],
      "source": [
        "# Loading the dataset\n",
        "data1 = pd.read_csv(f'{current_dir}/MachineLearningCVE/Monday-WorkingHours.pcap_ISCX.csv')\n",
        "data2 = pd.read_csv(f'{current_dir}/MachineLearningCVE/Tuesday-WorkingHours.pcap_ISCX.csv')\n",
        "data3 = pd.read_csv(f'{current_dir}/MachineLearningCVE/Wednesday-workingHours.pcap_ISCX.csv')\n",
        "data4 = pd.read_csv(f'{current_dir}/MachineLearningCVE/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv')\n",
        "data5 = pd.read_csv(f'{current_dir}/MachineLearningCVE/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv')\n",
        "data6 = pd.read_csv(f'{current_dir}/MachineLearningCVE/Friday-WorkingHours-Morning.pcap_ISCX.csv')\n",
        "data7 = pd.read_csv(f'{current_dir}/MachineLearningCVE/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv')\n",
        "data8 = pd.read_csv(f'{current_dir}/MachineLearningCVE/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuzF1FT5IEyr",
        "outputId": "c5f5b9db-6091-4f8a-d8ff-d3b48f8d510a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data dimensions: \n",
            "Data1 -> 529918 rows, 79 columns\n",
            "Data2 -> 445909 rows, 79 columns\n",
            "Data3 -> 692703 rows, 79 columns\n",
            "Data4 -> 170366 rows, 79 columns\n",
            "Data5 -> 288602 rows, 79 columns\n",
            "Data6 -> 191033 rows, 79 columns\n",
            "Data7 -> 286467 rows, 79 columns\n",
            "Data8 -> 225745 rows, 79 columns\n"
          ]
        }
      ],
      "source": [
        "data_list = [data1, data2, data3, data4, data5, data6, data7, data8]\n",
        "\n",
        "print('Data dimensions: ')\n",
        "for i, data in enumerate(data_list, start = 1):\n",
        "  rows, cols = data.shape\n",
        "  print(f'Data{i} -> {rows} rows, {cols} columns')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47AUI4Q9GiBt",
        "outputId": "105406bc-2fb0-4b5f-b3e4-98acacb78e2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New dimension:\n",
            "Number of rows: 2830743\n",
            "Number of columns: 79\n",
            "Total cells: 223628697\n"
          ]
        }
      ],
      "source": [
        "data = pd.concat(data_list)\n",
        "rows, cols = data.shape\n",
        "\n",
        "print('New dimension:')\n",
        "print(f'Number of rows: {rows}')\n",
        "print(f'Number of columns: {cols}')\n",
        "print(f'Total cells: {rows * cols}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "w3VWo9AZa0CP"
      },
      "outputs": [],
      "source": [
        "# Deleting dataframes after concating to save memory\n",
        "for d in data_list: del d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TKja3Q5r3AiS"
      },
      "outputs": [],
      "source": [
        "# Renaming the columns by removing leading/trailing whitespace\n",
        "col_names = {col: col.strip() for col in data.columns}\n",
        "data.rename(columns = col_names, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydfEc-jBstvg",
        "outputId": "059ca16f-5707-429a-cb05-d896d853c132"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Destination Port', 'Flow Duration', 'Total Fwd Packets',\n",
              "       'Total Backward Packets', 'Total Length of Fwd Packets',\n",
              "       'Total Length of Bwd Packets', 'Fwd Packet Length Max',\n",
              "       'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
              "       'Fwd Packet Length Std', 'Bwd Packet Length Max',\n",
              "       'Bwd Packet Length Min', 'Bwd Packet Length Mean',\n",
              "       'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s',\n",
              "       'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min',\n",
              "       'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max',\n",
              "       'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std',\n",
              "       'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags',\n",
              "       'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length',\n",
              "       'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s',\n",
              "       'Min Packet Length', 'Max Packet Length', 'Packet Length Mean',\n",
              "       'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count',\n",
              "       'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n",
              "       'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio',\n",
              "       'Average Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size',\n",
              "       'Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk',\n",
              "       'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk',\n",
              "       'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes',\n",
              "       'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
              "       'Init_Win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward',\n",
              "       'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean',\n",
              "       'Idle Std', 'Idle Max', 'Idle Min', 'Label'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w14PfaRt9ZH",
        "outputId": "2d2e74ee-8964-441e-c9cc-7ead85214b67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 2830743 entries, 0 to 225744\n",
            "Data columns (total 79 columns):\n",
            " #   Column                       Dtype  \n",
            "---  ------                       -----  \n",
            " 0   Destination Port             int64  \n",
            " 1   Flow Duration                int64  \n",
            " 2   Total Fwd Packets            int64  \n",
            " 3   Total Backward Packets       int64  \n",
            " 4   Total Length of Fwd Packets  int64  \n",
            " 5   Total Length of Bwd Packets  int64  \n",
            " 6   Fwd Packet Length Max        int64  \n",
            " 7   Fwd Packet Length Min        int64  \n",
            " 8   Fwd Packet Length Mean       float64\n",
            " 9   Fwd Packet Length Std        float64\n",
            " 10  Bwd Packet Length Max        int64  \n",
            " 11  Bwd Packet Length Min        int64  \n",
            " 12  Bwd Packet Length Mean       float64\n",
            " 13  Bwd Packet Length Std        float64\n",
            " 14  Flow Bytes/s                 float64\n",
            " 15  Flow Packets/s               float64\n",
            " 16  Flow IAT Mean                float64\n",
            " 17  Flow IAT Std                 float64\n",
            " 18  Flow IAT Max                 int64  \n",
            " 19  Flow IAT Min                 int64  \n",
            " 20  Fwd IAT Total                int64  \n",
            " 21  Fwd IAT Mean                 float64\n",
            " 22  Fwd IAT Std                  float64\n",
            " 23  Fwd IAT Max                  int64  \n",
            " 24  Fwd IAT Min                  int64  \n",
            " 25  Bwd IAT Total                int64  \n",
            " 26  Bwd IAT Mean                 float64\n",
            " 27  Bwd IAT Std                  float64\n",
            " 28  Bwd IAT Max                  int64  \n",
            " 29  Bwd IAT Min                  int64  \n",
            " 30  Fwd PSH Flags                int64  \n",
            " 31  Bwd PSH Flags                int64  \n",
            " 32  Fwd URG Flags                int64  \n",
            " 33  Bwd URG Flags                int64  \n",
            " 34  Fwd Header Length            int64  \n",
            " 35  Bwd Header Length            int64  \n",
            " 36  Fwd Packets/s                float64\n",
            " 37  Bwd Packets/s                float64\n",
            " 38  Min Packet Length            int64  \n",
            " 39  Max Packet Length            int64  \n",
            " 40  Packet Length Mean           float64\n",
            " 41  Packet Length Std            float64\n",
            " 42  Packet Length Variance       float64\n",
            " 43  FIN Flag Count               int64  \n",
            " 44  SYN Flag Count               int64  \n",
            " 45  RST Flag Count               int64  \n",
            " 46  PSH Flag Count               int64  \n",
            " 47  ACK Flag Count               int64  \n",
            " 48  URG Flag Count               int64  \n",
            " 49  CWE Flag Count               int64  \n",
            " 50  ECE Flag Count               int64  \n",
            " 51  Down/Up Ratio                int64  \n",
            " 52  Average Packet Size          float64\n",
            " 53  Avg Fwd Segment Size         float64\n",
            " 54  Avg Bwd Segment Size         float64\n",
            " 55  Fwd Header Length.1          int64  \n",
            " 56  Fwd Avg Bytes/Bulk           int64  \n",
            " 57  Fwd Avg Packets/Bulk         int64  \n",
            " 58  Fwd Avg Bulk Rate            int64  \n",
            " 59  Bwd Avg Bytes/Bulk           int64  \n",
            " 60  Bwd Avg Packets/Bulk         int64  \n",
            " 61  Bwd Avg Bulk Rate            int64  \n",
            " 62  Subflow Fwd Packets          int64  \n",
            " 63  Subflow Fwd Bytes            int64  \n",
            " 64  Subflow Bwd Packets          int64  \n",
            " 65  Subflow Bwd Bytes            int64  \n",
            " 66  Init_Win_bytes_forward       int64  \n",
            " 67  Init_Win_bytes_backward      int64  \n",
            " 68  act_data_pkt_fwd             int64  \n",
            " 69  min_seg_size_forward         int64  \n",
            " 70  Active Mean                  float64\n",
            " 71  Active Std                   float64\n",
            " 72  Active Max                   int64  \n",
            " 73  Active Min                   int64  \n",
            " 74  Idle Mean                    float64\n",
            " 75  Idle Std                     float64\n",
            " 76  Idle Max                     int64  \n",
            " 77  Idle Min                     int64  \n",
            " 78  Label                        object \n",
            "dtypes: float64(24), int64(54), object(1)\n",
            "memory usage: 1.7+ GB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Tt8K5je1auwT",
        "outputId": "35cc864d-3162-4b44-fde3-b6529407a5e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overview of Columns:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/alexin/Documents/Cours/TelecomSE/FISE2/Semestre 7/Projet/AdversarialNIDS/.venv/lib/python3.12/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
            "  sqr = _ensure_numeric((avg - values) ** 2)\n",
            "/home/alexin/Documents/Cours/TelecomSE/FISE2/Semestre 7/Projet/AdversarialNIDS/.venv/lib/python3.12/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
            "  sqr = _ensure_numeric((avg - values) ** 2)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Destination Port</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>8.071483e+03</td>\n",
              "      <td>1.828363e+04</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>4.430000e+02</td>\n",
              "      <td>6.553500e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Flow Duration</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>1.478566e+07</td>\n",
              "      <td>3.365374e+07</td>\n",
              "      <td>-1.300000e+01</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>31316.000000</td>\n",
              "      <td>3.204828e+06</td>\n",
              "      <td>1.200000e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>9.361160e+00</td>\n",
              "      <td>7.496728e+02</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.000000e+00</td>\n",
              "      <td>2.197590e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>1.039377e+01</td>\n",
              "      <td>9.973883e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>2.919220e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>5.493024e+02</td>\n",
              "      <td>9.993589e+03</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>1.870000e+02</td>\n",
              "      <td>1.290000e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>1.616264e+04</td>\n",
              "      <td>2.263088e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>4.820000e+02</td>\n",
              "      <td>6.554530e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>2.075999e+02</td>\n",
              "      <td>7.171848e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>8.100000e+01</td>\n",
              "      <td>2.482000e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>1.871366e+01</td>\n",
              "      <td>6.033935e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.600000e+01</td>\n",
              "      <td>2.325000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>5.820194e+01</td>\n",
              "      <td>1.860912e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>5.000000e+01</td>\n",
              "      <td>5.940857e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>6.891013e+01</td>\n",
              "      <td>2.811871e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.616295e+01</td>\n",
              "      <td>7.125597e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>8.708495e+02</td>\n",
              "      <td>1.946367e+03</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>2.800000e+02</td>\n",
              "      <td>1.953000e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>4.104958e+01</td>\n",
              "      <td>6.886260e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.700000e+01</td>\n",
              "      <td>2.896000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>3.059493e+02</td>\n",
              "      <td>6.052568e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>1.810000e+02</td>\n",
              "      <td>5.800500e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>3.353257e+02</td>\n",
              "      <td>8.396932e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.794054e+01</td>\n",
              "      <td>8.194660e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <td>2829385.0</td>\n",
              "      <td>inf</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-2.610000e+08</td>\n",
              "      <td>119.319731</td>\n",
              "      <td>4595.549126</td>\n",
              "      <td>1.666667e+05</td>\n",
              "      <td>inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>inf</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-2.000000e+06</td>\n",
              "      <td>3.446226</td>\n",
              "      <td>110.668437</td>\n",
              "      <td>2.325581e+04</td>\n",
              "      <td>inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>1.298449e+06</td>\n",
              "      <td>4.507944e+06</td>\n",
              "      <td>-1.300000e+01</td>\n",
              "      <td>63.666667</td>\n",
              "      <td>11438.842110</td>\n",
              "      <td>3.374266e+05</td>\n",
              "      <td>1.200000e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>2.919271e+06</td>\n",
              "      <td>8.045870e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>137.178716</td>\n",
              "      <td>6.912663e+05</td>\n",
              "      <td>8.480026e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>9.182475e+06</td>\n",
              "      <td>2.445954e+07</td>\n",
              "      <td>-1.300000e+01</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>30865.000000</td>\n",
              "      <td>2.440145e+06</td>\n",
              "      <td>1.200000e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>1.623796e+05</td>\n",
              "      <td>2.950282e+06</td>\n",
              "      <td>-1.400000e+01</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>6.400000e+01</td>\n",
              "      <td>1.200000e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>1.448296e+07</td>\n",
              "      <td>3.357581e+07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>1.242844e+06</td>\n",
              "      <td>1.200000e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fwd IAT Mean</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>2.610193e+06</td>\n",
              "      <td>9.525722e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>2.063064e+05</td>\n",
              "      <td>1.200000e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fwd IAT Std</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>3.266957e+06</td>\n",
              "      <td>9.639055e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.598982e+04</td>\n",
              "      <td>8.460293e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fwd IAT Max</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>9.042939e+06</td>\n",
              "      <td>2.452916e+07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>9.310060e+05</td>\n",
              "      <td>1.200000e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fwd IAT Min</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>1.021893e+06</td>\n",
              "      <td>8.591436e+06</td>\n",
              "      <td>-1.200000e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.800000e+01</td>\n",
              "      <td>1.200000e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bwd IAT Total</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>9.893830e+06</td>\n",
              "      <td>2.873661e+07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>9.858050e+04</td>\n",
              "      <td>1.200000e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bwd IAT Mean</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>1.805784e+06</td>\n",
              "      <td>8.887197e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.824857e+04</td>\n",
              "      <td>1.200000e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bwd IAT Std</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>1.485973e+06</td>\n",
              "      <td>6.278469e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.572409e+04</td>\n",
              "      <td>8.441801e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bwd IAT Max</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>4.684692e+06</td>\n",
              "      <td>1.716095e+07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>6.021000e+04</td>\n",
              "      <td>1.200000e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bwd IAT Min</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>9.672614e+05</td>\n",
              "      <td>8.308983e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.500000e+01</td>\n",
              "      <td>1.200000e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fwd PSH Flags</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>4.644646e-02</td>\n",
              "      <td>2.104500e-01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bwd PSH Flags</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fwd URG Flags</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>1.112782e-04</td>\n",
              "      <td>1.054826e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bwd URG Flags</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fwd Header Length</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>-2.599739e+04</td>\n",
              "      <td>2.105286e+07</td>\n",
              "      <td>-3.221223e+10</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>1.200000e+02</td>\n",
              "      <td>4.644908e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bwd Header Length</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>-2.273275e+03</td>\n",
              "      <td>1.452209e+06</td>\n",
              "      <td>-1.073741e+09</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>1.040000e+02</td>\n",
              "      <td>5.838440e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fwd Packets/s</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>6.386535e+04</td>\n",
              "      <td>2.475371e+05</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.749446</td>\n",
              "      <td>61.325238</td>\n",
              "      <td>1.204819e+04</td>\n",
              "      <td>3.000000e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bwd Packets/s</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>6.995192e+03</td>\n",
              "      <td>3.815170e+04</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.122920</td>\n",
              "      <td>19.827894</td>\n",
              "      <td>7.352941e+03</td>\n",
              "      <td>2.000000e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Min Packet Length</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>1.643450e+01</td>\n",
              "      <td>2.523772e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.600000e+01</td>\n",
              "      <td>1.448000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max Packet Length</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>9.504024e+02</td>\n",
              "      <td>2.028229e+03</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>5.250000e+02</td>\n",
              "      <td>2.482000e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Packet Length Mean</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>1.719444e+02</td>\n",
              "      <td>3.054915e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>57.200000</td>\n",
              "      <td>1.198000e+02</td>\n",
              "      <td>3.337143e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Packet Length Std</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>2.949756e+02</td>\n",
              "      <td>6.318001e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.980762</td>\n",
              "      <td>1.743239e+02</td>\n",
              "      <td>4.731522e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Packet Length Variance</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>4.861548e+05</td>\n",
              "      <td>1.647490e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>675.000000</td>\n",
              "      <td>3.038884e+04</td>\n",
              "      <td>2.240000e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FIN Flag Count</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>3.537976e-02</td>\n",
              "      <td>1.847378e-01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SYN Flag Count</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>4.644646e-02</td>\n",
              "      <td>2.104500e-01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RST Flag Count</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>2.423392e-04</td>\n",
              "      <td>1.556536e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PSH Flag Count</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>2.980705e-01</td>\n",
              "      <td>4.574107e-01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ACK Flag Count</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>3.158443e-01</td>\n",
              "      <td>4.648513e-01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>URG Flag Count</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>9.482316e-02</td>\n",
              "      <td>2.929706e-01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CWE Flag Count</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>1.112782e-04</td>\n",
              "      <td>1.054826e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ECE Flag Count</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>2.433990e-04</td>\n",
              "      <td>1.559935e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Down/Up Ratio</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>6.835004e-01</td>\n",
              "      <td>6.804920e-01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.560000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Average Packet Size</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>1.919837e+02</td>\n",
              "      <td>3.318603e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>72.250000</td>\n",
              "      <td>1.492639e+02</td>\n",
              "      <td>3.893333e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Avg Fwd Segment Size</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>5.820194e+01</td>\n",
              "      <td>1.860912e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>5.000000e+01</td>\n",
              "      <td>5.940857e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Avg Bwd Segment Size</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>3.059493e+02</td>\n",
              "      <td>6.052568e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>1.810000e+02</td>\n",
              "      <td>5.800500e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fwd Header Length.1</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>-2.599739e+04</td>\n",
              "      <td>2.105286e+07</td>\n",
              "      <td>-3.221223e+10</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>1.200000e+02</td>\n",
              "      <td>4.644908e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fwd Avg Bytes/Bulk</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fwd Avg Packets/Bulk</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fwd Avg Bulk Rate</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bwd Avg Bytes/Bulk</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bwd Avg Packets/Bulk</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bwd Avg Bulk Rate</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Subflow Fwd Packets</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>9.361160e+00</td>\n",
              "      <td>7.496728e+02</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.000000e+00</td>\n",
              "      <td>2.197590e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>5.492919e+02</td>\n",
              "      <td>9.980070e+03</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>1.870000e+02</td>\n",
              "      <td>1.287034e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>1.039377e+01</td>\n",
              "      <td>9.973883e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>2.919220e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>1.616230e+04</td>\n",
              "      <td>2.263057e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>4.820000e+02</td>\n",
              "      <td>6.554530e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>6.989837e+03</td>\n",
              "      <td>1.433873e+04</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>251.000000</td>\n",
              "      <td>8.192000e+03</td>\n",
              "      <td>6.553500e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>1.989433e+03</td>\n",
              "      <td>8.456883e+03</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>2.350000e+02</td>\n",
              "      <td>6.553500e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>5.418218e+00</td>\n",
              "      <td>6.364257e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.135570e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>-2.741688e+03</td>\n",
              "      <td>1.084989e+06</td>\n",
              "      <td>-5.368707e+08</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>3.200000e+01</td>\n",
              "      <td>1.380000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Active Mean</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>8.155132e+04</td>\n",
              "      <td>6.485999e+05</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.100000e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Active Std</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>4.113412e+04</td>\n",
              "      <td>3.933815e+05</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>7.420000e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Active Max</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>1.531825e+05</td>\n",
              "      <td>1.025825e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.100000e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Active Min</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>5.829582e+04</td>\n",
              "      <td>5.770923e+05</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.100000e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Idle Mean</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>8.316037e+06</td>\n",
              "      <td>2.363008e+07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.200000e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Idle Std</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>5.038439e+05</td>\n",
              "      <td>4.602984e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>7.690000e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Idle Max</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>8.695752e+06</td>\n",
              "      <td>2.436689e+07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.200000e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Idle Min</th>\n",
              "      <td>2830743.0</td>\n",
              "      <td>7.920031e+06</td>\n",
              "      <td>2.336342e+07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.200000e+08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 count          mean           std  \\\n",
              "Destination Port             2830743.0  8.071483e+03  1.828363e+04   \n",
              "Flow Duration                2830743.0  1.478566e+07  3.365374e+07   \n",
              "Total Fwd Packets            2830743.0  9.361160e+00  7.496728e+02   \n",
              "Total Backward Packets       2830743.0  1.039377e+01  9.973883e+02   \n",
              "Total Length of Fwd Packets  2830743.0  5.493024e+02  9.993589e+03   \n",
              "Total Length of Bwd Packets  2830743.0  1.616264e+04  2.263088e+06   \n",
              "Fwd Packet Length Max        2830743.0  2.075999e+02  7.171848e+02   \n",
              "Fwd Packet Length Min        2830743.0  1.871366e+01  6.033935e+01   \n",
              "Fwd Packet Length Mean       2830743.0  5.820194e+01  1.860912e+02   \n",
              "Fwd Packet Length Std        2830743.0  6.891013e+01  2.811871e+02   \n",
              "Bwd Packet Length Max        2830743.0  8.708495e+02  1.946367e+03   \n",
              "Bwd Packet Length Min        2830743.0  4.104958e+01  6.886260e+01   \n",
              "Bwd Packet Length Mean       2830743.0  3.059493e+02  6.052568e+02   \n",
              "Bwd Packet Length Std        2830743.0  3.353257e+02  8.396932e+02   \n",
              "Flow Bytes/s                 2829385.0           inf           NaN   \n",
              "Flow Packets/s               2830743.0           inf           NaN   \n",
              "Flow IAT Mean                2830743.0  1.298449e+06  4.507944e+06   \n",
              "Flow IAT Std                 2830743.0  2.919271e+06  8.045870e+06   \n",
              "Flow IAT Max                 2830743.0  9.182475e+06  2.445954e+07   \n",
              "Flow IAT Min                 2830743.0  1.623796e+05  2.950282e+06   \n",
              "Fwd IAT Total                2830743.0  1.448296e+07  3.357581e+07   \n",
              "Fwd IAT Mean                 2830743.0  2.610193e+06  9.525722e+06   \n",
              "Fwd IAT Std                  2830743.0  3.266957e+06  9.639055e+06   \n",
              "Fwd IAT Max                  2830743.0  9.042939e+06  2.452916e+07   \n",
              "Fwd IAT Min                  2830743.0  1.021893e+06  8.591436e+06   \n",
              "Bwd IAT Total                2830743.0  9.893830e+06  2.873661e+07   \n",
              "Bwd IAT Mean                 2830743.0  1.805784e+06  8.887197e+06   \n",
              "Bwd IAT Std                  2830743.0  1.485973e+06  6.278469e+06   \n",
              "Bwd IAT Max                  2830743.0  4.684692e+06  1.716095e+07   \n",
              "Bwd IAT Min                  2830743.0  9.672614e+05  8.308983e+06   \n",
              "Fwd PSH Flags                2830743.0  4.644646e-02  2.104500e-01   \n",
              "Bwd PSH Flags                2830743.0  0.000000e+00  0.000000e+00   \n",
              "Fwd URG Flags                2830743.0  1.112782e-04  1.054826e-02   \n",
              "Bwd URG Flags                2830743.0  0.000000e+00  0.000000e+00   \n",
              "Fwd Header Length            2830743.0 -2.599739e+04  2.105286e+07   \n",
              "Bwd Header Length            2830743.0 -2.273275e+03  1.452209e+06   \n",
              "Fwd Packets/s                2830743.0  6.386535e+04  2.475371e+05   \n",
              "Bwd Packets/s                2830743.0  6.995192e+03  3.815170e+04   \n",
              "Min Packet Length            2830743.0  1.643450e+01  2.523772e+01   \n",
              "Max Packet Length            2830743.0  9.504024e+02  2.028229e+03   \n",
              "Packet Length Mean           2830743.0  1.719444e+02  3.054915e+02   \n",
              "Packet Length Std            2830743.0  2.949756e+02  6.318001e+02   \n",
              "Packet Length Variance       2830743.0  4.861548e+05  1.647490e+06   \n",
              "FIN Flag Count               2830743.0  3.537976e-02  1.847378e-01   \n",
              "SYN Flag Count               2830743.0  4.644646e-02  2.104500e-01   \n",
              "RST Flag Count               2830743.0  2.423392e-04  1.556536e-02   \n",
              "PSH Flag Count               2830743.0  2.980705e-01  4.574107e-01   \n",
              "ACK Flag Count               2830743.0  3.158443e-01  4.648513e-01   \n",
              "URG Flag Count               2830743.0  9.482316e-02  2.929706e-01   \n",
              "CWE Flag Count               2830743.0  1.112782e-04  1.054826e-02   \n",
              "ECE Flag Count               2830743.0  2.433990e-04  1.559935e-02   \n",
              "Down/Up Ratio                2830743.0  6.835004e-01  6.804920e-01   \n",
              "Average Packet Size          2830743.0  1.919837e+02  3.318603e+02   \n",
              "Avg Fwd Segment Size         2830743.0  5.820194e+01  1.860912e+02   \n",
              "Avg Bwd Segment Size         2830743.0  3.059493e+02  6.052568e+02   \n",
              "Fwd Header Length.1          2830743.0 -2.599739e+04  2.105286e+07   \n",
              "Fwd Avg Bytes/Bulk           2830743.0  0.000000e+00  0.000000e+00   \n",
              "Fwd Avg Packets/Bulk         2830743.0  0.000000e+00  0.000000e+00   \n",
              "Fwd Avg Bulk Rate            2830743.0  0.000000e+00  0.000000e+00   \n",
              "Bwd Avg Bytes/Bulk           2830743.0  0.000000e+00  0.000000e+00   \n",
              "Bwd Avg Packets/Bulk         2830743.0  0.000000e+00  0.000000e+00   \n",
              "Bwd Avg Bulk Rate            2830743.0  0.000000e+00  0.000000e+00   \n",
              "Subflow Fwd Packets          2830743.0  9.361160e+00  7.496728e+02   \n",
              "Subflow Fwd Bytes            2830743.0  5.492919e+02  9.980070e+03   \n",
              "Subflow Bwd Packets          2830743.0  1.039377e+01  9.973883e+02   \n",
              "Subflow Bwd Bytes            2830743.0  1.616230e+04  2.263057e+06   \n",
              "Init_Win_bytes_forward       2830743.0  6.989837e+03  1.433873e+04   \n",
              "Init_Win_bytes_backward      2830743.0  1.989433e+03  8.456883e+03   \n",
              "act_data_pkt_fwd             2830743.0  5.418218e+00  6.364257e+02   \n",
              "min_seg_size_forward         2830743.0 -2.741688e+03  1.084989e+06   \n",
              "Active Mean                  2830743.0  8.155132e+04  6.485999e+05   \n",
              "Active Std                   2830743.0  4.113412e+04  3.933815e+05   \n",
              "Active Max                   2830743.0  1.531825e+05  1.025825e+06   \n",
              "Active Min                   2830743.0  5.829582e+04  5.770923e+05   \n",
              "Idle Mean                    2830743.0  8.316037e+06  2.363008e+07   \n",
              "Idle Std                     2830743.0  5.038439e+05  4.602984e+06   \n",
              "Idle Max                     2830743.0  8.695752e+06  2.436689e+07   \n",
              "Idle Min                     2830743.0  7.920031e+06  2.336342e+07   \n",
              "\n",
              "                                      min         25%           50%  \\\n",
              "Destination Port             0.000000e+00   53.000000     80.000000   \n",
              "Flow Duration               -1.300000e+01  155.000000  31316.000000   \n",
              "Total Fwd Packets            1.000000e+00    2.000000      2.000000   \n",
              "Total Backward Packets       0.000000e+00    1.000000      2.000000   \n",
              "Total Length of Fwd Packets  0.000000e+00   12.000000     62.000000   \n",
              "Total Length of Bwd Packets  0.000000e+00    0.000000    123.000000   \n",
              "Fwd Packet Length Max        0.000000e+00    6.000000     37.000000   \n",
              "Fwd Packet Length Min        0.000000e+00    0.000000      2.000000   \n",
              "Fwd Packet Length Mean       0.000000e+00    6.000000     34.000000   \n",
              "Fwd Packet Length Std        0.000000e+00    0.000000      0.000000   \n",
              "Bwd Packet Length Max        0.000000e+00    0.000000     79.000000   \n",
              "Bwd Packet Length Min        0.000000e+00    0.000000      0.000000   \n",
              "Bwd Packet Length Mean       0.000000e+00    0.000000     72.000000   \n",
              "Bwd Packet Length Std        0.000000e+00    0.000000      0.000000   \n",
              "Flow Bytes/s                -2.610000e+08  119.319731   4595.549126   \n",
              "Flow Packets/s              -2.000000e+06    3.446226    110.668437   \n",
              "Flow IAT Mean               -1.300000e+01   63.666667  11438.842110   \n",
              "Flow IAT Std                 0.000000e+00    0.000000    137.178716   \n",
              "Flow IAT Max                -1.300000e+01  123.000000  30865.000000   \n",
              "Flow IAT Min                -1.400000e+01    3.000000      4.000000   \n",
              "Fwd IAT Total                0.000000e+00    0.000000     43.000000   \n",
              "Fwd IAT Mean                 0.000000e+00    0.000000     26.000000   \n",
              "Fwd IAT Std                  0.000000e+00    0.000000      0.000000   \n",
              "Fwd IAT Max                  0.000000e+00    0.000000     43.000000   \n",
              "Fwd IAT Min                 -1.200000e+01    0.000000      3.000000   \n",
              "Bwd IAT Total                0.000000e+00    0.000000      3.000000   \n",
              "Bwd IAT Mean                 0.000000e+00    0.000000      3.000000   \n",
              "Bwd IAT Std                  0.000000e+00    0.000000      0.000000   \n",
              "Bwd IAT Max                  0.000000e+00    0.000000      3.000000   \n",
              "Bwd IAT Min                  0.000000e+00    0.000000      1.000000   \n",
              "Fwd PSH Flags                0.000000e+00    0.000000      0.000000   \n",
              "Bwd PSH Flags                0.000000e+00    0.000000      0.000000   \n",
              "Fwd URG Flags                0.000000e+00    0.000000      0.000000   \n",
              "Bwd URG Flags                0.000000e+00    0.000000      0.000000   \n",
              "Fwd Header Length           -3.221223e+10   40.000000     64.000000   \n",
              "Bwd Header Length           -1.073741e+09   20.000000     40.000000   \n",
              "Fwd Packets/s                0.000000e+00    1.749446     61.325238   \n",
              "Bwd Packets/s                0.000000e+00    0.122920     19.827894   \n",
              "Min Packet Length            0.000000e+00    0.000000      2.000000   \n",
              "Max Packet Length            0.000000e+00    6.000000     87.000000   \n",
              "Packet Length Mean           0.000000e+00    6.000000     57.200000   \n",
              "Packet Length Std            0.000000e+00    0.000000     25.980762   \n",
              "Packet Length Variance       0.000000e+00    0.000000    675.000000   \n",
              "FIN Flag Count               0.000000e+00    0.000000      0.000000   \n",
              "SYN Flag Count               0.000000e+00    0.000000      0.000000   \n",
              "RST Flag Count               0.000000e+00    0.000000      0.000000   \n",
              "PSH Flag Count               0.000000e+00    0.000000      0.000000   \n",
              "ACK Flag Count               0.000000e+00    0.000000      0.000000   \n",
              "URG Flag Count               0.000000e+00    0.000000      0.000000   \n",
              "CWE Flag Count               0.000000e+00    0.000000      0.000000   \n",
              "ECE Flag Count               0.000000e+00    0.000000      0.000000   \n",
              "Down/Up Ratio                0.000000e+00    0.000000      1.000000   \n",
              "Average Packet Size          0.000000e+00    7.500000     72.250000   \n",
              "Avg Fwd Segment Size         0.000000e+00    6.000000     34.000000   \n",
              "Avg Bwd Segment Size         0.000000e+00    0.000000     72.000000   \n",
              "Fwd Header Length.1         -3.221223e+10   40.000000     64.000000   \n",
              "Fwd Avg Bytes/Bulk           0.000000e+00    0.000000      0.000000   \n",
              "Fwd Avg Packets/Bulk         0.000000e+00    0.000000      0.000000   \n",
              "Fwd Avg Bulk Rate            0.000000e+00    0.000000      0.000000   \n",
              "Bwd Avg Bytes/Bulk           0.000000e+00    0.000000      0.000000   \n",
              "Bwd Avg Packets/Bulk         0.000000e+00    0.000000      0.000000   \n",
              "Bwd Avg Bulk Rate            0.000000e+00    0.000000      0.000000   \n",
              "Subflow Fwd Packets          1.000000e+00    2.000000      2.000000   \n",
              "Subflow Fwd Bytes            0.000000e+00   12.000000     62.000000   \n",
              "Subflow Bwd Packets          0.000000e+00    1.000000      2.000000   \n",
              "Subflow Bwd Bytes            0.000000e+00    0.000000    123.000000   \n",
              "Init_Win_bytes_forward      -1.000000e+00   -1.000000    251.000000   \n",
              "Init_Win_bytes_backward     -1.000000e+00   -1.000000     -1.000000   \n",
              "act_data_pkt_fwd             0.000000e+00    0.000000      1.000000   \n",
              "min_seg_size_forward        -5.368707e+08   20.000000     24.000000   \n",
              "Active Mean                  0.000000e+00    0.000000      0.000000   \n",
              "Active Std                   0.000000e+00    0.000000      0.000000   \n",
              "Active Max                   0.000000e+00    0.000000      0.000000   \n",
              "Active Min                   0.000000e+00    0.000000      0.000000   \n",
              "Idle Mean                    0.000000e+00    0.000000      0.000000   \n",
              "Idle Std                     0.000000e+00    0.000000      0.000000   \n",
              "Idle Max                     0.000000e+00    0.000000      0.000000   \n",
              "Idle Min                     0.000000e+00    0.000000      0.000000   \n",
              "\n",
              "                                      75%           max  \n",
              "Destination Port             4.430000e+02  6.553500e+04  \n",
              "Flow Duration                3.204828e+06  1.200000e+08  \n",
              "Total Fwd Packets            5.000000e+00  2.197590e+05  \n",
              "Total Backward Packets       4.000000e+00  2.919220e+05  \n",
              "Total Length of Fwd Packets  1.870000e+02  1.290000e+07  \n",
              "Total Length of Bwd Packets  4.820000e+02  6.554530e+08  \n",
              "Fwd Packet Length Max        8.100000e+01  2.482000e+04  \n",
              "Fwd Packet Length Min        3.600000e+01  2.325000e+03  \n",
              "Fwd Packet Length Mean       5.000000e+01  5.940857e+03  \n",
              "Fwd Packet Length Std        2.616295e+01  7.125597e+03  \n",
              "Bwd Packet Length Max        2.800000e+02  1.953000e+04  \n",
              "Bwd Packet Length Min        7.700000e+01  2.896000e+03  \n",
              "Bwd Packet Length Mean       1.810000e+02  5.800500e+03  \n",
              "Bwd Packet Length Std        7.794054e+01  8.194660e+03  \n",
              "Flow Bytes/s                 1.666667e+05           inf  \n",
              "Flow Packets/s               2.325581e+04           inf  \n",
              "Flow IAT Mean                3.374266e+05  1.200000e+08  \n",
              "Flow IAT Std                 6.912663e+05  8.480026e+07  \n",
              "Flow IAT Max                 2.440145e+06  1.200000e+08  \n",
              "Flow IAT Min                 6.400000e+01  1.200000e+08  \n",
              "Fwd IAT Total                1.242844e+06  1.200000e+08  \n",
              "Fwd IAT Mean                 2.063064e+05  1.200000e+08  \n",
              "Fwd IAT Std                  6.598982e+04  8.460293e+07  \n",
              "Fwd IAT Max                  9.310060e+05  1.200000e+08  \n",
              "Fwd IAT Min                  4.800000e+01  1.200000e+08  \n",
              "Bwd IAT Total                9.858050e+04  1.200000e+08  \n",
              "Bwd IAT Mean                 1.824857e+04  1.200000e+08  \n",
              "Bwd IAT Std                  1.572409e+04  8.441801e+07  \n",
              "Bwd IAT Max                  6.021000e+04  1.200000e+08  \n",
              "Bwd IAT Min                  4.500000e+01  1.200000e+08  \n",
              "Fwd PSH Flags                0.000000e+00  1.000000e+00  \n",
              "Bwd PSH Flags                0.000000e+00  0.000000e+00  \n",
              "Fwd URG Flags                0.000000e+00  1.000000e+00  \n",
              "Bwd URG Flags                0.000000e+00  0.000000e+00  \n",
              "Fwd Header Length            1.200000e+02  4.644908e+06  \n",
              "Bwd Header Length            1.040000e+02  5.838440e+06  \n",
              "Fwd Packets/s                1.204819e+04  3.000000e+06  \n",
              "Bwd Packets/s                7.352941e+03  2.000000e+06  \n",
              "Min Packet Length            3.600000e+01  1.448000e+03  \n",
              "Max Packet Length            5.250000e+02  2.482000e+04  \n",
              "Packet Length Mean           1.198000e+02  3.337143e+03  \n",
              "Packet Length Std            1.743239e+02  4.731522e+03  \n",
              "Packet Length Variance       3.038884e+04  2.240000e+07  \n",
              "FIN Flag Count               0.000000e+00  1.000000e+00  \n",
              "SYN Flag Count               0.000000e+00  1.000000e+00  \n",
              "RST Flag Count               0.000000e+00  1.000000e+00  \n",
              "PSH Flag Count               1.000000e+00  1.000000e+00  \n",
              "ACK Flag Count               1.000000e+00  1.000000e+00  \n",
              "URG Flag Count               0.000000e+00  1.000000e+00  \n",
              "CWE Flag Count               0.000000e+00  1.000000e+00  \n",
              "ECE Flag Count               0.000000e+00  1.000000e+00  \n",
              "Down/Up Ratio                1.000000e+00  1.560000e+02  \n",
              "Average Packet Size          1.492639e+02  3.893333e+03  \n",
              "Avg Fwd Segment Size         5.000000e+01  5.940857e+03  \n",
              "Avg Bwd Segment Size         1.810000e+02  5.800500e+03  \n",
              "Fwd Header Length.1          1.200000e+02  4.644908e+06  \n",
              "Fwd Avg Bytes/Bulk           0.000000e+00  0.000000e+00  \n",
              "Fwd Avg Packets/Bulk         0.000000e+00  0.000000e+00  \n",
              "Fwd Avg Bulk Rate            0.000000e+00  0.000000e+00  \n",
              "Bwd Avg Bytes/Bulk           0.000000e+00  0.000000e+00  \n",
              "Bwd Avg Packets/Bulk         0.000000e+00  0.000000e+00  \n",
              "Bwd Avg Bulk Rate            0.000000e+00  0.000000e+00  \n",
              "Subflow Fwd Packets          5.000000e+00  2.197590e+05  \n",
              "Subflow Fwd Bytes            1.870000e+02  1.287034e+07  \n",
              "Subflow Bwd Packets          4.000000e+00  2.919220e+05  \n",
              "Subflow Bwd Bytes            4.820000e+02  6.554530e+08  \n",
              "Init_Win_bytes_forward       8.192000e+03  6.553500e+04  \n",
              "Init_Win_bytes_backward      2.350000e+02  6.553500e+04  \n",
              "act_data_pkt_fwd             2.000000e+00  2.135570e+05  \n",
              "min_seg_size_forward         3.200000e+01  1.380000e+02  \n",
              "Active Mean                  0.000000e+00  1.100000e+08  \n",
              "Active Std                   0.000000e+00  7.420000e+07  \n",
              "Active Max                   0.000000e+00  1.100000e+08  \n",
              "Active Min                   0.000000e+00  1.100000e+08  \n",
              "Idle Mean                    0.000000e+00  1.200000e+08  \n",
              "Idle Std                     0.000000e+00  7.690000e+07  \n",
              "Idle Max                     0.000000e+00  1.200000e+08  \n",
              "Idle Min                     0.000000e+00  1.200000e+08  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.options.display.max_rows = 80\n",
        "\n",
        "print('Overview of Columns:')\n",
        "data.describe().transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "y4UHpc39vmst",
        "outputId": "4c86e5e6-5ed1-4675-97c5-6f14850b86fa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Destination Port</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Fwd IAT Mean</th>\n",
              "      <th>Fwd IAT Std</th>\n",
              "      <th>Fwd IAT Max</th>\n",
              "      <th>Fwd IAT Min</th>\n",
              "      <th>Bwd IAT Total</th>\n",
              "      <th>Bwd IAT Mean</th>\n",
              "      <th>Bwd IAT Std</th>\n",
              "      <th>Bwd IAT Max</th>\n",
              "      <th>Bwd IAT Min</th>\n",
              "      <th>Fwd PSH Flags</th>\n",
              "      <th>Bwd PSH Flags</th>\n",
              "      <th>Fwd URG Flags</th>\n",
              "      <th>Bwd URG Flags</th>\n",
              "      <th>Fwd Header Length</th>\n",
              "      <th>Bwd Header Length</th>\n",
              "      <th>Fwd Packets/s</th>\n",
              "      <th>Bwd Packets/s</th>\n",
              "      <th>Min Packet Length</th>\n",
              "      <th>Max Packet Length</th>\n",
              "      <th>Packet Length Mean</th>\n",
              "      <th>Packet Length Std</th>\n",
              "      <th>Packet Length Variance</th>\n",
              "      <th>FIN Flag Count</th>\n",
              "      <th>SYN Flag Count</th>\n",
              "      <th>RST Flag Count</th>\n",
              "      <th>PSH Flag Count</th>\n",
              "      <th>ACK Flag Count</th>\n",
              "      <th>URG Flag Count</th>\n",
              "      <th>CWE Flag Count</th>\n",
              "      <th>ECE Flag Count</th>\n",
              "      <th>Down/Up Ratio</th>\n",
              "      <th>Average Packet Size</th>\n",
              "      <th>Avg Fwd Segment Size</th>\n",
              "      <th>Avg Bwd Segment Size</th>\n",
              "      <th>Fwd Header Length.1</th>\n",
              "      <th>Fwd Avg Bytes/Bulk</th>\n",
              "      <th>Fwd Avg Packets/Bulk</th>\n",
              "      <th>Fwd Avg Bulk Rate</th>\n",
              "      <th>Bwd Avg Bytes/Bulk</th>\n",
              "      <th>Bwd Avg Packets/Bulk</th>\n",
              "      <th>Bwd Avg Bulk Rate</th>\n",
              "      <th>Subflow Fwd Packets</th>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>49188</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.000000e+06</td>\n",
              "      <td>5.000000e+05</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>5.000000e+05</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>329</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>49188</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.200000e+07</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>329</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>49188</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.200000e+07</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>329</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>49188</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.200000e+07</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>329</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>49486</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.000000e+06</td>\n",
              "      <td>6.666667e+05</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>6.666667e+05</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>245</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225740</th>\n",
              "      <td>61374</td>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.967213e+05</td>\n",
              "      <td>3.278689e+04</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>61</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>1.639344e+04</td>\n",
              "      <td>16393.44262</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>288</td>\n",
              "      <td>253</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225741</th>\n",
              "      <td>61378</td>\n",
              "      <td>72</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.666667e+05</td>\n",
              "      <td>2.777778e+04</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72</td>\n",
              "      <td>72</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>1.388889e+04</td>\n",
              "      <td>13888.88889</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>288</td>\n",
              "      <td>253</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225742</th>\n",
              "      <td>61375</td>\n",
              "      <td>75</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.600000e+05</td>\n",
              "      <td>2.666667e+04</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75</td>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>1.333333e+04</td>\n",
              "      <td>13333.33333</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>288</td>\n",
              "      <td>253</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225743</th>\n",
              "      <td>61323</td>\n",
              "      <td>48</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.500000e+05</td>\n",
              "      <td>4.166667e+04</td>\n",
              "      <td>48.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>48.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>4.166667e+04</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4719</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225744</th>\n",
              "      <td>61326</td>\n",
              "      <td>68</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.764706e+05</td>\n",
              "      <td>2.941176e+04</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>68</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>1.470588e+04</td>\n",
              "      <td>14705.88235</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>13140</td>\n",
              "      <td>64240</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2830743 rows  79 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Destination Port  Flow Duration  Total Fwd Packets  \\\n",
              "0                  49188              4                  2   \n",
              "1                  49188              1                  2   \n",
              "2                  49188              1                  2   \n",
              "3                  49188              1                  2   \n",
              "4                  49486              3                  2   \n",
              "...                  ...            ...                ...   \n",
              "225740             61374             61                  1   \n",
              "225741             61378             72                  1   \n",
              "225742             61375             75                  1   \n",
              "225743             61323             48                  2   \n",
              "225744             61326             68                  1   \n",
              "\n",
              "        Total Backward Packets  Total Length of Fwd Packets  \\\n",
              "0                            0                           12   \n",
              "1                            0                           12   \n",
              "2                            0                           12   \n",
              "3                            0                           12   \n",
              "4                            0                           12   \n",
              "...                        ...                          ...   \n",
              "225740                       1                            6   \n",
              "225741                       1                            6   \n",
              "225742                       1                            6   \n",
              "225743                       0                           12   \n",
              "225744                       1                            6   \n",
              "\n",
              "        Total Length of Bwd Packets  Fwd Packet Length Max  \\\n",
              "0                                 0                      6   \n",
              "1                                 0                      6   \n",
              "2                                 0                      6   \n",
              "3                                 0                      6   \n",
              "4                                 0                      6   \n",
              "...                             ...                    ...   \n",
              "225740                            6                      6   \n",
              "225741                            6                      6   \n",
              "225742                            6                      6   \n",
              "225743                            0                      6   \n",
              "225744                            6                      6   \n",
              "\n",
              "        Fwd Packet Length Min  Fwd Packet Length Mean  Fwd Packet Length Std  \\\n",
              "0                           6                     6.0                    0.0   \n",
              "1                           6                     6.0                    0.0   \n",
              "2                           6                     6.0                    0.0   \n",
              "3                           6                     6.0                    0.0   \n",
              "4                           6                     6.0                    0.0   \n",
              "...                       ...                     ...                    ...   \n",
              "225740                      6                     6.0                    0.0   \n",
              "225741                      6                     6.0                    0.0   \n",
              "225742                      6                     6.0                    0.0   \n",
              "225743                      6                     6.0                    0.0   \n",
              "225744                      6                     6.0                    0.0   \n",
              "\n",
              "        Bwd Packet Length Max  Bwd Packet Length Min  Bwd Packet Length Mean  \\\n",
              "0                           0                      0                     0.0   \n",
              "1                           0                      0                     0.0   \n",
              "2                           0                      0                     0.0   \n",
              "3                           0                      0                     0.0   \n",
              "4                           0                      0                     0.0   \n",
              "...                       ...                    ...                     ...   \n",
              "225740                      6                      6                     6.0   \n",
              "225741                      6                      6                     6.0   \n",
              "225742                      6                      6                     6.0   \n",
              "225743                      0                      0                     0.0   \n",
              "225744                      6                      6                     6.0   \n",
              "\n",
              "        Bwd Packet Length Std  Flow Bytes/s  Flow Packets/s  Flow IAT Mean  \\\n",
              "0                         0.0  3.000000e+06    5.000000e+05            4.0   \n",
              "1                         0.0  1.200000e+07    2.000000e+06            1.0   \n",
              "2                         0.0  1.200000e+07    2.000000e+06            1.0   \n",
              "3                         0.0  1.200000e+07    2.000000e+06            1.0   \n",
              "4                         0.0  4.000000e+06    6.666667e+05            3.0   \n",
              "...                       ...           ...             ...            ...   \n",
              "225740                    0.0  1.967213e+05    3.278689e+04           61.0   \n",
              "225741                    0.0  1.666667e+05    2.777778e+04           72.0   \n",
              "225742                    0.0  1.600000e+05    2.666667e+04           75.0   \n",
              "225743                    0.0  2.500000e+05    4.166667e+04           48.0   \n",
              "225744                    0.0  1.764706e+05    2.941176e+04           68.0   \n",
              "\n",
              "        Flow IAT Std  Flow IAT Max  Flow IAT Min  Fwd IAT Total  Fwd IAT Mean  \\\n",
              "0                0.0             4             4              4           4.0   \n",
              "1                0.0             1             1              1           1.0   \n",
              "2                0.0             1             1              1           1.0   \n",
              "3                0.0             1             1              1           1.0   \n",
              "4                0.0             3             3              3           3.0   \n",
              "...              ...           ...           ...            ...           ...   \n",
              "225740           0.0            61            61              0           0.0   \n",
              "225741           0.0            72            72              0           0.0   \n",
              "225742           0.0            75            75              0           0.0   \n",
              "225743           0.0            48            48             48          48.0   \n",
              "225744           0.0            68            68              0           0.0   \n",
              "\n",
              "        Fwd IAT Std  Fwd IAT Max  Fwd IAT Min  Bwd IAT Total  Bwd IAT Mean  \\\n",
              "0               0.0            4            4              0           0.0   \n",
              "1               0.0            1            1              0           0.0   \n",
              "2               0.0            1            1              0           0.0   \n",
              "3               0.0            1            1              0           0.0   \n",
              "4               0.0            3            3              0           0.0   \n",
              "...             ...          ...          ...            ...           ...   \n",
              "225740          0.0            0            0              0           0.0   \n",
              "225741          0.0            0            0              0           0.0   \n",
              "225742          0.0            0            0              0           0.0   \n",
              "225743          0.0           48           48              0           0.0   \n",
              "225744          0.0            0            0              0           0.0   \n",
              "\n",
              "        Bwd IAT Std  Bwd IAT Max  Bwd IAT Min  Fwd PSH Flags  Bwd PSH Flags  \\\n",
              "0               0.0            0            0              0              0   \n",
              "1               0.0            0            0              0              0   \n",
              "2               0.0            0            0              0              0   \n",
              "3               0.0            0            0              0              0   \n",
              "4               0.0            0            0              0              0   \n",
              "...             ...          ...          ...            ...            ...   \n",
              "225740          0.0            0            0              0              0   \n",
              "225741          0.0            0            0              0              0   \n",
              "225742          0.0            0            0              0              0   \n",
              "225743          0.0            0            0              0              0   \n",
              "225744          0.0            0            0              0              0   \n",
              "\n",
              "        Fwd URG Flags  Bwd URG Flags  Fwd Header Length  Bwd Header Length  \\\n",
              "0                   0              0                 40                  0   \n",
              "1                   0              0                 40                  0   \n",
              "2                   0              0                 40                  0   \n",
              "3                   0              0                 40                  0   \n",
              "4                   0              0                 40                  0   \n",
              "...               ...            ...                ...                ...   \n",
              "225740              0              0                 20                 20   \n",
              "225741              0              0                 20                 20   \n",
              "225742              0              0                 20                 20   \n",
              "225743              0              0                 40                  0   \n",
              "225744              0              0                 20                 20   \n",
              "\n",
              "        Fwd Packets/s  Bwd Packets/s  Min Packet Length  Max Packet Length  \\\n",
              "0        5.000000e+05        0.00000                  6                  6   \n",
              "1        2.000000e+06        0.00000                  6                  6   \n",
              "2        2.000000e+06        0.00000                  6                  6   \n",
              "3        2.000000e+06        0.00000                  6                  6   \n",
              "4        6.666667e+05        0.00000                  6                  6   \n",
              "...               ...            ...                ...                ...   \n",
              "225740   1.639344e+04    16393.44262                  6                  6   \n",
              "225741   1.388889e+04    13888.88889                  6                  6   \n",
              "225742   1.333333e+04    13333.33333                  6                  6   \n",
              "225743   4.166667e+04        0.00000                  6                  6   \n",
              "225744   1.470588e+04    14705.88235                  6                  6   \n",
              "\n",
              "        Packet Length Mean  Packet Length Std  Packet Length Variance  \\\n",
              "0                      6.0                0.0                     0.0   \n",
              "1                      6.0                0.0                     0.0   \n",
              "2                      6.0                0.0                     0.0   \n",
              "3                      6.0                0.0                     0.0   \n",
              "4                      6.0                0.0                     0.0   \n",
              "...                    ...                ...                     ...   \n",
              "225740                 6.0                0.0                     0.0   \n",
              "225741                 6.0                0.0                     0.0   \n",
              "225742                 6.0                0.0                     0.0   \n",
              "225743                 6.0                0.0                     0.0   \n",
              "225744                 6.0                0.0                     0.0   \n",
              "\n",
              "        FIN Flag Count  SYN Flag Count  RST Flag Count  PSH Flag Count  \\\n",
              "0                    0               0               0               0   \n",
              "1                    0               0               0               0   \n",
              "2                    0               0               0               0   \n",
              "3                    0               0               0               0   \n",
              "4                    0               0               0               0   \n",
              "...                ...             ...             ...             ...   \n",
              "225740               0               0               0               0   \n",
              "225741               0               0               0               0   \n",
              "225742               0               0               0               0   \n",
              "225743               0               0               0               0   \n",
              "225744               0               0               0               0   \n",
              "\n",
              "        ACK Flag Count  URG Flag Count  CWE Flag Count  ECE Flag Count  \\\n",
              "0                    1               1               0               0   \n",
              "1                    1               1               0               0   \n",
              "2                    1               1               0               0   \n",
              "3                    1               1               0               0   \n",
              "4                    1               1               0               0   \n",
              "...                ...             ...             ...             ...   \n",
              "225740               1               1               0               0   \n",
              "225741               1               1               0               0   \n",
              "225742               1               1               0               0   \n",
              "225743               1               0               0               0   \n",
              "225744               1               1               0               0   \n",
              "\n",
              "        Down/Up Ratio  Average Packet Size  Avg Fwd Segment Size  \\\n",
              "0                   0                  9.0                   6.0   \n",
              "1                   0                  9.0                   6.0   \n",
              "2                   0                  9.0                   6.0   \n",
              "3                   0                  9.0                   6.0   \n",
              "4                   0                  9.0                   6.0   \n",
              "...               ...                  ...                   ...   \n",
              "225740              1                  9.0                   6.0   \n",
              "225741              1                  9.0                   6.0   \n",
              "225742              1                  9.0                   6.0   \n",
              "225743              0                  9.0                   6.0   \n",
              "225744              1                  9.0                   6.0   \n",
              "\n",
              "        Avg Bwd Segment Size  Fwd Header Length.1  Fwd Avg Bytes/Bulk  \\\n",
              "0                        0.0                   40                   0   \n",
              "1                        0.0                   40                   0   \n",
              "2                        0.0                   40                   0   \n",
              "3                        0.0                   40                   0   \n",
              "4                        0.0                   40                   0   \n",
              "...                      ...                  ...                 ...   \n",
              "225740                   6.0                   20                   0   \n",
              "225741                   6.0                   20                   0   \n",
              "225742                   6.0                   20                   0   \n",
              "225743                   0.0                   40                   0   \n",
              "225744                   6.0                   20                   0   \n",
              "\n",
              "        Fwd Avg Packets/Bulk  Fwd Avg Bulk Rate  Bwd Avg Bytes/Bulk  \\\n",
              "0                          0                  0                   0   \n",
              "1                          0                  0                   0   \n",
              "2                          0                  0                   0   \n",
              "3                          0                  0                   0   \n",
              "4                          0                  0                   0   \n",
              "...                      ...                ...                 ...   \n",
              "225740                     0                  0                   0   \n",
              "225741                     0                  0                   0   \n",
              "225742                     0                  0                   0   \n",
              "225743                     0                  0                   0   \n",
              "225744                     0                  0                   0   \n",
              "\n",
              "        Bwd Avg Packets/Bulk  Bwd Avg Bulk Rate  Subflow Fwd Packets  \\\n",
              "0                          0                  0                    2   \n",
              "1                          0                  0                    2   \n",
              "2                          0                  0                    2   \n",
              "3                          0                  0                    2   \n",
              "4                          0                  0                    2   \n",
              "...                      ...                ...                  ...   \n",
              "225740                     0                  0                    1   \n",
              "225741                     0                  0                    1   \n",
              "225742                     0                  0                    1   \n",
              "225743                     0                  0                    2   \n",
              "225744                     0                  0                    1   \n",
              "\n",
              "        Subflow Fwd Bytes  Subflow Bwd Packets  Subflow Bwd Bytes  \\\n",
              "0                      12                    0                  0   \n",
              "1                      12                    0                  0   \n",
              "2                      12                    0                  0   \n",
              "3                      12                    0                  0   \n",
              "4                      12                    0                  0   \n",
              "...                   ...                  ...                ...   \n",
              "225740                  6                    1                  6   \n",
              "225741                  6                    1                  6   \n",
              "225742                  6                    1                  6   \n",
              "225743                 12                    0                  0   \n",
              "225744                  6                    1                  6   \n",
              "\n",
              "        Init_Win_bytes_forward  Init_Win_bytes_backward  act_data_pkt_fwd  \\\n",
              "0                          329                       -1                 1   \n",
              "1                          329                       -1                 1   \n",
              "2                          329                       -1                 1   \n",
              "3                          329                       -1                 1   \n",
              "4                          245                       -1                 1   \n",
              "...                        ...                      ...               ...   \n",
              "225740                     288                      253                 0   \n",
              "225741                     288                      253                 0   \n",
              "225742                     288                      253                 0   \n",
              "225743                    4719                       -1                 1   \n",
              "225744                   13140                    64240                 0   \n",
              "\n",
              "        min_seg_size_forward  Active Mean  Active Std  Active Max  Active Min  \\\n",
              "0                         20          0.0         0.0           0           0   \n",
              "1                         20          0.0         0.0           0           0   \n",
              "2                         20          0.0         0.0           0           0   \n",
              "3                         20          0.0         0.0           0           0   \n",
              "4                         20          0.0         0.0           0           0   \n",
              "...                      ...          ...         ...         ...         ...   \n",
              "225740                    20          0.0         0.0           0           0   \n",
              "225741                    20          0.0         0.0           0           0   \n",
              "225742                    20          0.0         0.0           0           0   \n",
              "225743                    20          0.0         0.0           0           0   \n",
              "225744                    20          0.0         0.0           0           0   \n",
              "\n",
              "        Idle Mean  Idle Std  Idle Max  Idle Min   Label  \n",
              "0             0.0       0.0         0         0  BENIGN  \n",
              "1             0.0       0.0         0         0  BENIGN  \n",
              "2             0.0       0.0         0         0  BENIGN  \n",
              "3             0.0       0.0         0         0  BENIGN  \n",
              "4             0.0       0.0         0         0  BENIGN  \n",
              "...           ...       ...       ...       ...     ...  \n",
              "225740        0.0       0.0         0         0  BENIGN  \n",
              "225741        0.0       0.0         0         0  BENIGN  \n",
              "225742        0.0       0.0         0         0  BENIGN  \n",
              "225743        0.0       0.0         0         0  BENIGN  \n",
              "225744        0.0       0.0         0         0  BENIGN  \n",
              "\n",
              "[2830743 rows x 79 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.options.display.max_columns = 80\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSAAWG06ekQn"
      },
      "source": [
        "### 2.2 Data Cleaning\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDdJgFihgVf8"
      },
      "source": [
        "#### Identifying duplicate values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCLMpzvegtHo",
        "outputId": "82144560-876c-447b-f9bb-0d4e5a2eb0e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of duplicates: 308381\n"
          ]
        }
      ],
      "source": [
        "dups = data[data.duplicated()]\n",
        "print(f'Number of duplicates: {len(dups)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZRWCnHg-Rfh",
        "outputId": "0686cdde-07be-4add-dd43-fe664b7733f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2522362, 79)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.drop_duplicates(inplace = True)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R28LNrp5iWR7"
      },
      "source": [
        "#### Identifying missing values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIwPAME64Xvd",
        "outputId": "a7f80264-e534-41e7-f2c9-574b1f441863"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Flow Bytes/s    353\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "missing_val = data.isna().sum()\n",
        "print(missing_val.loc[missing_val > 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w84MJW5o45KG",
        "outputId": "f5975086-f911-4747-89f1-58f8b27a84aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Flow Bytes/s      1211\n",
            "Flow Packets/s    1564\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Checking for infinity values\n",
        "numeric_cols = data.select_dtypes(include = np.number).columns\n",
        "inf_count = np.isinf(data[numeric_cols]).sum()\n",
        "print(inf_count[inf_count > 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIsiR9JC1ccV",
        "outputId": "896135f3-ef18-450a-ca0a-f0e1d3fb62c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial missing values: 353\n",
            "Missing values after processing infinite values: 3128\n"
          ]
        }
      ],
      "source": [
        "# Replacing any infinite values (positive or negative) with NaN (not a number)\n",
        "print(f'Initial missing values: {data.isna().sum().sum()}')\n",
        "\n",
        "data.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
        "\n",
        "print(f'Missing values after processing infinite values: {data.isna().sum().sum()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYdMMTNf3lqD",
        "outputId": "9c0ca587-c913-444f-abd2-73cb53af83d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Flow Bytes/s      1564\n",
            "Flow Packets/s    1564\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "missing = data.isna().sum()\n",
        "print(missing.loc[missing > 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sPt__O_sjCd",
        "outputId": "7e48e48b-78da-45e2-e18c-886626af5760"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                Missing Values  Percentage of Total Values\n",
            "Flow Bytes/s              1564                        0.06\n",
            "Flow Packets/s            1564                        0.06\n"
          ]
        }
      ],
      "source": [
        "# Calculating missing value percentage in the dataset\n",
        "mis_per = (missing / len(data)) * 100\n",
        "mis_table = pd.concat([missing, mis_per.round(2)], axis = 1)\n",
        "mis_table = mis_table.rename(columns = {0 : 'Missing Values', 1 : 'Percentage of Total Values'})\n",
        "\n",
        "print(mis_table.loc[mis_per > 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xf9z8Pwlid-3"
      },
      "source": [
        "#### Visualisation of missing data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DibPfnKeXAWS",
        "outputId": "ed29aa4d-4496-46e1-f66c-9a7fd861b7a2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 200x600 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.set_palette('pastel')\n",
        "colors = sns.color_palette()\n",
        "\n",
        "missing_vals = [col for col in data.columns if data[col].isna().any()]\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (2, 6))\n",
        "msno.bar(data[missing_vals], ax = ax, fontsize = 12, color = colors)\n",
        "ax.set_xlabel('Features', fontsize = 12)\n",
        "ax.set_ylabel('Non-Null Value Count', fontsize = 12)\n",
        "ax.set_title('Missing Value Chart', fontsize = 12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXWOYP6-ieI0"
      },
      "source": [
        "#### Dealing with missing values (Columns with missing data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "E_wW5arHZUo5",
        "outputId": "50e328dc-a2b8-44a0-fe00-3a2c664daf36"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "cannot reindex on an axis with duplicate labels",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m plt.figure(figsize = (\u001b[32m8\u001b[39m, \u001b[32m3\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43msns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mboxplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mFlow Bytes/s\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mBoxplot of Flow Bytes/s\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m plt.show()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/TelecomSE/FISE2/Semestre 7/Projet/AdversarialNIDS/.venv/lib/python3.12/site-packages/seaborn/categorical.py:1634\u001b[39m, in \u001b[36mboxplot\u001b[39m\u001b[34m(data, x, y, hue, order, hue_order, orient, color, palette, saturation, fill, dodge, width, gap, whis, linecolor, linewidth, fliersize, hue_norm, native_scale, log_scale, formatter, legend, ax, **kwargs)\u001b[39m\n\u001b[32m   1627\u001b[39m color = _default_color(\n\u001b[32m   1628\u001b[39m     ax.fill_between, hue, color,\n\u001b[32m   1629\u001b[39m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mc\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcolor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfc\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfacecolor\u001b[39m\u001b[33m\"\u001b[39m]},\n\u001b[32m   1630\u001b[39m     saturation=saturation,\n\u001b[32m   1631\u001b[39m )\n\u001b[32m   1632\u001b[39m linecolor = p._complement_color(linecolor, color, p._hue_map)\n\u001b[32m-> \u001b[39m\u001b[32m1634\u001b[39m \u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot_boxes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1635\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1636\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdodge\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdodge\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1637\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1638\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfill\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1639\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwhis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1640\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1641\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlinecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlinecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1642\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1643\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfliersize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfliersize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1644\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplot_kws\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1645\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1647\u001b[39m p._add_axis_labels(ax)\n\u001b[32m   1648\u001b[39m p._adjust_cat_axis(ax, axis=p.orient)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/TelecomSE/FISE2/Semestre 7/Projet/AdversarialNIDS/.venv/lib/python3.12/site-packages/seaborn/categorical.py:631\u001b[39m, in \u001b[36m_CategoricalPlotter.plot_boxes\u001b[39m\u001b[34m(self, width, dodge, gap, fill, whis, color, linecolor, linewidth, fliersize, plot_kws)\u001b[39m\n\u001b[32m    627\u001b[39m props[\u001b[33m\"\u001b[39m\u001b[33mflier\u001b[39m\u001b[33m\"\u001b[39m].setdefault(\u001b[33m\"\u001b[39m\u001b[33mmarkersize\u001b[39m\u001b[33m\"\u001b[39m, fliersize)\n\u001b[32m    629\u001b[39m ax = \u001b[38;5;28mself\u001b[39m.ax\n\u001b[32m--> \u001b[39m\u001b[32m631\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msub_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43miter_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43mfrom_comp_data\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m    \u001b[49m\u001b[43max\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_axes\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrouped\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43morient\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvalue_var\u001b[49m\u001b[43m]\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/TelecomSE/FISE2/Semestre 7/Projet/AdversarialNIDS/.venv/lib/python3.12/site-packages/seaborn/_base.py:902\u001b[39m, in \u001b[36mVectorPlotter.iter_data\u001b[39m\u001b[34m(self, grouping_vars, reverse, from_comp_data, by_facet, allow_empty, dropna)\u001b[39m\n\u001b[32m    899\u001b[39m grouping_vars = [var \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m grouping_vars \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.variables]\n\u001b[32m    901\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m from_comp_data:\n\u001b[32m--> \u001b[39m\u001b[32m902\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcomp_data\u001b[49m\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    904\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.plot_data\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/TelecomSE/FISE2/Semestre 7/Projet/AdversarialNIDS/.venv/lib/python3.12/site-packages/seaborn/_base.py:1007\u001b[39m, in \u001b[36mVectorPlotter.comp_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1005\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1006\u001b[39m             comp_col = pd.Series(dtype=\u001b[38;5;28mfloat\u001b[39m, name=var)\n\u001b[32m-> \u001b[39m\u001b[32m1007\u001b[39m         \u001b[43mcomp_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomp_col\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28mself\u001b[39m._comp_data = comp_data\n\u001b[32m   1011\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._comp_data\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/TelecomSE/FISE2/Semestre 7/Projet/AdversarialNIDS/.venv/lib/python3.12/site-packages/pandas/core/frame.py:5193\u001b[39m, in \u001b[36mDataFrame.insert\u001b[39m\u001b[34m(self, loc, column, value, allow_duplicates)\u001b[39m\n\u001b[32m   5190\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[32m   5191\u001b[39m     value = value.iloc[:, \u001b[32m0\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m5193\u001b[39m value, refs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5194\u001b[39m \u001b[38;5;28mself\u001b[39m._mgr.insert(loc, column, value, refs=refs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/TelecomSE/FISE2/Semestre 7/Projet/AdversarialNIDS/.venv/lib/python3.12/site-packages/pandas/core/frame.py:5285\u001b[39m, in \u001b[36mDataFrame._sanitize_column\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m   5283\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Series):\n\u001b[32m   5284\u001b[39m         value = Series(value)\n\u001b[32m-> \u001b[39m\u001b[32m5285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_reindex_for_setitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[32m   5288\u001b[39m     com.require_length_match(value, \u001b[38;5;28mself\u001b[39m.index)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/TelecomSE/FISE2/Semestre 7/Projet/AdversarialNIDS/.venv/lib/python3.12/site-packages/pandas/core/frame.py:12719\u001b[39m, in \u001b[36m_reindex_for_setitem\u001b[39m\u001b[34m(value, index)\u001b[39m\n\u001b[32m  12715\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m  12716\u001b[39m     \u001b[38;5;66;03m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n\u001b[32m  12717\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value.index.is_unique:\n\u001b[32m  12718\u001b[39m         \u001b[38;5;66;03m# duplicate axis\u001b[39;00m\n\u001b[32m> \u001b[39m\u001b[32m12719\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m  12721\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m  12722\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mincompatible index of inserted column with frame index\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m  12723\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m  12724\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m reindexed_value, \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/TelecomSE/FISE2/Semestre 7/Projet/AdversarialNIDS/.venv/lib/python3.12/site-packages/pandas/core/frame.py:12714\u001b[39m, in \u001b[36m_reindex_for_setitem\u001b[39m\u001b[34m(value, index)\u001b[39m\n\u001b[32m  12712\u001b[39m \u001b[38;5;66;03m# GH#4107\u001b[39;00m\n\u001b[32m  12713\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m> \u001b[39m\u001b[32m12714\u001b[39m     reindexed_value = \u001b[43mvalue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m._values\n\u001b[32m  12715\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m  12716\u001b[39m     \u001b[38;5;66;03m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n\u001b[32m  12717\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value.index.is_unique:\n\u001b[32m  12718\u001b[39m         \u001b[38;5;66;03m# duplicate axis\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/TelecomSE/FISE2/Semestre 7/Projet/AdversarialNIDS/.venv/lib/python3.12/site-packages/pandas/core/series.py:5172\u001b[39m, in \u001b[36mSeries.reindex\u001b[39m\u001b[34m(self, index, axis, method, copy, level, fill_value, limit, tolerance)\u001b[39m\n\u001b[32m   5155\u001b[39m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[32m   5156\u001b[39m     NDFrame.reindex,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m   5157\u001b[39m     klass=_shared_doc_kwargs[\u001b[33m\"\u001b[39m\u001b[33mklass\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   5170\u001b[39m     tolerance=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5171\u001b[39m ) -> Series:\n\u001b[32m-> \u001b[39m\u001b[32m5172\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/TelecomSE/FISE2/Semestre 7/Projet/AdversarialNIDS/.venv/lib/python3.12/site-packages/pandas/core/generic.py:5632\u001b[39m, in \u001b[36mNDFrame.reindex\u001b[39m\u001b[34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[39m\n\u001b[32m   5629\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._reindex_multi(axes, copy, fill_value)\n\u001b[32m   5631\u001b[39m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5632\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reindex_axes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5633\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[32m   5634\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mreindex\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/TelecomSE/FISE2/Semestre 7/Projet/AdversarialNIDS/.venv/lib/python3.12/site-packages/pandas/core/generic.py:5655\u001b[39m, in \u001b[36mNDFrame._reindex_axes\u001b[39m\u001b[34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[39m\n\u001b[32m   5652\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   5654\u001b[39m ax = \u001b[38;5;28mself\u001b[39m._get_axis(a)\n\u001b[32m-> \u001b[39m\u001b[32m5655\u001b[39m new_index, indexer = \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5656\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\n\u001b[32m   5657\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5659\u001b[39m axis = \u001b[38;5;28mself\u001b[39m._get_axis_number(a)\n\u001b[32m   5660\u001b[39m obj = obj._reindex_with_indexers(\n\u001b[32m   5661\u001b[39m     {axis: [new_index, indexer]},\n\u001b[32m   5662\u001b[39m     fill_value=fill_value,\n\u001b[32m   5663\u001b[39m     copy=copy,\n\u001b[32m   5664\u001b[39m     allow_dups=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   5665\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/TelecomSE/FISE2/Semestre 7/Projet/AdversarialNIDS/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:4436\u001b[39m, in \u001b[36mIndex.reindex\u001b[39m\u001b[34m(self, target, method, level, limit, tolerance)\u001b[39m\n\u001b[32m   4433\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot handle a non-unique multi-index!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4434\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_unique:\n\u001b[32m   4435\u001b[39m     \u001b[38;5;66;03m# GH#42568\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4436\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4437\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4438\u001b[39m     indexer, _ = \u001b[38;5;28mself\u001b[39m.get_indexer_non_unique(target)\n",
            "\u001b[31mValueError\u001b[39m: cannot reindex on an axis with duplicate labels"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize = (8, 3))\n",
        "sns.boxplot(x = data['Flow Bytes/s'])\n",
        "plt.xlabel('Boxplot of Flow Bytes/s')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vqQzdH7ccwv0",
        "outputId": "6ab7b050-df82-44e4-8529-7ae675baf01b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "colors = sns.color_palette('Blues')\n",
        "plt.hist(data['Flow Bytes/s'], color = colors[1])\n",
        "plt.title('Histogram of Flow Bytes/s')\n",
        "plt.xlabel('Flow Bytes/s')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kjaJVgULdCZx",
        "outputId": "1aaa647d-b19d-4db6-b538-8c17e911f5b1"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (8, 3))\n",
        "sns.boxplot(x = data['Flow Packets/s'])\n",
        "plt.xlabel('Boxplot of Flow Packets/s')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KVYQ07HvdOby",
        "outputId": "4396ca68-3ecf-4831-fb45-7cdc080648a4"
      },
      "outputs": [],
      "source": [
        "plt.hist(data['Flow Packets/s'], color = colors[1])\n",
        "plt.title('Histogram of Flow Packets/s')\n",
        "plt.xlabel('Flow Packets/s')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMitp-BBZvl8",
        "outputId": "118f84b0-410c-4a16-a2ac-acc297a32e92"
      },
      "outputs": [],
      "source": [
        "med_flow_bytes = data['Flow Bytes/s'].median()\n",
        "med_flow_packets = data['Flow Packets/s'].median()\n",
        "\n",
        "print('Median of Flow Bytes/s: ', med_flow_bytes)\n",
        "print('Median of Flow Packets/s: ', med_flow_packets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4_mBQswOvNE"
      },
      "outputs": [],
      "source": [
        "# Filling missing values with median\n",
        "data['Flow Bytes/s'].fillna(med_flow_bytes, inplace = True)\n",
        "data['Flow Packets/s'].fillna(med_flow_packets, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryxi5CZzayJq",
        "outputId": "b9ddfc62-4040-4580-9d40-77e7dca58562"
      },
      "outputs": [],
      "source": [
        "print('Number of \\'Flow Bytes/s\\' missing values:', data['Flow Bytes/s'].isna().sum())\n",
        "print('Number of \\'Flow Packets/s\\' missing values:', data['Flow Packets/s'].isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rIU56yNiPxq"
      },
      "source": [
        "- The first step is to identify duplicate rows and missing or invalid values. We\n",
        "identified and dropped the duplicate rows (308381 rows). From the data description, we identified that the dataset has infinity values. So, we checked and replaced the positive or negative infinity values with NaN (not a number) and counted it as a missing value. In the dataset, two features, FlowBytes/s, and Flow Packets/s contain missing values. For both columns, the number of missing values is 1564 which is 0.06% of total values.\n",
        "\n",
        "- Flow Bytes/s and Flow Packets/s are continuous variables. We can see from the Flow Bytes/s and Flow Packets/s histogram and box plot that the majority of values are towards one area which indicates that the data is not normally distributed. The box plot of the Flow Bytes/s and Flow Packets/s shows that the variables have extreme values or outliers. So, our strategy is to fill in missing values with median value. Because, filling the missing values with the median does not introduce any new categories or disrupt the distribution of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsSwQ-DOvm-6"
      },
      "source": [
        "### 2.3 Analysing Patterns using Visualisations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGkxFBOYv5Gt"
      },
      "source": [
        "#### Visualization of column correlation. Also, plotting Heat Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6no9oLuBvnST",
        "outputId": "ae75dd0c-010d-4383-e21a-95fc1f775d01"
      },
      "outputs": [],
      "source": [
        "data['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c-cQD00vuL5",
        "outputId": "2417238c-b9cd-4685-f677-680eec2ff636"
      },
      "outputs": [],
      "source": [
        "# Types of attacks & normal instances (BENIGN)\n",
        "data['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lt1zWoqUwKa0"
      },
      "outputs": [],
      "source": [
        "# Creating a dictionary that maps each label to its attack type\n",
        "attack_map = {\n",
        "    'BENIGN': 'BENIGN',\n",
        "    'DDoS': 'DDoS',\n",
        "    'DoS Hulk': 'DoS',\n",
        "    'DoS GoldenEye': 'DoS',\n",
        "    'DoS slowloris': 'DoS',\n",
        "    'DoS Slowhttptest': 'DoS',\n",
        "    'PortScan': 'Port Scan',\n",
        "    'FTP-Patator': 'Brute Force',\n",
        "    'SSH-Patator': 'Brute Force',\n",
        "    'Bot': 'Bot',\n",
        "    'Web Attack  Brute Force': 'Web Attack',\n",
        "    'Web Attack  XSS': 'Web Attack',\n",
        "    'Web Attack  Sql Injection': 'Web Attack',\n",
        "    'Infiltration': 'Infiltration',\n",
        "    'Heartbleed': 'Heartbleed'\n",
        "}\n",
        "\n",
        "# Creating a new column 'Attack Type' in the DataFrame based on the attack_map dictionary\n",
        "data['Attack Type'] = data['Label'].map(attack_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWLCTLRyxxW0",
        "outputId": "98919350-b090-45f2-cd23-b8ab201e52bc"
      },
      "outputs": [],
      "source": [
        "data['Attack Type'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4tyKwUlwTPw"
      },
      "outputs": [],
      "source": [
        "data.drop('Label', axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fId7C3nUyNZ1",
        "outputId": "daf54ba2-fcd0-4947-ba0f-29fd4a15c6ec"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "data['Attack Number'] = le.fit_transform(data['Attack Type'])\n",
        "\n",
        "print(data['Attack Number'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJhWdou_yN9-",
        "outputId": "6f096b16-3ee8-492e-c068-8d2eec5f24f0"
      },
      "outputs": [],
      "source": [
        "# Printing corresponding attack type for each encoded value\n",
        "encoded_values = data['Attack Number'].unique()\n",
        "for val in sorted(encoded_values):\n",
        "    print(f\"{val}: {le.inverse_transform([val])[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_O1N0PzUyOIq",
        "outputId": "ffdb9756-324b-4a50-eacd-2f73b15647c4"
      },
      "outputs": [],
      "source": [
        "corr = data.corr(numeric_only = True).round(2)\n",
        "corr.style.background_gradient(cmap = 'coolwarm', axis = None).format(precision = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eejPjRDA1OBq",
        "outputId": "e64a1935-3898-49b1-873f-c09e368990fd"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize = (24, 24))\n",
        "sns.heatmap(corr, cmap = 'coolwarm', annot = False, linewidth = 0.5)\n",
        "plt.title('Correlation Matrix', fontsize = 18)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0xq3ZryyOUL",
        "outputId": "a98c358f-2f09-43a9-ef03-a60453ee4c02"
      },
      "outputs": [],
      "source": [
        "# Positive correlation features for 'Attack Number'\n",
        "pos_corr_features = corr['Attack Number'][(corr['Attack Number'] > 0) & (corr['Attack Number'] < 1)].index.tolist()\n",
        "\n",
        "print(\"Features with positive correlation with 'Attack Number':\\n\")\n",
        "for i, feature in enumerate(pos_corr_features, start = 1):\n",
        "    corr_value = corr.loc[feature, 'Attack Number']\n",
        "    print('{:<3} {:<24} :{}'.format(f'{i}.', feature, corr_value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_ahQcNdyOgI",
        "outputId": "4a6021a1-1268-45e7-83e6-75b229e616fc"
      },
      "outputs": [],
      "source": [
        "print(f'Number of considerable important features: {len(pos_corr_features)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUxccTMBPvdJ",
        "outputId": "6384f31c-3195-4bcc-c88c-24843cef363b"
      },
      "outputs": [],
      "source": [
        "# Checking for columns with zero standard deviation (the blank squares in the heatmap)\n",
        "std = data.std(numeric_only = True)\n",
        "zero_std_cols = std[std == 0].index.tolist()\n",
        "zero_std_cols"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqV63kz3OesE"
      },
      "source": [
        "- We mapped each label to the corresponding attack type. This groups similar attacks together and provides an easier and more interpretable way to analyze the dataset and identify patterns in the different types of attacks.\n",
        "\n",
        "- For plotting the correlation matrix, we encoded the 'Attack Type' column and plotted the heatmap. From the heatmap, we observe that there are many pairs of highly correlated features. Highly correlated features in the dataset are problematic and lead to overfitting. A positive correlation exists when one variable decreases as the other variable decreases or one variable increases while the other increases. There are 32 features with positive correlations that may help in predicting the target feature.\n",
        "\n",
        "- The columns with zero standard deviation have the same value in all rows. These columns don't have any variance. It simply means that there is no meaningful relationship with any other columns which results in NaN correlation cofficient. These columns cannot help differentiate between the classes or groups of data. So, these zero standard deviation columns don't contribute to the correlation matrix and will appear blank in the heatmap. This can be helpful while doing data processing as we may drop the columns if we find out that these columns has no variation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uDiDKokwPhS"
      },
      "source": [
        "#### Visualization of Linear Relationships of columns (Continuous Numerical Variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kg3zyroTrKO",
        "outputId": "0f706a60-66a4-428c-9fc7-99cf5a66127f"
      },
      "outputs": [],
      "source": [
        "# Data sampling for data analysis\n",
        "sample_size = int(0.2 * len(data)) # 20% of the original size\n",
        "sampled_data = data.sample(n = sample_size, replace = False, random_state = 0)\n",
        "sampled_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMglBEJeT5Xk",
        "outputId": "445de183-196b-4615-e6bc-871aa2669c82"
      },
      "outputs": [],
      "source": [
        "# To assess if a sample is representative of the population and comparison of descriptive statistics (mean)\n",
        "numeric_cols = data.select_dtypes(include = [np.number]).columns.tolist()\n",
        "print('Descriptive Statistics Comparison (mean):\\n')\n",
        "print('{:<32s}{:<22s}{:<22s}{}'.format('Feature', 'Original Dataset', 'Sampled Dataset', 'Variation Percentage'))\n",
        "print('-' * 96)\n",
        "\n",
        "high_variations = []\n",
        "for col in numeric_cols:\n",
        "    old = data[col].describe()[1]\n",
        "    new = sampled_data[col].describe()[1]\n",
        "    if old == 0:\n",
        "        pct = 0\n",
        "    else:\n",
        "        pct = abs((new - old) / old)\n",
        "    if pct * 100 > 5:\n",
        "        high_variations.append((col, pct * 100))\n",
        "    print('{:<32s}{:<22.6f}{:<22.6f}{:<2.2%}'.format(col, old, new, pct))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "vFX4uTA5UflZ",
        "outputId": "eafd0dbe-3516-4715-abc3-c68e7c8b2268"
      },
      "outputs": [],
      "source": [
        "labels = [t[0] for t in high_variations]\n",
        "values = [t[1] for t in high_variations]\n",
        "\n",
        "colors = sns.color_palette('Blues', n_colors=len(labels))\n",
        "fig, ax = plt.subplots(figsize = (10, 5))\n",
        "ax.bar(labels, values, color = colors)\n",
        "\n",
        "for i in range(len(labels)):\n",
        "    ax.text(i, values[i], str(round(values[i], 2)), ha = 'center', va = 'bottom', fontsize = 10)\n",
        "\n",
        "plt.xticks(rotation = 90)\n",
        "ax.set_title('Variation percenatge of the features of the sample which\\n mean value variates higher than 5% of the actual mean')\n",
        "ax.set_ylabel('Percentage (%)')\n",
        "ax.set_yticks(np.arange(0, 41, 5))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaTNH4jv0CTq",
        "outputId": "392895a3-b854-4640-8141-b60e39655e05"
      },
      "outputs": [],
      "source": [
        "# Printing the unique value count\n",
        "indent = '{:<3} {:<30}: {}'\n",
        "print('Unique value count for: ')\n",
        "for i, feature in enumerate(list(sampled_data.columns)[:-1], start = 1):\n",
        "    print(indent.format(f'{i}.', feature, sampled_data[feature].nunique()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g4ujCskP0Hbf",
        "outputId": "b3dbd7f2-191b-4a68-a6a6-84aa3b5532fd"
      },
      "outputs": [],
      "source": [
        "'''Generating a set of visualizations for columns that have more than one unique value but less than 50 unique values.\n",
        "For categorical columns, a bar plot is generated showing the count of each unique value.\n",
        "For numerical columns, a histogram is generated.'''\n",
        "unique_values = sampled_data.nunique()\n",
        "selected_cols = sampled_data[[col for col in sampled_data if 1 < unique_values[col] < 50]]\n",
        "rows, cols = selected_cols.shape\n",
        "col_names = list(selected_cols)\n",
        "num_of_rows = (cols + 3) // 4\n",
        "\n",
        "color_palette = sns.color_palette('Blues', n_colors = 3)\n",
        "plt.figure(figsize = (6 * 4, 8 * num_of_rows))\n",
        "\n",
        "for i in range(cols):\n",
        "    plt.subplot(num_of_rows, 4, i + 1)\n",
        "    col_data = selected_cols.iloc[:, i]\n",
        "    if col_data.dtype.name == 'object':\n",
        "        col_data.value_counts().plot(kind = 'bar', color = color_palette[2])\n",
        "    else:\n",
        "        col_data.hist(color = color_palette[0])\n",
        "\n",
        "    plt.ylabel('Count')\n",
        "    plt.xticks(rotation = 90)\n",
        "    plt.title(col_names[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_Lj5L_2RUvTf",
        "outputId": "24406221-4358-4b28-dc47-625d5b619fc4"
      },
      "outputs": [],
      "source": [
        "# Correlation matrix for sampled data\n",
        "corr_matrix = sampled_data.corr(numeric_only = True).round(2)\n",
        "corr_matrix.style.background_gradient(cmap = 'coolwarm', axis = None).format(precision = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "16eLCj4YVFw-",
        "outputId": "58b7e8c4-8a39-47a1-908e-1ef86c733a1b"
      },
      "outputs": [],
      "source": [
        "# Plotting the pairs of strongly positive correlated features in the sampled_data that have a correlation coefficient of 0.85 or higher\n",
        "cols = list(sampled_data.columns)[:-2]\n",
        "high_corr_pairs = []\n",
        "corr_th = 0.85\n",
        "\n",
        "for i in range(len(cols)):\n",
        "  for j in range(i + 1, len(cols)):\n",
        "    val = sampled_data[cols[i]].corr(sampled_data[cols[j]])\n",
        "    # If the correlation coefficient is NaN or below the threshold, skip to the next pair\n",
        "    if np.isnan(val) or val < corr_th:\n",
        "      continue\n",
        "    high_corr_pairs.append((val, cols[i], cols[j]))\n",
        "\n",
        "size, cols = len(high_corr_pairs), 4\n",
        "rows, rem =  size // cols, size % cols\n",
        "if rem:\n",
        "  rows += 1\n",
        "\n",
        "fig, axs = plt.subplots(rows, cols, figsize = (24, int(size * 1.7)))\n",
        "for i in range(rows):\n",
        "    for j in range(cols):\n",
        "      try:\n",
        "        val, x, y = high_corr_pairs[i * cols + j]\n",
        "        if val > 0.99:\n",
        "          axs[i, j].scatter(sampled_data[x], sampled_data[y], color = 'green', alpha = 0.1)\n",
        "        else:\n",
        "          axs[i, j].scatter(sampled_data[x], sampled_data[y], color = 'blue', alpha = 0.1)\n",
        "        axs[i, j].set_xlabel(x)\n",
        "        axs[i, j].set_ylabel(y)\n",
        "        axs[i, j].set_title(f'{x} vs\\n{y} ({val:.2f})')\n",
        "      except IndexError:\n",
        "        fig.delaxes(axs[i, j])\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkXVvSrux4i8"
      },
      "outputs": [],
      "source": [
        "sampled_data.drop('Attack Number', axis = 1, inplace = True)\n",
        "data.drop('Attack Number', axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRehOiWZuvvF",
        "outputId": "8a5b6661-189b-41c7-dd21-d93f9c006c65"
      },
      "outputs": [],
      "source": [
        "# Identifying outliers\n",
        "numeric_data = sampled_data.select_dtypes(include = ['float', 'int'])\n",
        "q1 = numeric_data.quantile(0.25)\n",
        "q3 = numeric_data.quantile(0.75)\n",
        "iqr = q3 - q1\n",
        "outlier = (numeric_data < (q1 - 1.5 * iqr)) | (numeric_data > (q3 + 1.5 * iqr))\n",
        "outlier_count = outlier.sum()\n",
        "outlier_percentage = round(outlier.mean() * 100, 2)\n",
        "outlier_stats = pd.concat([outlier_count, outlier_percentage], axis = 1)\n",
        "outlier_stats.columns = ['Outlier Count', 'Outlier Percentage']\n",
        "\n",
        "print(outlier_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xtY6mgJuxqt",
        "outputId": "cae39d72-fa71-4f0f-ee21-c75d6bf0c4c9"
      },
      "outputs": [],
      "source": [
        "# Identifying outliers based on attack type\n",
        "outlier_counts = {}\n",
        "for i in numeric_data:\n",
        "    for attack_type in sampled_data['Attack Type'].unique():\n",
        "        attack_data = sampled_data[i][sampled_data['Attack Type'] == attack_type]\n",
        "        q1, q3 = np.percentile(attack_data, [25, 75])\n",
        "        iqr = q3 - q1\n",
        "        lower_bound = q1 - 1.5 * iqr\n",
        "        upper_bound = q3 + 1.5 * iqr\n",
        "        num_outliers = ((attack_data < lower_bound) | (attack_data > upper_bound)).sum()\n",
        "        outlier_percent = num_outliers / len(attack_data) * 100\n",
        "        outlier_counts[(i, attack_type)] = (num_outliers, outlier_percent)\n",
        "\n",
        "for i in numeric_data:\n",
        "  print(f'Feature: {i}')\n",
        "  for attack_type in sampled_data['Attack Type'].unique():\n",
        "    num_outliers, outlier_percent = outlier_counts[(i, attack_type)]\n",
        "    print(f'- {attack_type}: {num_outliers} ({outlier_percent:.2f}%)')\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        },
        "id": "tUUeIrRSvI73",
        "outputId": "097a8369-463e-4a0b-bbd9-53a35186bc5d"
      },
      "outputs": [],
      "source": [
        "# Plotting the percentage of outliers that are higher than 20%\n",
        "fig, ax = plt.subplots(figsize = (24, 10))\n",
        "for i in numeric_data:\n",
        "    for attack_type in sampled_data['Attack Type'].unique():\n",
        "        num_outliers, outlier_percent = outlier_counts[(i, attack_type)]\n",
        "        if outlier_percent > 20:\n",
        "            ax.bar(f'{i} - {attack_type}', outlier_percent)\n",
        "\n",
        "ax.set_xlabel('Feature-Attack Type')\n",
        "ax.set_ylabel('Percentage of Outliers')\n",
        "ax.set_title('Outlier Analysis')\n",
        "ax.set_yticks(np.arange(0, 41, 10))\n",
        "plt.xticks(rotation = 90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tlRhXeZoze8"
      },
      "source": [
        "- As we have a large dataset, it was both time-consuming and computationally expensive to do all the analysis on the original-sized dataset. Therefore, we sampled 20% of the dataset to do our computationally expensive analysis. We also assessed whether the sample is representative of the population by doing a comparison of descriptive statistics (mean) and features that variates 5%\n",
        "higher than the actual mean values of the dataset.\n",
        "\n",
        "- A histogram for numerical columns and a bar plot for categorical columns are generated that have more than one unique value and less than 50 unique values. The plots visualize the distribution of data in a quick and easier way. This visualizes patterns like the distribution of values in numerical columns and common categories in categorical columns. It is used to understand the relationships between different variables and identify anomalies in the data.\n",
        "\n",
        "- The scatter plots show the relationship between strongly positive correlated features with a correlation coefficient of 0.85 or higher. Blue scatter plot points show the correlation coefficient pairs less than 0.99 and green scatter plot points show the pairs with 0.99 or almost 1.0. From these plots, we can visualize linear relationships between the features or identify indications of multicollinearity between features where two or more predictors are highly correlated. Highly correlated features introduce multicollinearity which causes problems for machine learning algorithms because it assumes that the features are independent. From some of the plots, we can see that there is a tight cluster of data points around\n",
        "the straight line where the correlation coefficient is close to 1.\n",
        "\n",
        "- We identified the outliers of each feature based on attack types and found that this dataset contains many outliers. Outliers increase variability in the dataset. But in the dataset, outliers may indicate different patterns like network intrusion attempts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iYfyW2-yyAR"
      },
      "source": [
        "#### Visualization of column relationships (Categorical Variables)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrzKgheVy967"
      },
      "source": [
        "All the features in our dataset is numerical. We have one Categorical Variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "gVvkohfgBMCT",
        "outputId": "4f875e7d-93fa-4a72-cd23-fe1cf3f08bca"
      },
      "outputs": [],
      "source": [
        "# Different 'Attack Type' in the main dataset excluding 'BENIGN'\n",
        "attacks = data.loc[data['Attack Type'] != 'BENIGN']\n",
        "\n",
        "plt.figure(figsize = (10, 6))\n",
        "ax = sns.countplot(x = 'Attack Type', data = attacks, palette = 'pastel', order = attacks['Attack Type'].value_counts().index)\n",
        "plt.title('Types of attacks')\n",
        "plt.xlabel('Attack Type')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation = 90)\n",
        "\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{p.get_height():.0f}', (p.get_x() + p.get_width() / 2, p.get_height() + 1000), ha = 'center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "_PQc5IIUBM0o",
        "outputId": "92a36639-36f4-45c4-d4a6-303e86128ba1"
      },
      "outputs": [],
      "source": [
        "attack_counts = attacks['Attack Type'].value_counts()\n",
        "threshold = 0.005\n",
        "percentages = attack_counts / attack_counts.sum()\n",
        "small_slices = percentages[percentages < threshold].index.tolist()\n",
        "attack_counts['Other'] = attack_counts[small_slices].sum()\n",
        "attack_counts.drop(small_slices, inplace = True)\n",
        "\n",
        "sns.set_palette('pastel')\n",
        "plt.figure(figsize = (8, 8))\n",
        "plt.pie(attack_counts.values, labels = attack_counts.index, autopct = '%1.1f%%', textprops={'fontsize': 6})\n",
        "plt.title('Distribution of Attack Types')\n",
        "plt.legend(attack_counts.index, loc = 'best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Pxl8l92KBn2Y",
        "outputId": "b1c0d5d7-a759-49bc-8ccc-48c63a4a1784"
      },
      "outputs": [],
      "source": [
        "# Creating a boxplot for each attack type with the columns of sampled dataset\n",
        "for attack_type in sampled_data['Attack Type'].unique():\n",
        "    attack_data = sampled_data[sampled_data['Attack Type'] == attack_type]\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    sns.boxplot(data = attack_data.drop(columns = ['Attack Type']), orient = 'h')\n",
        "    plt.title(f'Boxplot of Features for Attack Type: {attack_type}')\n",
        "    plt.xlabel('Feature Value')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "ZRhokdjOBU1F",
        "outputId": "49cf3e10-cf3f-4c3b-c9cf-6bd27efb0daf"
      },
      "outputs": [],
      "source": [
        "data.groupby('Attack Type').first()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ9tbZTRxHVU"
      },
      "source": [
        "## 3. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNRw8GcEQ-st"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAqW7PSTnsf-",
        "outputId": "fceb4cd3-0a18-4dfc-b83b-3ef55de730e0"
      },
      "outputs": [],
      "source": [
        "# For improving performance and reduce memory-related errors\n",
        "old_memory_usage = data.memory_usage().sum() / 1024 ** 2\n",
        "print(f'Initial memory usage: {old_memory_usage:.2f} MB')\n",
        "for col in data.columns:\n",
        "    col_type = data[col].dtype\n",
        "    if col_type != object:\n",
        "        c_min = data[col].min()\n",
        "        c_max = data[col].max()\n",
        "        # Downcasting float64 to float32\n",
        "        if str(col_type).find('float') >= 0 and c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "            data[col] = data[col].astype(np.float32)\n",
        "\n",
        "        # Downcasting int64 to int32\n",
        "        elif str(col_type).find('int') >= 0 and c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "            data[col] = data[col].astype(np.int32)\n",
        "\n",
        "new_memory_usage = data.memory_usage().sum() / 1024 ** 2\n",
        "print(f\"Final memory usage: {new_memory_usage:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncQeTyOOpl1N",
        "outputId": "4f1136d4-55fe-4f85-f6f3-31b10d1bc236"
      },
      "outputs": [],
      "source": [
        "# Calculating percentage reduction in memory usage\n",
        "print(f'Reduced memory usage: {1 - (new_memory_usage / old_memory_usage):.2%}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCZ4UmTaB_I7",
        "outputId": "5c1bce54-bba4-4a72-b07b-8b3a974190d2"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vFidCf0oqvii",
        "outputId": "cbf2228b-484f-4c7e-e43b-781afa3870b6"
      },
      "outputs": [],
      "source": [
        "data.describe().transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5AkJSL0kGX2",
        "outputId": "7c5f500a-4769-493b-c362-2c18872e30aa"
      },
      "outputs": [],
      "source": [
        "# Dropping columns with only one unique value\n",
        "num_unique = data.nunique()\n",
        "one_variable = num_unique[num_unique == 1]\n",
        "not_one_variable = num_unique[num_unique > 1].index\n",
        "\n",
        "dropped_cols = one_variable.index\n",
        "data = data[not_one_variable]\n",
        "\n",
        "print('Dropped columns:')\n",
        "dropped_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA8wz7Y0kj0g",
        "outputId": "1edcb84e-0212-4051-f446-bdb6789e008a"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R4OKANLsibW",
        "outputId": "c4cb0c23-8ccb-49f3-8a2f-6f44c030e9c6"
      },
      "outputs": [],
      "source": [
        "# Columns after removing non variant columns\n",
        "data.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "482NezsW-1Ua"
      },
      "source": [
        "- To improve performance and reduce the risk of memory-related errors (mostly session crashes), we downcasted the float and integer values based on the presence of the minimum and maximum values and reduced memory usage by 47.5%.\n",
        "\n",
        "- The columns with zero standard deviation have the same value in all rows.\n",
        "These columns don't have any variance. It simply means that there is no meaningful relationship with any other columns. These columns cannot help differentiate between the classes or groups of data. So, we dropped the columns that have no variation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk2Kas03g1V3"
      },
      "source": [
        "### Applying PCA to reduce dimensions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZfQoEn1LO49"
      },
      "source": [
        "A simple and effective way to reduce the dimensionality of the dataset and improve the performance of the model is to use strongly correlated features. We used label encoding on the target feature where the numerical values assigned to each category do not have inherent meaning and they are arbitrary. For this reason, the correlation matrix calculated using label-encoded variables may not accurately reflect the true relationships between the variables.\n",
        "\n",
        "So, a more flexible approach to feature selection can be PCA. PCA is a technique that transforms original set of variables into a smaller set of uncorrelated variables, called principal components.\n",
        "\n",
        "PCA can capture more complex relationships between variables that may not be evident from correlation matrix analysis. It can also help to reduce the risk of overfitting.\n",
        "\n",
        "Here, we applied Incremental PCA. Incremental PCA is a variant of PCA that allows for the efficient computation of principal components of a large dataset that cannot be stored in memory.\n",
        "\n",
        "We applied StandardScaler before performing Incremental PCA to standardize the data values into a standard format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4tIrp4FCiw0"
      },
      "outputs": [],
      "source": [
        "# Standardizing the dataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "features = data.drop('Attack Type', axis = 1)\n",
        "attacks = data['Attack Type']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ADsMJMUgI-z",
        "outputId": "09ed3ea9-cc30-4e51-b110-fc440a681854"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import IncrementalPCA\n",
        "\n",
        "size = len(features.columns) // 2\n",
        "ipca = IncrementalPCA(n_components = size, batch_size = 500)\n",
        "for batch in np.array_split(scaled_features, len(features) // 500):\n",
        "    ipca.partial_fit(batch)\n",
        "\n",
        "print(f'information retained: {sum(ipca.explained_variance_ratio_):.2%}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTOr8TbKqZWw"
      },
      "outputs": [],
      "source": [
        "transformed_features = ipca.transform(scaled_features)\n",
        "new_data = pd.DataFrame(transformed_features, columns = [f'PC{i+1}' for i in range(size)])\n",
        "new_data['Attack Type'] = attacks.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "qe-2NiIhSvdM",
        "outputId": "22f2b674-27f6-4295-dd8f-01603c145152"
      },
      "outputs": [],
      "source": [
        "new_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_y73RFP274P"
      },
      "source": [
        "## 4.\tMachine Learning Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tgkPDHR59TJ"
      },
      "source": [
        "### Each of the model descriptions is written in their designated sections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxBJKYIYbspe"
      },
      "outputs": [],
      "source": [
        "# For cross validation\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db-kcdZVVrYX"
      },
      "source": [
        "### Creating a Balanced Dataset for Binary Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NedYVzvrAkys"
      },
      "source": [
        "We know that a balanced dataset is crucial in machine learning because it\n",
        "ensures that each class or category of data is represented equally. This means that the number of observations in each class is roughly the same which prevents the model from being biased toward the majority class. A biased dataset can lead to poor model performance, as the model may have difficulty predicting the minority classes. As we already know that the following dataset is highly imbalanced, we took the help of **SMOTE (Synthetic Minority Over-sampling Technique)** to upsample the minority classes while creating a balanced dataset for multi-class classification. This helped us in creating an overall balanced dataset to feed the classification models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3IY9PKxVyK6",
        "outputId": "ce9230ff-4dab-4ac4-b604-2b357a80cc7d"
      },
      "outputs": [],
      "source": [
        "# Creating a balanced dataset for Binary Classification\n",
        "normal_traffic = new_data.loc[new_data['Attack Type'] == 'BENIGN']\n",
        "intrusions = new_data.loc[new_data['Attack Type'] != 'BENIGN']\n",
        "\n",
        "normal_traffic = normal_traffic.sample(n = len(intrusions), replace = False)\n",
        "\n",
        "ids_data = pd.concat([intrusions, normal_traffic])\n",
        "ids_data['Attack Type'] = np.where((ids_data['Attack Type'] == 'BENIGN'), 0, 1)\n",
        "bc_data = ids_data.sample(n = 15000)\n",
        "\n",
        "print(bc_data['Attack Type'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50MzC2G5V0PP"
      },
      "outputs": [],
      "source": [
        "# Splitting the data into features (X) and target (y)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_bc = bc_data.drop('Attack Type', axis = 1)\n",
        "y_bc = bc_data['Attack Type']\n",
        "\n",
        "X_train_bc, X_test_bc, y_train_bc, y_test_bc = train_test_split(X_bc, y_bc, test_size = 0.25, random_state = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHpB4fGaTzPK"
      },
      "source": [
        "### Logistic Regression (Binary Classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_Dq3tp7HmhA"
      },
      "source": [
        "Logistic regression is a type of statistical model used to predict the probability of a binary outcome based on one or more independent variables. It models the relationship between the independent and dependent variable using a sigmoid function to output a probability score between 0 and 1. It's often used in classification tasks where the goal is to determine which of two classes an observation belongs to, such as whether an email is spam or not.\n",
        "\\\n",
        "\\\n",
        "**Parameters:**\\\n",
        "*max_iter:* this parameter sets the maximum number of iterations for the solver to converge. The default value is set to 100. However, our model could not converge with only 100 iterations so we increased it to our desire.\\\n",
        "\\\n",
        "*C:* This parameter is the regularization strength and controls the trade-off between fitting the training data well and avoiding overfitting. A smaller value of C specifies stronger regularization. We used a lower value for one model and higher value on other to see how the models perform in avoiding overfitting after placing high and low importance respectively.\\\n",
        "\\\n",
        "*solver:* This parameter specifies the algorithm to use in the optimization problem when fitting the logistic regression model. There are several different solver algorithms available such as lbfgs, saga, liblinear and a few more. We went with 'saga' and 'sag' to train our models.\\\n",
        "\\\n",
        "*random_state:* This is to ensure that the output is deterministic and can be reproduced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ofQqIitbqrr",
        "outputId": "49264002-1482-4f0e-bddd-4f2e47601d19"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr1 = LogisticRegression(max_iter = 10000, C = 0.1, random_state = 0, solver = 'saga')\n",
        "lr1.fit(X_train_bc, y_train_bc)\n",
        "\n",
        "cv_lr1 = cross_val_score(lr1, X_train_bc, y_train_bc, cv = 5)\n",
        "print('Logistic regression Model 1')\n",
        "print(f'\\nCross-validation scores:', ', '.join(map(str, cv_lr1)))\n",
        "print(f'\\nMean cross-validation score: {cv_lr1.mean():.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1txdSFbC12rz",
        "outputId": "a0d1042f-b720-4c92-f729-c5610b65671b"
      },
      "outputs": [],
      "source": [
        "print('Logistic Regression Model 1 coefficients:')\n",
        "print(*lr1.coef_, sep = ', ')\n",
        "print('\\nLogistic Regression Model 1 intercept:', *lr1.intercept_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C81rVfrK57wB",
        "outputId": "4564cc9a-d208-4196-c106-9308118d3262"
      },
      "outputs": [],
      "source": [
        "lr2 = LogisticRegression(max_iter = 15000, solver = 'sag', C = 100, random_state = 0)\n",
        "lr2.fit(X_train_bc, y_train_bc)\n",
        "\n",
        "cv_lr2 = cross_val_score(lr2, X_train_bc, y_train_bc, cv = 5)\n",
        "print('Logistic regression Model 2')\n",
        "print(f'\\nCross-validation scores:', ', '.join(map(str, cv_lr2)))\n",
        "print(f'\\nMean cross-validation score: {cv_lr2.mean():.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zc2aGXzq6eRo",
        "outputId": "f24ddbce-3868-4d44-d0b5-6119e64a3d02"
      },
      "outputs": [],
      "source": [
        "print('Logistic Regression Model 2 coefficients:')\n",
        "print(*lr2.coef_, sep = ', ')\n",
        "print('\\nLogistic Regression Model 2 intercept:', *lr2.intercept_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bYBt91SVl2Q"
      },
      "source": [
        "### Support Vector Machine (Binary Classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjREE3A2TCWw"
      },
      "source": [
        "Support Vector Machine (SVM) is a type of supervised machine learning algorithm used for classification and regression analysis. It works by finding a hyperplane in a high-dimensional space that best separates the data points into different classes.\n",
        "\\\n",
        "\\\n",
        "**Parameters:**\\\n",
        "*kernel:* The kernel parameter specifies the type of kernel function to use. In this case, we have used rbf and poly kernel.\\\n",
        "\\\n",
        "*C:* The C parameter controls the trade-off between maximizing the margin and minimizing the classification error.\\\n",
        "\\\n",
        "*gamma:* The gamma parameter is a hyperparameter that determines the influence of a single training example on the decision boundary.\\\n",
        "\\\n",
        "*random_state:* This is to ensure that the output is deterministic and can be reproduced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDS7K7l7Vqll",
        "outputId": "066f6feb-973d-44de-e27a-26830e8ea7ab"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm1 = SVC(kernel = 'poly', C = 1, random_state = 0, probability = True)\n",
        "svm1.fit(X_train_bc, y_train_bc)\n",
        "\n",
        "cv_svm1 = cross_val_score(svm1, X_train_bc, y_train_bc, cv = 5)\n",
        "print('Support Vector Machine Model 1')\n",
        "print(f'\\nCross-validation scores:', ', '.join(map(str, cv_svm1)))\n",
        "print(f'\\nMean cross-validation score: {cv_svm1.mean():.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bVsX6rNVrLY",
        "outputId": "0feb59e1-b42f-4545-9d16-a8561d18968b"
      },
      "outputs": [],
      "source": [
        "svm2 = SVC(kernel = 'rbf', C = 1, gamma = 0.1, random_state = 0, probability = True)\n",
        "svm2.fit(X_train_bc, y_train_bc)\n",
        "\n",
        "cv_svm2 = cross_val_score(svm2, X_train_bc, y_train_bc, cv = 5)\n",
        "print('Support Vector Machine Model 2')\n",
        "print(f'\\nCross-validation scores:', ', '.join(map(str, cv_svm2)))\n",
        "print(f'\\nMean cross-validation score: {cv_svm2.mean():.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLX5osnVuCxk",
        "outputId": "9549e267-6f68-4522-e29a-27cecc2ac055"
      },
      "outputs": [],
      "source": [
        "print('SVM Model 1 intercept:', *svm1.intercept_)\n",
        "print('SVM Model 2 intercept:', *svm2.intercept_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOZmLQQ4t730"
      },
      "source": [
        "**We did not use the linear kernel. Hence no coefficients.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bvab0SkCfy0d"
      },
      "source": [
        "### Creating a Balanced Dataset for Multi-class Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRGWKYwPJeek",
        "outputId": "e18bcb30-040f-44bf-f9fb-f1440e075da3"
      },
      "outputs": [],
      "source": [
        "new_data['Attack Type'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnCaEsAjA1p3",
        "outputId": "dadaac73-caf1-48ad-a65e-9f6390828962"
      },
      "outputs": [],
      "source": [
        "class_counts = new_data['Attack Type'].value_counts()\n",
        "selected_classes = class_counts[class_counts > 1950]\n",
        "class_names = selected_classes.index\n",
        "selected = new_data[new_data['Attack Type'].isin(class_names)]\n",
        "\n",
        "dfs = []\n",
        "for name in class_names:\n",
        "  df = selected[selected['Attack Type'] == name]\n",
        "  if len(df) > 2500:\n",
        "    df = df.sample(n = 5000, random_state = 0)\n",
        "\n",
        "  dfs.append(df)\n",
        "\n",
        "df = pd.concat(dfs, ignore_index = True)\n",
        "df['Attack Type'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXDuMQ3euiM_",
        "outputId": "d1c0e5f4-0008-4e33-8fd3-433b88df337c"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "X = df.drop('Attack Type', axis=1)\n",
        "y = df['Attack Type']\n",
        "\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=0)\n",
        "X_upsampled, y_upsampled = smote.fit_resample(X, y)\n",
        "\n",
        "blnc_data = pd.DataFrame(X_upsampled)\n",
        "blnc_data['Attack Type'] = y_upsampled\n",
        "blnc_data = blnc_data.sample(frac=1)\n",
        "\n",
        "blnc_data['Attack Type'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W958TQwtSxgz"
      },
      "outputs": [],
      "source": [
        "features = blnc_data.drop('Attack Type', axis = 1)\n",
        "labels = blnc_data['Attack Type']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.25, random_state = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isyblWcu-wmg"
      },
      "source": [
        "### Random Forest Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "susNMd2vOO4M"
      },
      "source": [
        "Random Forest is an ensemble learning method that combines multiple decision trees to improve the accuracy and generalization performance of the model. The basic idea behind random forests is to fit multiple decision trees on random subsets of the training data and average their predictions to reduce overfitting and improve generalization performance.\n",
        "\\\n",
        "\\\n",
        "**Parameters:**\\\n",
        "*n_estimators:* This parameter specifies the number of decision trees to fit in the random forest.\\\n",
        "\\\n",
        "*max_depth:* This parameter specifies the maximum depth of each decision tree in the random forest. A deeper tree can capture more complex interactions in the data. In our case, this parameter played a major role getting better results.\\\n",
        "\\\n",
        "*max_features:* This parameter specifies the number of features to consider when looking for the best split in each tree. We trained the first model taking all the features into account an dfor the second one, we used only 20 features.\\\n",
        "\\\n",
        "*random_state:* As mentioned earliar, this is to ensure that the output is deterministic and can be reproduced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK2A_QdRTaV0",
        "outputId": "3c949e70-85b1-460b-aa5a-410b405eb639"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf1 = RandomForestClassifier(n_estimators = 10, max_depth = 6, max_features = None, random_state = 0)\n",
        "rf1.fit(X_train, y_train)\n",
        "\n",
        "cv_rf1 = cross_val_score(rf1, X_train, y_train, cv = 5)\n",
        "print('Random Forest Model 1')\n",
        "print(f'\\nCross-validation scores:', ', '.join(map(str, cv_rf1)))\n",
        "print(f'\\nMean cross-validation score: {cv_rf1.mean():.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_H0qB7aUFKj",
        "outputId": "a8475fc1-4963-4a5b-8271-4a5d584d4b3c"
      },
      "outputs": [],
      "source": [
        "rf2 = RandomForestClassifier(n_estimators = 15, max_depth = 8, max_features = 20, random_state = 0)\n",
        "rf2.fit(X_train, y_train)\n",
        "\n",
        "cv_rf2 = cross_val_score(rf2, X_train, y_train, cv = 5)\n",
        "print('Random Forest Model 2')\n",
        "print(f'\\nCross-validation scores:', ', '.join(map(str, cv_rf2)))\n",
        "print(f'\\nMean cross-validation score: {cv_rf2.mean():.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D1ip-J88_fE"
      },
      "source": [
        "### Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTODuqEDQh3p"
      },
      "source": [
        "A decision tree is a type of algorithm used in machine learning for both classification and regression tasks. The algorithm works by recursively splitting the data into smaller subsets based on the values of the input features until a stopping criterion is met. In our case, it's the maximum depth of the tree.\n",
        "\\\n",
        "\\\n",
        "**Parameters:**\\\n",
        "*max_depth:* This parameter specifies the maximum depth of the tree. A deeper tree can capture more complex interactions in the data but can be computationally expensive. We started with a small depth and later increased it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGhd5swq9J5G",
        "outputId": "70a51cac-b6f4-4e75-d20e-cf2bbce7ba42"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt1 = DecisionTreeClassifier(max_depth = 6)\n",
        "dt1.fit(X_train, y_train)\n",
        "\n",
        "cv_dt1 = cross_val_score(dt1, X_train, y_train, cv = 5)\n",
        "print('Decision Tree Model 1')\n",
        "print(f'\\nCross-validation scores:', ', '.join(map(str, cv_dt1)))\n",
        "print(f'\\nMean cross-validation score: {cv_dt1.mean():.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VG63XESTmgK",
        "outputId": "cfb988e4-4cf3-4fbb-d644-1b07fe2c2db0"
      },
      "outputs": [],
      "source": [
        "dt2 = DecisionTreeClassifier(max_depth = 8)\n",
        "dt2.fit(X_train, y_train)\n",
        "\n",
        "cv_dt2 = cross_val_score(dt2, X_train, y_train, cv = 5)\n",
        "print('Decision Tree Model 2')\n",
        "print(f'\\nCross-validation scores:', ', '.join(map(str, cv_dt2)))\n",
        "print(f'\\nMean cross-validation score: {cv_dt2.mean():.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qr2iEpQYjmr"
      },
      "source": [
        "### K Nearest Neighbours"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8IS9CyqsBa8"
      },
      "source": [
        "K Nearest Neighbors (KNN) is a simple algorithm that searches for the k closest data points (neighbors) in the training set to the new input data point, based on some distance metric, usually Euclidean distance. Then, the algorithm takes a majority vote for classification of the labels or target values of those k neighbors to predict the label or target value of the new data point.\n",
        "\\\n",
        "\\\n",
        "**Parameters:**\\\n",
        "*n_neighbors:* This is a hyperparameter of the KNN algorithm that specifies the number of neighbors to consider when making predictions for a new input data point. In our case we initailly started with 16 to make predictions. So, the model will consider the 16 closest data points (neighbors).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZqyPHBAYuIF",
        "outputId": "703e8e00-bf0e-4bb0-97a7-f8165cb33689"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn1 = KNeighborsClassifier(n_neighbors = 16)\n",
        "knn1.fit(X_train, y_train)\n",
        "\n",
        "cv_knn1 = cross_val_score(knn1, X_train, y_train, cv = 5)\n",
        "print('K Nearest Neighbors Model 1')\n",
        "print(f'\\nCross-validation scores:', ', '.join(map(str, cv_knn1)))\n",
        "print(f'\\nMean cross-validation score: {cv_knn1.mean():.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrasZwf5Yua3",
        "outputId": "bbf2ab04-a6bf-432e-81ad-0d31beaa8505"
      },
      "outputs": [],
      "source": [
        "knn2 = KNeighborsClassifier(n_neighbors = 8)\n",
        "knn2.fit(X_train, y_train)\n",
        "\n",
        "cv_knn2 = cross_val_score(knn2, X_train, y_train, cv = 5)\n",
        "print('K Nearest Neighbors Model 1')\n",
        "print(f'\\nCross-validation scores:', ', '.join(map(str, cv_knn2)))\n",
        "print(f'\\nMean cross-validation score: {cv_knn2.mean():.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEDT9-gO6UfJ"
      },
      "source": [
        "## 5.\tPerformance Evaluation and Discussion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_hyY4e9B1hn"
      },
      "outputs": [],
      "source": [
        "# Importing necessary functions\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, classification_report, \\\n",
        " roc_auc_score, roc_curve, auc, precision_recall_curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUzFJzuL7K35"
      },
      "source": [
        "### Logistic Regression Models Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aZDJpxcj7JjW",
        "outputId": "d67263b9-54ac-4b15-cd0e-55f78d5a8716"
      },
      "outputs": [],
      "source": [
        "y_pred_lr1 = lr1.predict(X_test_bc)\n",
        "y_pred_lr2 = lr2.predict(X_test_bc)\n",
        "\n",
        "conf_matrix_model1 = confusion_matrix(y_test_bc, y_pred_lr1)\n",
        "conf_matrix_model2 = confusion_matrix(y_test_bc, y_pred_lr2)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize = (12, 4))\n",
        "\n",
        "sns.heatmap(conf_matrix_model1, annot = True, cmap = 'Blues', ax = axs[0])\n",
        "axs[0].set_title('Model 1')\n",
        "\n",
        "sns.heatmap(conf_matrix_model2, annot = True, cmap = 'Blues', ax = axs[1])\n",
        "axs[1].set_title('Model 2')\n",
        "\n",
        "axs[0].set_xlabel('Predicted label')\n",
        "axs[0].set_ylabel('True label')\n",
        "axs[1].set_xlabel('Predicted label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WP6blBkphNMM",
        "outputId": "3e22a31e-7d4e-415a-cf28-82758125fbb6"
      },
      "outputs": [],
      "source": [
        "y_prob_lr1 = lr1.predict_proba(X_test_bc)[:,1]\n",
        "y_prob_lr2 = lr2.predict_proba(X_test_bc)[:,1]\n",
        "\n",
        "fpr1, tpr1, _ = roc_curve(y_test_bc, y_prob_lr1)\n",
        "roc_auc1 = auc(fpr1, tpr1)\n",
        "\n",
        "fpr2, tpr2, _ = roc_curve(y_test_bc, y_prob_lr2)\n",
        "roc_auc2 = auc(fpr2, tpr2)\n",
        "\n",
        "colors = sns.color_palette('Set2', n_colors = 3)\n",
        "fig, axes = plt.subplots(1, 3, figsize = (15, 5))\n",
        "\n",
        "axes[0].plot(fpr1, tpr1, label = f'ROC curve (area = {roc_auc1:.2%})', color = colors[1])\n",
        "axes[0].plot([0, 1], [0, 1], color = colors[0], linestyle = '--')\n",
        "axes[0].set_xlim([-0.05, 1.0])\n",
        "axes[0].set_ylim([0.0, 1.05])\n",
        "axes[0].set_xlabel('False Positive Rate')\n",
        "axes[0].set_ylabel('True Positive Rate')\n",
        "axes[0].set_title('ROC Curve (Model 1)')\n",
        "axes[0].legend(loc = 'lower right')\n",
        "\n",
        "axes[1].plot(fpr2, tpr2, label = f'ROC curve (area = {roc_auc2:.2%})', color = colors[2])\n",
        "axes[1].plot([0, 1], [0, 1], color = colors[0], linestyle = '--')\n",
        "axes[1].set_xlim([-0.05, 1.0])\n",
        "axes[1].set_ylim([0.0, 1.05])\n",
        "axes[1].set_xlabel('False Positive Rate')\n",
        "axes[1].set_ylabel('True Positive Rate')\n",
        "axes[1].set_title('ROC Curve (Model 2)')\n",
        "axes[1].legend(loc = 'lower right')\n",
        "\n",
        "axes[2].plot(fpr1, tpr1, label = f'ROC curve (area = {roc_auc1:.2%})', color = colors[1])\n",
        "axes[2].plot(fpr2, tpr2, label = f'ROC curve (area = {roc_auc2:.2%})', color = colors[2])\n",
        "axes[2].plot([0, 1], [0, 1], color = colors[0], linestyle = '--')\n",
        "axes[2].set_xlim([-0.05, 1.0])\n",
        "axes[2].set_ylim([0.0, 1.05])\n",
        "axes[2].set_xlabel('False Positive Rate')\n",
        "axes[2].set_ylabel('True Positive Rate')\n",
        "axes[2].set_title('Model 1 vs Model 2')\n",
        "axes[2].legend(loc = 'lower right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QBt7iRvb-QKU",
        "outputId": "38da8831-ffed-4b77-d35f-8e0fb7d0bcce"
      },
      "outputs": [],
      "source": [
        "precision1, recall1, threshold1 = precision_recall_curve(y_test_bc, y_prob_lr1)\n",
        "precision2, recall2, threshold2 = precision_recall_curve(y_test_bc, y_prob_lr2)\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize = (15, 5))\n",
        "\n",
        "axs[0].plot(recall1, precision1, color = colors[1], label = 'Model 1')\n",
        "axs[0].set_xlabel('Recall')\n",
        "axs[0].set_ylabel('Precision')\n",
        "axs[0].set_title('Precision-Recall Curve (Model 1)')\n",
        "\n",
        "axs[1].plot(recall2, precision2, color = colors[2], label = 'Model 2')\n",
        "axs[1].set_xlabel('Recall')\n",
        "axs[1].set_ylabel('Precision')\n",
        "axs[1].set_title('Precision-Recall Curve (Model 2)')\n",
        "\n",
        "axs[2].plot(recall1, precision1, color = colors[1], label = 'Model 1')\n",
        "axs[2].plot(recall2, precision2, color = colors[2], label = 'Model 2')\n",
        "axs[2].set_xlabel('Recall')\n",
        "axs[2].set_ylabel('Precision')\n",
        "axs[2].set_title('Model 1 vs Model 2')\n",
        "axs[2].legend(loc = 'lower left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "r4cFymF0HMhs",
        "outputId": "de014981-2265-42b4-c82f-2550511fb88d"
      },
      "outputs": [],
      "source": [
        "target_names = lr1.classes_\n",
        "metrics1 = classification_report(y_true = y_test_bc, y_pred = y_pred_lr1, target_names = target_names, output_dict = True)\n",
        "precision1 = [metrics1[target_name]['precision'] for target_name in target_names]\n",
        "recall1 = [metrics1[target_name]['recall'] for target_name in target_names]\n",
        "f1_score1 = [metrics1[target_name]['f1-score'] for target_name in target_names]\n",
        "\n",
        "metrics2 = classification_report(y_true = y_test_bc, y_pred = y_pred_lr2, target_names = target_names, output_dict = True)\n",
        "precision2 = [metrics2[target_name]['precision'] for target_name in target_names]\n",
        "recall2 = [metrics2[target_name]['recall'] for target_name in target_names]\n",
        "f1_score2 = [metrics2[target_name]['f1-score'] for target_name in target_names]\n",
        "\n",
        "data1 = np.array([precision1, recall1, f1_score1])\n",
        "data2 = np.array([precision2, recall2, f1_score2])\n",
        "rows = ['Precision', 'Recall', 'F1-score']\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize = (14, 6))\n",
        "sns.heatmap(data1, cmap='Pastel1', annot = True, fmt='.2f', xticklabels = target_names, yticklabels = rows, ax = axs[0])\n",
        "sns.heatmap(data2, cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax = axs[1])\n",
        "axs[0].set_title('Classification Report (Model 1)')\n",
        "axs[1].set_title('Classification Report (Model 2)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "oExZbeARAnq_",
        "outputId": "3107fa23-088b-4ccf-fad1-25c47dfb09fa"
      },
      "outputs": [],
      "source": [
        "palette = sns.color_palette('Blues', n_colors = 3)\n",
        "\n",
        "acc1 = accuracy_score(y_pred_lr1, y_test_bc)\n",
        "acc2 = accuracy_score(y_pred_lr2, y_test_bc)\n",
        "\n",
        "labels = ['Model 1', 'Model 2']\n",
        "scores = [acc1, acc2]\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (9, 3))\n",
        "ax.barh(labels, scores, color = palette)\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_xlabel('Accuracy Score')\n",
        "ax.set_title('Logistic Regression Model Comparison')\n",
        "\n",
        "for i, v in enumerate(scores):\n",
        "    ax.text(v + 0.01, i, str(round(v, 3)), ha = 'left', va = 'center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hocfVoCxj9Bz",
        "outputId": "4296e2d8-1bc3-43f3-dd19-3f76564770b9"
      },
      "outputs": [],
      "source": [
        "palette = sns.color_palette('Greens', n_colors = 3)\n",
        "\n",
        "labels = ['Model 1', 'Model 2']\n",
        "scores = [cv_lr1.mean(), cv_lr2.mean()]\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (9, 3))\n",
        "ax.barh(labels, scores, color = palette)\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_xlabel('Cross Validation Score')\n",
        "ax.set_title('Logistic Regression Model Comparison (Cross Validation)')\n",
        "\n",
        "for i, v in enumerate(scores):\n",
        "    ax.text(v + 0.01, i, str(round(v, 3)), ha = 'left', va = 'center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_5dqWNjXuRL"
      },
      "source": [
        "### Support Vector Machine Models Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mD8EQxRsXuRL",
        "outputId": "36d95d80-dc02-4807-b835-ca9ff322dbaa"
      },
      "outputs": [],
      "source": [
        "y_pred_svm1 = svm1.predict(X_test_bc)\n",
        "y_pred_svm2 = svm2.predict(X_test_bc)\n",
        "\n",
        "conf_matrix_model1 = confusion_matrix(y_test_bc, y_pred_svm1)\n",
        "conf_matrix_model2 = confusion_matrix(y_test_bc, y_pred_svm2)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize = (12, 4))\n",
        "\n",
        "sns.heatmap(conf_matrix_model1, annot = True, cmap = 'Blues', ax = axs[0])\n",
        "axs[0].set_title('Model 1')\n",
        "\n",
        "sns.heatmap(conf_matrix_model2, annot = True, cmap = 'Blues', ax = axs[1])\n",
        "axs[1].set_title('Model 2')\n",
        "\n",
        "axs[0].set_xlabel('Predicted label')\n",
        "axs[0].set_ylabel('True label')\n",
        "axs[1].set_xlabel('Predicted label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5Xof-5OuXuRM",
        "outputId": "2e7ad99f-d0b4-4428-8caa-202329e67c6b"
      },
      "outputs": [],
      "source": [
        "y_prob_svm1 = svm1.predict_proba(X_test_bc)[:,1]\n",
        "y_prob_svm2 = svm2.predict_proba(X_test_bc)[:,1]\n",
        "\n",
        "fpr1, tpr1, _ = roc_curve(y_test_bc, y_prob_svm1)\n",
        "roc_auc1 = auc(fpr1, tpr1)\n",
        "\n",
        "fpr2, tpr2, _ = roc_curve(y_test_bc, y_prob_svm2)\n",
        "roc_auc2 = auc(fpr2, tpr2)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize = (15, 5))\n",
        "\n",
        "axes[0].plot(fpr1, tpr1, label = f'ROC curve (area = {roc_auc1:.2%})', color = colors[1])\n",
        "axes[0].plot([0, 1], [0, 1], color = colors[0], linestyle = '--')\n",
        "axes[0].set_xlim([-0.05, 1.0])\n",
        "axes[0].set_ylim([0.0, 1.05])\n",
        "axes[0].set_xlabel('False Positive Rate')\n",
        "axes[0].set_ylabel('True Positive Rate')\n",
        "axes[0].set_title('ROC Curve (Model 1)')\n",
        "axes[0].legend(loc = 'lower right')\n",
        "\n",
        "axes[1].plot(fpr2, tpr2, label = f'ROC curve (area = {roc_auc2:.2%})', color = colors[2])\n",
        "axes[1].plot([0, 1], [0, 1], color = colors[0], linestyle = '--')\n",
        "axes[1].set_xlim([-0.05, 1.0])\n",
        "axes[1].set_ylim([0.0, 1.05])\n",
        "axes[1].set_xlabel('False Positive Rate')\n",
        "axes[1].set_ylabel('True Positive Rate')\n",
        "axes[1].set_title('ROC Curve (Model 2)')\n",
        "axes[1].legend(loc = 'lower right')\n",
        "\n",
        "axes[2].plot(fpr1, tpr1, label = f'ROC curve (area = {roc_auc1:.2%})', color = colors[1])\n",
        "axes[2].plot(fpr2, tpr2, label = f'ROC curve (area = {roc_auc2:.2%})', color = colors[2])\n",
        "axes[2].plot([0, 1], [0, 1], color = colors[0], linestyle = '--')\n",
        "axes[2].set_xlim([-0.05, 1.0])\n",
        "axes[2].set_ylim([0.0, 1.05])\n",
        "axes[2].set_xlabel('False Positive Rate')\n",
        "axes[2].set_ylabel('True Positive Rate')\n",
        "axes[2].set_title('Model 1 vs Model 2')\n",
        "axes[2].legend(loc = 'lower right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2ha0tlm6XuRM",
        "outputId": "fb42abe4-408a-43c1-eec9-16da48ba38db"
      },
      "outputs": [],
      "source": [
        "precision1, recall1, threshold1 = precision_recall_curve(y_test_bc, y_prob_svm1)\n",
        "precision2, recall2, threshold2 = precision_recall_curve(y_test_bc, y_prob_svm2)\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize = (15, 5))\n",
        "\n",
        "axs[0].plot(recall1, precision1, color = colors[1])\n",
        "axs[0].set_xlabel('Recall')\n",
        "axs[0].set_ylabel('Precision')\n",
        "axs[0].set_title('Precision-Recall Curve (Model 1)')\n",
        "\n",
        "axs[1].plot(recall2, precision2, color = colors[2])\n",
        "axs[1].set_xlabel('Recall')\n",
        "axs[1].set_ylabel('Precision')\n",
        "axs[1].set_title('Precision-Recall Curve (Model 2)')\n",
        "\n",
        "axs[2].plot(recall1, precision1, color = colors[1], label = 'Model 1')\n",
        "axs[2].plot(recall2, precision2, color = colors[2], label = 'Model 2')\n",
        "axs[2].set_xlabel('Recall')\n",
        "axs[2].set_ylabel('Precision')\n",
        "axs[2].set_title('Model 1 vs Model 2')\n",
        "axs[2].legend(loc = 'lower left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8coNMkjWXuRM",
        "outputId": "4cd255f3-6974-4cf0-da37-6416893c047e"
      },
      "outputs": [],
      "source": [
        "target_names = svm1.classes_\n",
        "metrics1 = classification_report(y_true = y_test_bc, y_pred = y_pred_svm1, target_names = target_names, output_dict = True)\n",
        "precision1 = [metrics1[target_name]['precision'] for target_name in target_names]\n",
        "recall1 = [metrics1[target_name]['recall'] for target_name in target_names]\n",
        "f1_score1 = [metrics1[target_name]['f1-score'] for target_name in target_names]\n",
        "\n",
        "metrics2 = classification_report(y_true = y_test_bc, y_pred = y_pred_svm2, target_names = target_names, output_dict = True)\n",
        "precision2 = [metrics2[target_name]['precision'] for target_name in target_names]\n",
        "recall2 = [metrics2[target_name]['recall'] for target_name in target_names]\n",
        "f1_score2 = [metrics2[target_name]['f1-score'] for target_name in target_names]\n",
        "\n",
        "data1 = np.array([precision1, recall1, f1_score1])\n",
        "data2 = np.array([precision2, recall2, f1_score2])\n",
        "rows = ['Precision', 'Recall', 'F1-score']\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
        "sns.heatmap(data1, cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax = axs[0])\n",
        "sns.heatmap(data2, cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax = axs[1])\n",
        "axs[0].set_title('Classification Report (Model 1)')\n",
        "axs[1].set_title('Classification Report (Model 2)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EzNlyxISXuRN",
        "outputId": "1d8baca4-6a34-41e9-b651-e0876dad23b7"
      },
      "outputs": [],
      "source": [
        "palette = sns.color_palette('Blues', n_colors = 2)\n",
        "\n",
        "acc1 = accuracy_score(y_pred_svm1, y_test_bc)\n",
        "acc2 = accuracy_score(y_pred_svm2, y_test_bc)\n",
        "\n",
        "labels = ['Model 1', 'Model 2']\n",
        "scores = [acc1, acc2]\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (9, 3))\n",
        "ax.barh(labels, scores, color = palette)\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_xlabel('Accuracy Score')\n",
        "ax.set_title('Support Vector Machine Model Comparison')\n",
        "\n",
        "for i, v in enumerate(scores):\n",
        "    ax.text(v + 0.01, i, str(round(v, 3)), ha = 'left', va = 'center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "AUjTas0zkX_g",
        "outputId": "c3df7c5e-b103-4880-e704-b4c86d5da2ea"
      },
      "outputs": [],
      "source": [
        "palette = sns.color_palette('Greens', n_colors = 2)\n",
        "\n",
        "labels = ['Model 1', 'Model 2']\n",
        "scores = [cv_svm1.mean(), cv_svm2.mean()]\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (9, 3))\n",
        "ax.barh(labels, scores, color = palette)\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_xlabel('Cross Validation Score')\n",
        "ax.set_title('Support Vector Machine Model Comparison (Cross Validation)')\n",
        "\n",
        "for i, v in enumerate(scores):\n",
        "    ax.text(v + 0.01, i, str(round(v, 3)), ha = 'left', va = 'center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21Q9ths2VJC-"
      },
      "source": [
        "### Comparison of the Binary Classification Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leiWe60Qnp8Y"
      },
      "source": [
        "We trained two models for each different classification algorithm. For comparing different algorithms, we will take the best performing model from each class based on the model's precision, recall, accuracy, etc.\n",
        "\n",
        "1. Logistic Regression: Model 2\n",
        "1. Support Vector Machine: Model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "E4EX44I7oVo3",
        "outputId": "84dee316-1f1b-48a8-e410-7ba71c9de5e0"
      },
      "outputs": [],
      "source": [
        "conf_matrix_model1 = confusion_matrix(y_test_bc, y_pred_lr2)\n",
        "conf_matrix_model2 = confusion_matrix(y_test_bc, y_pred_svm2)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize = (12, 4))\n",
        "\n",
        "sns.heatmap(conf_matrix_model1, annot = True, cmap = 'Blues', ax = axs[0])\n",
        "axs[0].set_title('Logistic Regression')\n",
        "\n",
        "sns.heatmap(conf_matrix_model2, annot = True, cmap = 'Blues', ax = axs[1])\n",
        "axs[1].set_title('Support Vector Machine')\n",
        "\n",
        "axs[0].set_xlabel('Predicted label')\n",
        "axs[0].set_ylabel('True label')\n",
        "axs[1].set_xlabel('Predicted label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "_c-GDUcQoVo4",
        "outputId": "8aef6a67-d53e-4672-9452-04d92ef42955"
      },
      "outputs": [],
      "source": [
        "fpr1, tpr1, _ = roc_curve(y_test_bc, y_prob_lr2)\n",
        "roc_auc1 = auc(fpr1, tpr1)\n",
        "\n",
        "fpr2, tpr2, _ = roc_curve(y_test_bc, y_prob_svm2)\n",
        "roc_auc2 = auc(fpr2, tpr2)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize = (15, 5))\n",
        "\n",
        "axes[0].plot(fpr1, tpr1, label = f'ROC curve (area = {roc_auc1:.2%})', color = colors[1])\n",
        "axes[0].plot([0, 1], [0, 1], color = colors[0], linestyle = '--')\n",
        "axes[0].set_xlim([-0.05, 1.0])\n",
        "axes[0].set_ylim([0.0, 1.05])\n",
        "axes[0].set_xlabel('False Positive Rate')\n",
        "axes[0].set_ylabel('True Positive Rate')\n",
        "axes[0].set_title('ROC Curve (Logistic Regression)')\n",
        "axes[0].legend(loc = 'lower right')\n",
        "\n",
        "axes[1].plot(fpr2, tpr2, label = f'ROC curve (area = {roc_auc2:.2%})', color = colors[2])\n",
        "axes[1].plot([0, 1], [0, 1], color = colors[0], linestyle = '--')\n",
        "axes[1].set_xlim([-0.05, 1.0])\n",
        "axes[1].set_ylim([0.0, 1.05])\n",
        "axes[1].set_xlabel('False Positive Rate')\n",
        "axes[1].set_ylabel('True Positive Rate')\n",
        "axes[1].set_title('ROC Curve (SVM)')\n",
        "axes[1].legend(loc = 'lower right')\n",
        "\n",
        "axes[2].plot(fpr1, tpr1, label = f'LR ROC curve (area = {roc_auc1:.2%})', color = colors[1])\n",
        "axes[2].plot(fpr2, tpr2, label = f'SVM ROC curve (area = {roc_auc2:.2%})', color = colors[2])\n",
        "axes[2].plot([0, 1], [0, 1], color = colors[0], linestyle = '--')\n",
        "axes[2].set_xlim([-0.05, 1.0])\n",
        "axes[2].set_ylim([0.0, 1.05])\n",
        "axes[2].set_xlabel('False Positive Rate')\n",
        "axes[2].set_ylabel('True Positive Rate')\n",
        "axes[2].set_title('LR vs SVM')\n",
        "axes[2].legend(loc = 'lower right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "yUp1C2jKoVo5",
        "outputId": "f9d064d4-c20b-493a-f5e5-4c37ff5ad0e0"
      },
      "outputs": [],
      "source": [
        "precision1, recall1, threshold1 = precision_recall_curve(y_test_bc, y_prob_lr2)\n",
        "precision2, recall2, threshold2 = precision_recall_curve(y_test_bc, y_prob_svm2)\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize = (15, 5))\n",
        "\n",
        "axs[0].plot(recall1, precision1, color = colors[1], label = 'Model 1')\n",
        "axs[0].set_xlabel('Recall')\n",
        "axs[0].set_ylabel('Precision')\n",
        "axs[0].set_title('Precision-Recall Curve (LR)')\n",
        "\n",
        "axs[1].plot(recall2, precision2, color = colors[2], label = 'Model 2')\n",
        "axs[1].set_xlabel('Recall')\n",
        "axs[1].set_ylabel('Precision')\n",
        "axs[1].set_title('Precision-Recall Curve (SVM)')\n",
        "\n",
        "axs[2].plot(recall1, precision1, color = colors[1], label = 'Logistic Regression')\n",
        "axs[2].plot(recall2, precision2, color = colors[2], label = 'Support Vector Machine')\n",
        "axs[2].set_xlabel('Recall')\n",
        "axs[2].set_ylabel('Precision')\n",
        "axs[2].set_title('LR vs SVM')\n",
        "axs[2].legend(loc = 'lower left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "V2qkYUGFoVo5",
        "outputId": "0848acc0-54d7-46ca-c6b7-176be8379a2e"
      },
      "outputs": [],
      "source": [
        "target_names = svm2.classes_\n",
        "metrics1 = classification_report(y_true = y_test_bc, y_pred = y_pred_lr2, target_names = target_names, output_dict = True)\n",
        "precision1 = [metrics1[target_name]['precision'] for target_name in target_names]\n",
        "recall1 = [metrics1[target_name]['recall'] for target_name in target_names]\n",
        "f1_score1 = [metrics1[target_name]['f1-score'] for target_name in target_names]\n",
        "\n",
        "metrics2 = classification_report(y_true = y_test_bc, y_pred = y_pred_svm2, target_names = target_names, output_dict = True)\n",
        "precision2 = [metrics2[target_name]['precision'] for target_name in target_names]\n",
        "recall2 = [metrics2[target_name]['recall'] for target_name in target_names]\n",
        "f1_score2 = [metrics2[target_name]['f1-score'] for target_name in target_names]\n",
        "\n",
        "data1 = np.array([precision1, recall1, f1_score1])\n",
        "data2 = np.array([precision2, recall2, f1_score2])\n",
        "rows = ['Precision', 'Recall', 'F1-score']\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize = (14, 6))\n",
        "sns.heatmap(data1, cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax=axs[0])\n",
        "sns.heatmap(data2, cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax=axs[1])\n",
        "axs[0].set_title('Classification Report (LR)')\n",
        "axs[1].set_title('Classification Report (SVM)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "FPDQh5PyoVo5",
        "outputId": "be8c6715-7f4a-4382-c624-e5b914b686b7"
      },
      "outputs": [],
      "source": [
        "palette = sns.color_palette('Blues', n_colors = 2)\n",
        "\n",
        "acc1 = accuracy_score(y_pred_lr2, y_test_bc)\n",
        "acc2 = accuracy_score(y_pred_svm2, y_test_bc)\n",
        "\n",
        "labels = ['Logistic Regression', 'Support Vector Machine']\n",
        "scores = [acc1, acc2]\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (9, 3))\n",
        "ax.barh(labels, scores, color = palette)\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_xlabel('Accuracy Score')\n",
        "ax.set_title('Binary Classification Model Comparison')\n",
        "\n",
        "for i, v in enumerate(scores):\n",
        "    ax.text(v + 0.01, i, str(round(v, 3)), ha = 'left', va = 'center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "MaXXUOcsr2xJ",
        "outputId": "41bf010b-93e0-448f-bd8a-cc8bd5c6f62d"
      },
      "outputs": [],
      "source": [
        "palette = sns.color_palette('Greens', n_colors = 2)\n",
        "\n",
        "labels = ['Logistic Regression', 'Support Vector Machine']\n",
        "scores = [cv_lr2.mean(), cv_svm2.mean()]\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (9, 3))\n",
        "ax.barh(labels, scores, color = palette)\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_xlabel('Cross Validation Score')\n",
        "ax.set_title('Binary Classification Model Comparison')\n",
        "\n",
        "for i, v in enumerate(scores):\n",
        "    ax.text(v + 0.01, i, str(round(v, 3)), ha = 'left', va = 'center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDp-xQWSqtLV"
      },
      "source": [
        "### Random Forest Models Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "K3geU-g0qxqx",
        "outputId": "c06c9742-77f1-4de2-c15d-ac97df4d9a59"
      },
      "outputs": [],
      "source": [
        "y_pred_rf1 = rf1.predict(X_test)\n",
        "y_pred_rf2 = rf2.predict(X_test)\n",
        "\n",
        "conf_matrix_model1 = confusion_matrix(y_test, y_pred_rf1)\n",
        "conf_matrix_model2 = confusion_matrix(y_test, y_pred_rf2)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize = (16, 7))\n",
        "\n",
        "sns.heatmap(conf_matrix_model1, annot = True, cmap = 'Blues', ax = axs[0], xticklabels = rf1.classes_, yticklabels = rf1.classes_)\n",
        "axs[0].set_title('Model 1')\n",
        "\n",
        "sns.heatmap(conf_matrix_model2, annot = True, cmap = 'Blues', ax = axs[1], xticklabels = rf2.classes_, yticklabels = rf2.classes_)\n",
        "axs[1].set_title('Model 2')\n",
        "\n",
        "axs[0].set_xlabel('Predicted label')\n",
        "axs[0].set_ylabel('True label')\n",
        "axs[1].set_xlabel('Predicted label')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kgjmfsmQJd7w",
        "outputId": "406ff818-b47e-4108-f5d4-0315fa1262ac"
      },
      "outputs": [],
      "source": [
        "target_names = rf1.classes_\n",
        "metrics1 = classification_report(y_true = y_test, y_pred = y_pred_rf1, target_names = target_names, output_dict = True)\n",
        "precision1 = [metrics1[target_name]['precision'] for target_name in target_names]\n",
        "recall1 = [metrics1[target_name]['recall'] for target_name in target_names]\n",
        "f1_score1 = [metrics1[target_name]['f1-score'] for target_name in target_names]\n",
        "\n",
        "metrics2 = classification_report(y_true = y_test, y_pred = y_pred_rf2, target_names = target_names, output_dict = True)\n",
        "precision2 = [metrics2[target_name]['precision'] for target_name in target_names]\n",
        "recall2 = [metrics2[target_name]['recall'] for target_name in target_names]\n",
        "f1_score2 = [metrics2[target_name]['f1-score'] for target_name in target_names]\n",
        "\n",
        "data1 = np.array([precision1, recall1, f1_score1])\n",
        "data2 = np.array([precision2, recall2, f1_score2])\n",
        "rows = ['Precision', 'Recall', 'F1-score']\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize = (14, 6))\n",
        "sns.heatmap(data1, cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax = axs[0])\n",
        "sns.heatmap(data2, cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax = axs[1])\n",
        "axs[0].set_title('Classification Report (Model 1)')\n",
        "axs[1].set_title('Classification Report (Model 2)')\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-AEq7AxGwHb3",
        "outputId": "27112d37-cca7-46ef-b61d-a7a8e1c3891b"
      },
      "outputs": [],
      "source": [
        "palette = sns.color_palette('Blues', n_colors = 2)\n",
        "\n",
        "acc1 = accuracy_score(y_pred_rf1, y_test)\n",
        "acc2 = accuracy_score(y_pred_rf2, y_test)\n",
        "\n",
        "labels = ['Model 1', 'Model 2']\n",
        "scores = [acc1, acc2]\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (9, 3))\n",
        "ax.barh(labels, scores, color = palette)\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_xlabel('Accuracy Score')\n",
        "ax.set_title('Random Forest Model Comparison')\n",
        "\n",
        "for i, v in enumerate(scores):\n",
        "    ax.text(v + 0.01, i, str(round(v, 3)), ha = 'left', va = 'center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dHewLYnurYGu",
        "outputId": "2bcb721b-e625-4568-8824-ec1889b9eca1"
      },
      "outputs": [],
      "source": [
        "palette = sns.color_palette('Greens', n_colors = 2)\n",
        "\n",
        "labels = ['Model 1', 'Model 2']\n",
        "scores = [cv_rf1.mean(), cv_rf2.mean()]\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (9, 3))\n",
        "ax.barh(labels, scores, color = palette)\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_xlabel('Cross Validation Score')\n",
        "ax.set_title('Support Vector Machine Model Comparison (Cross Validation)')\n",
        "\n",
        "for i, v in enumerate(scores):\n",
        "    ax.text(v + 0.01, i, str(round(v, 3)), ha = 'left', va = 'center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIa0LHYKT78a"
      },
      "source": [
        "### Decision Trees Models Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ItDaKuqKT78b",
        "outputId": "ed6cdb8e-0493-4b13-f45f-5385d0ddf321"
      },
      "outputs": [],
      "source": [
        "y_pred_dt1 = dt1.predict(X_test)\n",
        "y_pred_dt2 = dt2.predict(X_test)\n",
        "\n",
        "conf_matrix_model1 = confusion_matrix(y_test, y_pred_dt1)\n",
        "conf_matrix_model2 = confusion_matrix(y_test, y_pred_dt2)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize = (16, 7))\n",
        "\n",
        "sns.heatmap(conf_matrix_model1, annot = True, cmap = 'Blues', ax = axs[0], xticklabels = dt1.classes_, yticklabels = dt1.classes_)\n",
        "axs[0].set_title('Model 1')\n",
        "\n",
        "sns.heatmap(conf_matrix_model2, annot = True, cmap = 'Blues', ax = axs[1], xticklabels = dt2.classes_, yticklabels = dt2.classes_)\n",
        "axs[1].set_title('Model 2')\n",
        "\n",
        "axs[0].set_xlabel('Predicted label')\n",
        "axs[0].set_ylabel('True label')\n",
        "axs[1].set_xlabel('Predicted label')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ppzpJ6NlT78b",
        "outputId": "a84b49cf-3a0c-4cc3-9ffd-caf8b1e87c37"
      },
      "outputs": [],
      "source": [
        "target_names = dt1.classes_\n",
        "metrics1 = classification_report(y_true = y_test, y_pred = y_pred_dt1, target_names = target_names, output_dict = True)\n",
        "precision1 = [metrics1[target_name]['precision'] for target_name in target_names]\n",
        "recall1 = [metrics1[target_name]['recall'] for target_name in target_names]\n",
        "f1_score1 = [metrics1[target_name]['f1-score'] for target_name in target_names]\n",
        "\n",
        "metrics2 = classification_report(y_true = y_test, y_pred = y_pred_dt2, target_names = target_names, output_dict = True)\n",
        "precision2 = [metrics2[target_name]['precision'] for target_name in target_names]\n",
        "recall2 = [metrics2[target_name]['recall'] for target_name in target_names]\n",
        "f1_score2 = [metrics2[target_name]['f1-score'] for target_name in target_names]\n",
        "\n",
        "data1 = np.array([precision1, recall1, f1_score1])\n",
        "data2 = np.array([precision2, recall2, f1_score2])\n",
        "rows = ['Precision', 'Recall', 'F1-score']\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize = (14, 6))\n",
        "sns.heatmap(data1, cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax = axs[0])\n",
        "sns.heatmap(data2, cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax = axs[1])\n",
        "axs[0].set_title('Classification Report (Model 1)')\n",
        "axs[1].set_title('Classification Report (Model 2)')\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Eaq6mTc6T78b",
        "outputId": "8ad21ae5-7241-484a-c854-70e8d8f56670"
      },
      "outputs": [],
      "source": [
        "palette = sns.color_palette('Blues', n_colors = 2)\n",
        "\n",
        "acc1 = accuracy_score(y_pred_dt1, y_test)\n",
        "acc2 = accuracy_score(y_pred_dt2, y_test)\n",
        "\n",
        "labels = ['Model 1', 'Model 2']\n",
        "scores = [acc1, acc2]\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (9, 3))\n",
        "ax.barh(labels, scores, color = palette)\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_xlabel('Accuracy Score')\n",
        "ax.set_title('Decision Trees Model Comparison')\n",
        "\n",
        "for i, v in enumerate(scores):\n",
        "    ax.text(v + 0.01, i, str(round(v, 3)), ha = 'left', va = 'center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gapIkuxus3cb",
        "outputId": "74b91fe7-ffd0-4584-b61e-44e9c96433a3"
      },
      "outputs": [],
      "source": [
        "palette = sns.color_palette('Greens', n_colors = 2)\n",
        "\n",
        "labels = ['Model 1', 'Model 2']\n",
        "scores = [cv_dt1.mean(), cv_dt2.mean()]\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (9, 3))\n",
        "ax.barh(labels, scores, color = palette)\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_xlabel('Cross Validation Score')\n",
        "ax.set_title('Decision Trees Model Comparison (Cross Validation)')\n",
        "\n",
        "for i, v in enumerate(scores):\n",
        "    ax.text(v + 0.01, i, str(round(v, 3)), ha = 'left', va = 'center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCVzGYzwXivR"
      },
      "source": [
        "### K Nearest Neighbours Models Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bsItgyOIXivS",
        "outputId": "ac3b10c6-d7fc-45ab-98f4-8002b7e492e7"
      },
      "outputs": [],
      "source": [
        "y_pred_knn1 = knn1.predict(X_test)\n",
        "y_pred_knn2 = knn2.predict(X_test)\n",
        "\n",
        "conf_matrix_model1 = confusion_matrix(y_test, y_pred_knn1)\n",
        "conf_matrix_model2 = confusion_matrix(y_test, y_pred_knn2)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize = (16, 7))\n",
        "\n",
        "sns.heatmap(conf_matrix_model1, annot = True, cmap = 'Blues', ax = axs[0], xticklabels = knn1.classes_, yticklabels = knn1.classes_)\n",
        "axs[0].set_title('Model 1')\n",
        "\n",
        "sns.heatmap(conf_matrix_model2, annot = True, cmap = 'Blues', ax = axs[1], xticklabels = knn2.classes_, yticklabels = knn2.classes_)\n",
        "axs[1].set_title('Model 2')\n",
        "\n",
        "axs[0].set_xlabel('Predicted label')\n",
        "axs[0].set_ylabel('True label')\n",
        "axs[1].set_xlabel('Predicted label')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "i0W9cPGiXivT",
        "outputId": "88bcfd44-38ef-4fc9-8caf-abde0504254d"
      },
      "outputs": [],
      "source": [
        "target_names = knn1.classes_\n",
        "metrics1 = classification_report(y_true = y_test, y_pred = y_pred_knn1, target_names = target_names, output_dict = True)\n",
        "precision1 = [metrics1[target_name]['precision'] for target_name in target_names]\n",
        "recall1 = [metrics1[target_name]['recall'] for target_name in target_names]\n",
        "f1_score1 = [metrics1[target_name]['f1-score'] for target_name in target_names]\n",
        "\n",
        "metrics2 = classification_report(y_true = y_test, y_pred = y_pred_knn2, target_names = target_names, output_dict = True)\n",
        "precision2 = [metrics2[target_name]['precision'] for target_name in target_names]\n",
        "recall2 = [metrics2[target_name]['recall'] for target_name in target_names]\n",
        "f1_score2 = [metrics2[target_name]['f1-score'] for target_name in target_names]\n",
        "\n",
        "data1 = np.array([precision1, recall1, f1_score1])\n",
        "data2 = np.array([precision2, recall2, f1_score2])\n",
        "rows = ['Precision', 'Recall', 'F1-score']\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize = (14, 6))\n",
        "sns.heatmap(data1, cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax = axs[0])\n",
        "sns.heatmap(data2, cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax = axs[1])\n",
        "axs[0].set_title('Classification Report (Model 1)')\n",
        "axs[1].set_title('Classification Report (Model 2)')\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-0WSwL6YXivT",
        "outputId": "359031eb-0ffb-45c3-f2f0-72ac15dfdcdc"
      },
      "outputs": [],
      "source": [
        "palette = sns.color_palette('Blues', n_colors = 2)\n",
        "\n",
        "acc1 = accuracy_score(y_pred_knn1, y_test)\n",
        "acc2 = accuracy_score(y_pred_knn2, y_test)\n",
        "\n",
        "labels = ['Model 1', 'Model 2']\n",
        "scores = [acc1, acc2]\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (9, 3))\n",
        "ax.barh(labels, scores, color = palette)\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_xlabel('Accuracy Score')\n",
        "ax.set_title('K Nearest Neighbour Model Comparison')\n",
        "\n",
        "for i, v in enumerate(scores):\n",
        "    ax.text(v + 0.01, i, str(round(v, 3)), ha = 'left', va = 'center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "j8ZSQVAPtF1S",
        "outputId": "66cf1408-3800-4bb6-d9be-3e7b3e5f445b"
      },
      "outputs": [],
      "source": [
        "palette = sns.color_palette('Greens', n_colors = 2)\n",
        "\n",
        "labels = ['Model 1', 'Model 2']\n",
        "scores = [cv_knn1.mean(), cv_knn2.mean()]\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (9, 3))\n",
        "ax.barh(labels, scores, color = palette)\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_xlabel('Cross Validation Score')\n",
        "ax.set_title('Decision Trees Model Comparison (Cross Validation)')\n",
        "\n",
        "for i, v in enumerate(scores):\n",
        "    ax.text(v + 0.01, i, str(round(v, 3)), ha = 'left', va = 'center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxUFSY5JapE5"
      },
      "source": [
        "### Comparison of the Multi-class Classification Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xln5XE3va7lL"
      },
      "source": [
        "We trained two models for each different classification algorithm. For comparing different algorithms, we will take the best performing model from each class based on the model's precision, recall, accuracy, etc.\n",
        "\n",
        "1. Random Forest: Model 2\n",
        "1. Decision Trees: Model 2\n",
        "1. KNN: Model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "ZYl_-kxHa0Tj",
        "outputId": "fb44563e-4974-4550-e322-f23fc6e39824"
      },
      "outputs": [],
      "source": [
        "palette = sns.color_palette('Blues', n_colors = 3)\n",
        "\n",
        "rf_acc = accuracy_score(y_pred_rf2, y_test)\n",
        "dt_acc = accuracy_score(y_pred_dt2, y_test)\n",
        "knn_acc = accuracy_score(y_pred_knn2, y_test)\n",
        "\n",
        "labels = ['Random Forest', 'Decision Trees', 'K Nearest Neighbours']\n",
        "scores = [rf_acc, dt_acc, knn_acc]\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (9, 3))\n",
        "ax.barh(labels, scores, color = palette)\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_xlabel('Accuracy Score')\n",
        "ax.set_title('Multi-class Classification Model Comparison')\n",
        "\n",
        "for i, v in enumerate(scores):\n",
        "    ax.text(v + 0.01, i, str(round(v, 4)), ha = 'left', va = 'center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "7FBhxJYjtnCP",
        "outputId": "bb55fda7-686b-4650-854d-1f78809eaca2"
      },
      "outputs": [],
      "source": [
        "palette = sns.color_palette('Greens', n_colors = 3)\n",
        "\n",
        "labels = ['Random Forest', 'Decision Trees', 'K Nearest Neighbours']\n",
        "scores = [cv_rf2.mean(), cv_dt2.mean(), cv_knn2.mean()]\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (9, 3))\n",
        "ax.barh(labels, scores, color = palette)\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_xlabel('Cross Validation Score')\n",
        "ax.set_title('Multi-class Classification Model Comparison')\n",
        "\n",
        "for i, v in enumerate(scores):\n",
        "    ax.text(v + 0.01, i, str(round(v, 4)), ha = 'left', va = 'center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "WekRRRWU2K5M",
        "outputId": "375b526a-7eab-4342-b8e0-bc337c483109"
      },
      "outputs": [],
      "source": [
        "target_names = rf2.classes_\n",
        "preds = [y_pred_rf2, y_pred_dt2, y_pred_knn2]\n",
        "\n",
        "datas = []\n",
        "for pred in preds:\n",
        "    metrics = classification_report(y_true = y_test, y_pred = pred, target_names = target_names, output_dict = True)\n",
        "    precision = [metrics[target_name]['precision'] for target_name in target_names]\n",
        "    recall = [metrics[target_name]['recall'] for target_name in target_names]\n",
        "    f1_score = [metrics[target_name]['f1-score'] for target_name in target_names]\n",
        "\n",
        "    datas.append(np.array([precision, recall, f1_score]))\n",
        "\n",
        "rows = ['Precision', 'Recall', 'F1-score']\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize = (19, 6))\n",
        "sns.heatmap(datas[0], cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax = axs[0])\n",
        "sns.heatmap(datas[1], cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax = axs[1])\n",
        "sns.heatmap(datas[2], cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax = axs[2])\n",
        "\n",
        "axs[0].set_title('Classification Report (Random Forest)')\n",
        "axs[1].set_title('Classification Report (Decision Trees)')\n",
        "axs[2].set_title('Classification Report (K Nearest Neighbours)')\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "oxS6tASTOTxf",
        "outputId": "be69a3a7-831d-4958-9648-3980b44735a2"
      },
      "outputs": [],
      "source": [
        "preds = [y_pred_rf2, y_pred_dt2, y_pred_knn2]\n",
        "\n",
        "conf_matrix = [confusion_matrix(y_test, y_pred) for y_pred in preds]\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize = (22, 8))\n",
        "\n",
        "sns.heatmap(conf_matrix[0], annot = True, cmap = 'Blues', ax = axs[0], xticklabels = dt1.classes_, yticklabels = dt1.classes_)\n",
        "sns.heatmap(conf_matrix[1], annot = True, cmap = 'Blues', ax = axs[1], xticklabels = dt1.classes_, yticklabels = dt1.classes_)\n",
        "sns.heatmap(conf_matrix[2], annot = True, cmap = 'Blues', ax = axs[2], xticklabels = dt1.classes_, yticklabels = dt1.classes_)\n",
        "\n",
        "axs[0].set_title('Confusion Matrix (Random Forest)')\n",
        "axs[1].set_title('Confusion Matrix (Decision Trees)')\n",
        "axs[2].set_title('Confusion Matrix (K Nearest Neighbours)')\n",
        "\n",
        "axs[0].set_xlabel('Predicted label')\n",
        "axs[1].set_xlabel('Predicted label')\n",
        "axs[2].set_xlabel('Predicted label')\n",
        "axs[0].set_ylabel('True label')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRLhtjzD66ZG"
      },
      "source": [
        "During the training phase of various classification algorithms, we trained two models for each of the algorithm using different parameters.\n",
        "\n",
        "\n",
        "***Binary Classification Algorithms:***\n",
        "1. Logistic Regression\n",
        "2. Support Vector Machine\n",
        "\n",
        "For comapring different classification algorithms, we took the best performing models from each algorithms.\n",
        "\n",
        "Based on our various tests, we found out that logistic Regression can handle large size data and can be trained in a very short amount of time. However, the drawback is less accurate models. On the other hand, SVM is quite computationally expensive and takes a hefty amount of time to train. but the good thing is the accuracy score is much higher than the logistic regression models. We tuned a few parameters here and there to improve the models' accuracy. We also did cross-validation to make sure that our model was not overfitted and was trained just right.\n",
        "\n",
        "One other thing to mention is that the accuracy of the models is dependent on the standardization of the dataset. We trained our model with and without the use of a standard scaler. During our testing different models, we found out that the accuracy and other performance measure scores went significantly high after standardizing the dataset. So, we chose to standardize data before applying PCA.\n",
        "\n",
        "\n",
        "***Multi-class Classification Algorithms:***\n",
        "1. Random Forest\n",
        "2. Decision Trees\n",
        "3. K Nearest Neighbours\n",
        "\n",
        "Again, for comapring different classification algorithms, we took the best performing models from each of the 3 algorithms.\n",
        "\n",
        "The time taken to train the multi-class classification models is relatively lower than the binary classification models. This could be due to the fact that the train data size is smaller than the binary classification train data.\n",
        "\n",
        "As shown above in the analysis section, the dataset is highly imbalanced. In order to keep the data balanced over all classes, we first took most number of samples from the minority classes and sufficient number of sample from the majority clasees. Later we used SMOTE (Synthetic Minority Over-sampling Technique) to create an overall balanced dataset for training the multi-class classification models.\n",
        "\n",
        "By comparing the performance metrics of the models, we see that Random Forest is the best performing model followed by KNN and Decision Tree. From the confusion matrix and the classification report, the dominance of Random Forest in terms of precision, recall, and f1-score is evident. The reason Decision Tree falling behind is that it is not always expressive enough to capture complex relationships between the input features and the target variable. Decision Tree may struggle with problems where the target variable depends on a combination of input features rather than just one or two features. KNN and Random Forest can handle more complex relationships between the input features and the target variable by using more flexible models. Also, we used relatively fewer parameters to tune the Decision Tree models. Just like the binary classification algorithms, we also cross-validated the multi-class classification models to make sure they were not overfitted.\n",
        "\n",
        "\n",
        "**Future Work:** Keeping this in mind, we have to choose our model accordingly if we want to stick with one. However, In this case, we can also combine the KNN and Random Forest classifiers using an ensemble method. This can improve the accuracy of our intrusion detection system by leveraging the strengths of both models and reducing the risk of overfitting. The ensemble method would allow the models to work together to produce a more robust prediction, which could be more effective at identifying different types of network attack.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "B8DGk4gEhiJp",
        "aSAAWG06ekQn",
        "LDdJgFihgVf8",
        "R28LNrp5iWR7",
        "xf9z8Pwlid-3",
        "hXWOYP6-ieI0",
        "MsSwQ-DOvm-6",
        "ZGkxFBOYv5Gt",
        "-uDiDKokwPhS",
        "_iYfyW2-yyAR",
        "NJ9tbZTRxHVU",
        "nNRw8GcEQ-st",
        "kk2Kas03g1V3",
        "R_y73RFP274P",
        "1tgkPDHR59TJ",
        "Db-kcdZVVrYX",
        "VHpB4fGaTzPK",
        "0bYBt91SVl2Q",
        "Bvab0SkCfy0d",
        "isyblWcu-wmg",
        "8D1ip-J88_fE",
        "0qr2iEpQYjmr",
        "tEDT9-gO6UfJ",
        "QUzFJzuL7K35",
        "O_5dqWNjXuRL",
        "21Q9ths2VJC-",
        "pDp-xQWSqtLV",
        "GIa0LHYKT78a",
        "GCVzGYzwXivR",
        "BxUFSY5JapE5"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
