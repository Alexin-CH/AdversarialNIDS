{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Training on CICIDS2017 Dataset\n",
    "\n",
    "This notebook trains a Random Forest classifier on the CICIDS2017 intrusion detection dataset.\n",
    "\n",
    "**Key Features:**\n",
    "- SMOTE balancing applied within CV pipeline (prevents data leakage)\n",
    "- Comprehensive preprocessing and feature engineering\n",
    "- Data leakage diagnostics\n",
    "- Feature importance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add project root to path\n",
    "root_dir = os.getcwd().split(\"AdversarialNIDS\")[0] + \"AdversarialNIDS\"\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "from CICIDS2017.preprocessing.dataset import CICIDS2017\n",
    "from UNSWNB15.preprocessing.dataset import UNSWNB15\n",
    "from scripts.models.model_utils import (\n",
    "    check_data_leakage,\n",
    "    get_tree_feature_importance    \n",
    ")\n",
    "\n",
    "# Import model-specific modules\n",
    "from scripts.models.random_forest.random_forest import train_random_forest\n",
    "\n",
    "from scripts.logger import LoggerManager\n",
    "from scripts.analysis.model_analysis import perform_model_analysis\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = LoggerManager(log_name=\"rf_notebook\").get_logger()\n",
    "logger.info(\"Starting Random Forest training notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Loading CICIDS2017 dataset...\")\n",
    "dataset = CICIDS2017(logger=logger).optimize_memory().encode().scale().subset(size=100000, multi_class=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Leakage Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for potential data leakage\n",
    "#diagnostics = check_data_leakage(X, y, logger=logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = dataset.split(test_size=0.2, apply_smote=True)\n",
    "print(f\"Train set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does Step 11 (Cross-Validation) do?\n",
    "\n",
    "In this step, we use 5-fold cross-validation to estimate how well our Random Forest pipeline will generalize to new, unseen data. The process works by splitting the training data into 5 parts (folds), training the model on 4 parts, and validating it on the remaining part. This is repeated so each part is used as a validation set once. The average accuracy across all folds gives us a robust measure of model performance before we evaluate on the true test set.\n",
    "\n",
    "**Why is this important?**\n",
    "- It helps detect overfitting or underfitting.\n",
    "- It allows us to compare different model settings fairly.\n",
    "- It provides a realistic estimate of how the model will perform in practice, using only the training data.\n",
    "- **Importantly, the real test set is never touched during cross-validation.** This ensures our final evaluation is unbiased and reflects true out-of-sample performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest using standalone function and plot CV scores\n",
    "logger.info(\"Training Random Forest with cross-validation using train_random_forest...\")\n",
    "rf_model, cv_scores = train_random_forest(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    n_estimators=10,\n",
    "    max_depth=3,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    random_state=0,\n",
    "    cv=5,\n",
    "    class_weight='balanced',\n",
    "    logger=None\n",
    ")\n",
    "if cv_scores!= None:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"CROSS-VALIDATION RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"CV Scores: {cv_scores}\")\n",
    "    print(f\"Mean CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
    "    # Plot CV scores\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(cv_scores)+1), cv_scores, marker='o', markersize=10, linewidth=2, color='green')\n",
    "    plt.axhline(y=cv_scores.mean(), color='r', linestyle='--', \n",
    "                label=f'Mean: {cv_scores.mean():.4f}')\n",
    "    plt.xlabel('Fold', fontsize=12)\n",
    "    plt.ylabel('Accuracy', fontsize=12)\n",
    "    plt.title('Decision Tree Cross-Validation Scores', fontsize=14, fontweight='bold')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "cm, cr = perform_model_analysis(\n",
    "    model=rf_model,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    logger=logger,\n",
    "    model_name=\"RandomForest\",\n",
    "    dir=os.getcwd(),\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "top_features = get_tree_feature_importance(\n",
    "    rf_model,\n",
    "    feature_names=list(dataset.data.columns),\n",
    "    top_n=15,\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "# Plot feature importance\n",
    "features, importances = zip(*top_features)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(features)))\n",
    "plt.barh(range(len(features)), importances, color=colors)\n",
    "plt.yticks(range(len(features)), features)\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.title('Top 15 Feature Importances', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
